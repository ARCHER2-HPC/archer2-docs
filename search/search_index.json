{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ARCHER2 User Documentation","text":"<p>ARCHER2 is the next generation UK National Supercomputing Service. You can find more information on the service and the research it supports on the ARCHER2 website.</p> <p>The ARCHER2 Service is a world class advanced computing resource for UK researchers. ARCHER2 is provided by UKRI, EPCC, Cray (an HPE company) and the University of Edinburgh.</p>"},{"location":"#what-the-documentation-covers","title":"What the documentation covers","text":"<p>This is the documentation for the ARCHER2 service and includes:</p> <ul> <li> <p>Quick Start Guide     The ARCHER2 quick start guide provides the minimum information for     new users.</p> </li> <li> <p>ARCHER2 User and Best Practice Guide     Covers all aspects of use of the ARCHER2 supercomputing service.     This includes fundamentals (required by all users to use the system     effectively), best practice for getting the most out of ARCHER2, and     other advanced technical topics.</p> </li> <li> <p>Research Software     Information on each of the centrally-installed research software     packages.</p> </li> <li> <p>Software Libraries     Information on the centrally-installed software libraries. Most     libraries work as expected so no additional notes are required     however a small number require specific documentation</p> </li> <li> <p>Data Analysis and Tools     Information on data analysis tools and other useful utilities.</p> </li> <li> <p>Other Software     Useful information on software that is not officially supported by the      ARCHER2 service but that will be useful to users of that software.</p> </li> <li> <p>Essential Skills     This section provides information and links on essential skills     required to use ARCHER2 efficiently: e.g. using Linux command     line, accessing help and documentation.</p> </li> <li> <p>ARCHER2 and publications     This section describes how to acknowledge the use of ARCHER2 in     your published work and how to use the ARCHER2 publications      database.</p> </li> </ul>"},{"location":"#contributing-to-the-documentation","title":"Contributing to the documentation","text":"<p>The source for this documentation is publicly available in the ARCHER2 documentation Github repository so that anyone can contribute to improve the documentation for the service. Contributions can be in the form of improvements or addtions to the content and/or addtion of Issues providing suggestions for how it can be improved.</p> <p>Full details of how to contribute can be found in the <code>README.md</code> file of the repository.</p>"},{"location":"#credits","title":"Credits","text":"<p>This documentation draws on the Cirrus Tier-2 HPC Documentation, Sheffield Iceberg Documentation and the ARCHER National Supercomputing Service Documentation.</p>"},{"location":"archer-migration/","title":"ARCHER to ARCHER2 migration","text":"<p>This section of the documentation is a guide for user migrating from ARCHER to ARCHER2.</p> <p>It covers:</p> <ul> <li>Migrating your account from ARCHER to ARCHER2</li> <li>Migrating data from ARCHER to ARCHER2</li> <li>Main differences between ARCHER and ARCHER2</li> </ul> <p>Tip</p> <p>If you need help or have questions on ARCHER to ARCHER2 migration,  please contact the ARCHER2 service desk</p>"},{"location":"archer-migration/account-migration/","title":"Migrating your account from ARCHER to ARCHER2","text":"<p>This section covers the following questions:</p> <ul> <li>When will I be able to access ARCHER2?</li> <li>Has my project has been migrated from ARCHER to ARCHER2?</li> <li>How much resource will my project have on ARCHER2?</li> <li>How do I set up an ARCHER2 account?</li> <li>How do I log into ARCHER2 for the first time?</li> </ul> <p>Tip</p> <p>If you need help or have questions on ARCHER to ARCHER2 migration,  please contact the ARCHER2 service desk</p>"},{"location":"archer-migration/account-migration/#when-will-i-be-able-to-access-archer2","title":"When will I be able to access ARCHER2?","text":"<p>We anticipate that users will have access during the week beginning 11th January 2021. Notification of activation of ARCHER2 projects will be sent to the project leaders/PIs and the project users. </p>"},{"location":"archer-migration/account-migration/#has-my-project-been-migrated-to-archer2","title":"Has my project been migrated to ARCHER2?","text":"<p>If you have an active ARCHER allocation at the end of the ARCHER service then your project will very likely be migrated to ARCHER2. If your project is migrated to ARCHER2 then it will have the same project code as it had on ARCHER.</p> <p>Some further information that may be useful:</p> <ul> <li>If you are a member of the EPSRC or NERC consortia on ARCHER then      all of these consortia have been migrated to ARCHER2.      A list of the consortia and their ARCHER/ARCHER2 codes can be found on the ARCHER2 website.</li> <li>If your project code begins with i or d then you are a member      of an industrial project or a Director's Time project, these      projects will be contacted individually to discuss arrangements.      Please speak to your project leader or PI in the first instance.</li> </ul>"},{"location":"archer-migration/account-migration/#how-much-resource-will-my-project-have-on-archer2","title":"How much resource will my project have on ARCHER2?","text":"<p>The unit of allocation on ARCHER2 is called the ARCHER2 Compute Unit (CU) and, in general, 1 CU will be worth 1 ARCHER2 node hour.</p> <p>UKRI have determined the conversion rates which will be used to transfer existing ARCHER allocations onto ARCHER2. These will be: </p> <ul> <li>1.5156 kAU = 4.21 ARCHER node hour = 1 ARCHER2 node hour = 1 CU</li> </ul> <p>In identifying these conversion rates UKRI has endeavoured to ensure that no user will be disadvantaged by the transfer of their allocation from ARCHER to ARCHER2.</p> <p>A nominal allocation will be provided to all projects during the initial no-charging period. Users will be notified before the no-charging period ends.</p> <p>When the ARCHER service ends, any unused ARCHER allocation in kAUs will be converted to ARCHER2 CUs and transferred to ARCHER2 project allocation.</p>"},{"location":"archer-migration/account-migration/#how-do-i-set-up-an-archer2-account","title":"How do I set up an ARCHER2 account?","text":"<p>Once you have been notified that you can go ahead and setup an ARCHER2  account you will do this through SAFE. Note that you should use the new unified SAFE interface rather than the ARCHER SAFE. The correct URL for the new SAFE is:</p> <ul> <li>https://safe.epcc.ed.ac.uk</li> </ul> <p>Your access details for this SAFE are the same as those for the ARCHER SAFE. You should log in in exactly the same way as you did on the  ARCHER SAFE.</p> <p>Important</p> <p>You should make sure you request the same account name in your project on ARCHER2 as you have on ARCHER. This is to ensure that you have seamless access to your ARCHER /home data on ARCHER2. See the ARCHER to ARCHER2 Data Migration page for details on data transfer from ARCHER to ARCHER2</p> <p>Once you have logged into SAFE, you will need to complete the following steps before you can log into ARCHER2 for the first time:</p> <ol> <li>Request an ARCHER2 account through SAFE<ol> <li>See: How to request a machine account (SAFE documentation)</li> </ol> </li> <li>(Optional) Create a new SSH key pair and add it to your ARCHER2 account in SAFE<ol> <li>See: SSH key pairs (ARCHER2 documentation)</li> <li>If you do not add a new SSH key to your ARCHER2 account, then      your account will use the same key as your ARCHER account</li> </ol> </li> <li>Collect your initial, one-shot password from SAFE<ol> <li>See: Intial passwords (ARCHER2 documentation)</li> </ol> </li> </ol>"},{"location":"archer-migration/account-migration/#how-do-i-log-into-archer2-for-the-first-time","title":"How do I log into ARCHER2 for the first time?","text":"<p>The ARCHER2 documentation covers logging in to ARCHER from a variety of operating systems:</p> <ul> <li>Logging in to ARCHER2 from macOS/Linux</li> <li>Logging in to ARCHER2 from Windows</li> </ul>"},{"location":"archer-migration/archer2-differences/","title":"Main differences between ARCHER and ARCHER2","text":"<p>This section provides an overview of the main differences between ARCHER and ARCHER2 along with links to more information where  appropriate.</p>"},{"location":"archer-migration/archer2-differences/#for-all-users","title":"For all users","text":"<ul> <li>You use the new SAFE rather than the ARCHER SAFE</li> <li>You can add multiple SSH keys to your ARCHER2 account using SAFE</li> <li>There are 128 cores on an ARCHER2 compute node rather than 24</li> <li>ARCHER2 usage is charged in CUs (Compute Units) rather than kAU<ul> <li>Generally: 1.5156 kAU = 4.21 ARCHER node hour = 1 ARCHER2 node hour = 1 CU</li> </ul> </li> <li>ARCHER2 uses the Slurm scheduler instead of PBS Pro<ul> <li>See: Running jobs on ARCHER2</li> </ul> </li> <li>Parallel applications are launched using <code>srun</code> rather than <code>aprun</code></li> <li>You cannot currently query your budget on ARCHER2 itself, you can      view your budget using SAFE</li> </ul>"},{"location":"archer-migration/archer2-differences/#for-users-compiling-and-developing-software-on-archer2","title":"For users compiling and developing software on ARCHER2","text":"<ul> <li>The Intel compilers are not available on ARCHER2<ul> <li>ARCHER2 supports the Cray, Gnu and AMD compilers</li> <li>See: Application development environment</li> </ul> </li> <li>Intel MKL libraries are not available on ARCHER2<ul> <li>Use Cray LibSci for BLAS/LAPACK/ScaLAPACK</li> <li>Use FFTW for FFTs</li> </ul> </li> <li>All binaries on ARCHER2 are dynamically linked<ul> <li>Static linking is currently not possible on ARCHER2</li> <li>This means that all binaries must be installed on the /work file systems   as these are the only file systems available on the compute nodes</li> </ul> </li> </ul>"},{"location":"archer-migration/data-migration/","title":"Data migration from ARCHER to ARCHER2","text":"<p>This short guide explains how to move data from the ARCHER service to the ARCHER2 service.</p> <p>We have also created a walkthrough video to guide you.</p> <p>Note</p> <p>This section assumes that you have an active ARCHER and ARCHER2 account,  and that you have successfully logged in to both accounts.</p> <p>Tip</p> <p>Unlike normal access, ARCHER to ARCHER2 transfer has been set up to require  only one form of authentication. You will not need to generate a new SSH key pair to transfer data from ARCHER to ARCHER2 as your password will suffice.</p> <p>First, login to the ARCHER(1) (making sure to change <code>auser</code> to your username):</p> <pre><code>ssh auser@login.archer.ac.uk\n</code></pre> <p>Then, combine important research data into a single archive file using the  following command:</p> <pre><code>tar -czf all_my_files.tar.gz file1.txt file2.txt directory1/\n</code></pre> <p>Please be selective -- the more data you want to transfer, the more time it  will take.</p> <p>From ARCHER in particular, in order to get the best transfer performance, we need to access a newer version of the SSH program. We do this by loading the <code>openssh</code> module:</p> <pre><code>module load openssh\n</code></pre>"},{"location":"archer-migration/data-migration/#transferring-data-using-rsync-recommended","title":"Transferring data using <code>rsync</code> (recommended)","text":"<p>Begin the data transfer from ARCHER to ARCHER2 using <code>rsync</code>:</p> <pre><code>rsync -Pv -e\"ssh -c aes128-gcm@openssh.com\" \\\n       ./all_my_files.tar.gz a2user@transfer.dyn.archer2.ac.uk:/work/t01/t01/a2user\n</code></pre> <p>Important</p> <p>Notice that the hostname for data transfer from ARCHER to ARCHER2 is not the usual login address. Instead, you use  <code>transfer.dyn.archer2.ac.uk</code>. This address has been configured to  allow higher performance data transfer and to allow access to  ARCHER with password only with no SSH key required.</p> <p>When running this command, you will be prompted to enter your ARCHER2 password. Enter it and the data transfer will begin. Also, remember to  replace <code>a2user</code> with your ARCHER2 username, and <code>t01</code> with the budget  associated with that username.</p> <p>The use of the <code>-P</code> flag to allow partial transfer -- the same command could be used to restart the transfer after a loss of connection. The <code>-e</code> flag allows specification of the ssh command - we have used this to add the location of the identity file.  The <code>-c</code> option specifies the cipher to be used as <code>aes128-gcm</code> which has  been found to increase performance. Unfortunately the <code>~</code> shortcut is not  correctly expanded, so we have specified the full path. We move our research  archive to our project work directory on ARCHER2.</p>"},{"location":"archer-migration/data-migration/#transferring-data-using-scp","title":"Transferring data using scp","text":"<p>If you are unconcerned about being able to restart an interrupted transfer, you could instead use the <code>scp</code> command,</p> <pre><code>scp -c aes128-gcm@openssh.com all_my_files.tar.gz \\\n    a2user@transfer.dyn.archer2.ac.uk:/work/t01/t01/a2user/\n</code></pre> <p>but <code>rsync</code> is recommended for larger transfers.</p> <p>Important</p> <p>Notice that the hostname for data transfer from ARCHER to ARCHER2 is not the usual login address. Instead, you use  <code>transfer.dyn.archer2.ac.uk</code>. This address has been configured to  allow higher performance data transfer and to allow access to  ARCHER with password only with no SSH key required.</p>"},{"location":"archer2-migration/","title":"ARCHER2 4-cabinet system to ARCHER2 full system migration","text":"<p>This section of the documentation is a guide for user migrating from the ARCHER2 4-cabinet system to the ARCHER2 full system.</p> <p>It covers:</p> <ul> <li>Migrating your account from ARCHER2 4-cab to full ARCHER2</li> <li>Migrating data from ARCHER2 4-cab to full ARCHER2</li> <li>Porting applications from ARCHER2 4-cab to full ARCHER2</li> <li>Main differences between ARCHER2 4-cab and full ARCHER2</li> </ul> <p>Tip</p> <p>If you need help or have questions on ARCHER2 4-cab to full ARCHER2 migration  please contact the ARCHER2 service desk</p>"},{"location":"archer2-migration/account-migration/","title":"Accessing the ARCHER2 full system","text":"<p>This section covers the following questions:</p> <ul> <li>When will I be able to access ARCHER2 full system? </li> <li>Has my project been enabled on ARCHER2 full system?</li> <li>How much resource will my project have on ARCHER2 full system?</li> <li>How do I set up an account on the full system?</li> <li>How do I log into the different ARCHER2 systems?</li> </ul> <p>Tip</p> <p>If you need help or have questions on using ARCHER2 4-cabinet system and ARCHER2 full system please contact the ARCHER2 service desk</p>"},{"location":"archer2-migration/account-migration/#when-will-i-be-able-to-access-archer2-full-system","title":"When will I be able to access ARCHER2 full system?","text":"<p>We anticipate that users will have access from mid-late November. Users will have access to both the ARCHER2 4-cabinet system and ARCHER2 full system for at least 30 days. UKRI will confirm the dates and these will be communicated to you as they are confirmed. There will be at least 14 days notice before access to the ARCHER2 4-Cabinet system is removed. </p>"},{"location":"archer2-migration/account-migration/#has-my-project-been-enabled-on-archer2-full-system","title":"Has my project been enabled on ARCHER2 full system?","text":"<p>If you have an active ARCHER2 4-cabinet system allocation on 1st October 2021 then your project will be enabled on the ARCHER2 full system. The project code is the same on the full service as it is on ARCHER2 4-cabinet system. </p> <p>Some further information that may be useful:</p> <ul> <li>If you are a member of the EPSRC or NERC consortia on ARCHER2 then all of these consortia have been enabled on ARCHER2 full system. A list of the consortia and their ARCHER2 codes can be found on the ARCHER2 website.</li> </ul>"},{"location":"archer2-migration/account-migration/#how-much-resource-will-my-project-have-on-archer2-full-system","title":"How much resource will my project have on ARCHER2 full system?","text":"<p>The unit of allocation on ARCHER2 is called the ARCHER2 Compute Unit (CU) and 1 CU is equivalent to 1 ARCHER2 node hour. Your time budget will be shared on both systems. This means that any existing allocation available to your project on the 4-cabinet system will also be available on the full system. </p> <p>There will be a period of at least 30 days where users will have access to both the 4-cabinet system and the full system. During this time, use on the full system will be uncharged (though users must still have access to a valid, positive budget to be able to submit jobs) and use on the 4-cabinet system will be a charged in the usual way. Users will be notified before the no-charging period ends.</p>"},{"location":"archer2-migration/account-migration/#how-do-i-set-up-an-account-on-the-full-system","title":"How do I set up an account on the full system?","text":"<p>You will keep the same usernames, passwords and SSH keys that you use on the 4-cabinet system on the full system.</p> <p>You do not need to do anything to enable your account, these will be made available automatically once access to the full system is available. </p> <p>You will connect to the full system in the same way as you connect to the 4-cabinet system except for switching the ordering of the credentials: </p> <ul> <li>4-cabinet system: enter machine account password then passphrase for SSH key pair</li> <li>Full system: enter passphrase for SSH key pair then machine account password</li> </ul>"},{"location":"archer2-migration/account-migration/#how-do-i-log-into-the-different-archer2-systems","title":"How do I log into the different ARCHER2 systems?","text":"<p>The ARCHER2 documentation covers logging in to ARCHER2 from a variety of operating systems:    - Logging in to ARCHER2 from macOS/Linux    - Logging in to ARCHER2 from Windows</p> <p>Login addresses:</p> <ul> <li>ARCHER2 4-cabinet system: login-4c.archer2.ac.uk</li> <li>ARCHER2 full system: login.archer2.ac.uk</li> </ul> <p>Tip</p> <p>When logging into the ARCHER2 full system for the first time, you may see an error  from SSH that looks like</p> <pre><code>@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@       WARNING: POSSIBLE DNS SPOOFING DETECTED!          @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nThe ECDSA host key for login.archer2.ac.uk has changed,\nand the key for the corresponding IP address 193.62.216.43\nhas a different value. This could either mean that\nDNS SPOOFING is happening or the IP address for the host\nand its host key have changed at the same time.\nOffending key for IP in /Users/auser/.ssh/known_hosts:11\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\nIt is also possible that a host key has just been changed.\nThe fingerprint for the ECDSA key sent by the remote host is\nSHA256:UGS+LA8I46LqnD58WiWNlaUFY3uD1WFr+V8RCG09fUg.\nPlease contact your system administrator.\n</code></pre> <p>If you see this, you should delete the offending host key from your <code>~/.ssh/known_hosts</code> file (in the example above the offending line is line #11)</p>"},{"location":"archer2-migration/account-migration/#what-will-happen-to-archer2-data","title":"What will happen to ARCHER2 data?","text":"<p>There are three file systems associated with the ARCHER2 Service: </p>"},{"location":"archer2-migration/account-migration/#home-file-systems","title":"home file systems","text":"<p>The home file systems will be mounted on both the 4-cabinet system and the full system; so users\u2019 directories are shared across the two systems. Users will be able to access the home file systems from both systems and no action is required to move data. The home file systems will be read and writeable on both services during the transition period. </p>"},{"location":"archer2-migration/account-migration/#work-file-systems","title":"work file systems","text":"<p>There are different work file systems for the 4-cabinet system and the full system. </p> <p>The work file system on the 4-cabinet system (labelled \u201carcher2-4c-work\u201d in SAFE) will remain available on the 4-cabinet system during the transition period.</p> <p>There will be new work file systems on the full system and you will have new directories on the new work file systems. Your initial quotas will typically be double your quotas for the 4-cabinet work file system.</p> <p>Important: you are responsible for transferring any required data from the 4-cabinet work file systems  to your new directories on the work file systems on the full system.</p> <p>The work file system on the 4-cabinet system will be available for you to transfer your data from for at least 30 days from the start of the ARCHER2 full system access and 14 days notice will be given before the 4-cabinet work file system is removed.</p>"},{"location":"archer2-migration/account-migration/#rdfaas-file-systems","title":"RDFaaS file systems","text":"<p>For users who have access to the RDFaaS, your RDFaaS data will be available on both the 4-cabinet system and the full system during the transition period and will be readable and writeable on both systems.</p>"},{"location":"archer2-migration/archer2-differences/","title":"Main differences between ARCHER2 4-cabinet system and ARCHER2 full system","text":"<p>This section provides an overview of the main differences between the ARCHER2 4-cabinet system that all users have been using up until now and the full ARCHER2 system along with links to more information where  appropriate.</p>"},{"location":"archer2-migration/archer2-differences/#for-all-users","title":"For all users","text":"<ul> <li>There are 5860 compute nodes in total on the full ARCHER2 system rather    than just the 1024 on the 4-cabinet ARCHER2 system.</li> <li>Of the 5860 compute nodes, 584 are high memory nodes, these nodes have   512 GiB of memory rather than the 256 GiB available on standard memory   nodes.</li> <li>There are two data analysis nodes available and these are shared by multiple   users. When using these nodes, users typically request the number of cores   and the amount of memory they require (unlike compute nodes where you always   have access to all the cores and all the memory on a node and do not share   with any other users). See the Data Analysis section of the User Guide   for more information.</li> <li>Software is provided by the Lmod module   system (on the 4-cabinet system, TCL environment modules are used instead). Many   commands are similar but there are some differences, see    the Software Environment section of the User Guide   for more information.</li> <li>Not all versions of all software have been ported over to the full system from   the 4-cabinet system, some older versions of software have not been installed.</li> <li>The scheduler layout has been expanded to provide more functionality and    flexibility. You can find details of the new QoS available in   the Submitting Jobs on ARCHER2 section of the User Guide.</li> <li>You no longer need to specify <code>--reservation=shortqos</code> when using the    <code>short</code> QoS.</li> <li>Jobs running in a reservation can now run for longer than the maximum wall time available   in any of the normal QoS defined in the scheduler. Reservations must use the <code>reservation</code>   QoS.</li> <li>You should no longer add the <code>module load epcc-job-env</code> command to job submission   scripts.</li> </ul>"},{"location":"archer2-migration/archer2-differences/#for-users-compiling-and-developing-software-on-archer2","title":"For users compiling and developing software on ARCHER2","text":"<ul> <li>The HPE Programming Environment (PE) version has been updated to the   21.04 release with the 21.09 release also available. These releases make   newer versions of compilers and MPI libraries available.</li> <li>The change to Lmod modules means that some modules are hidden by default   until dependencies have been loaded (for example, you will not be able   to load the <code>cray-netcdf</code> or <code>cray-netcdf-hdf5parallel</code> modules until   you have loaded the appropriate <code>cray-hdf5</code> or <code>cray-hdf5-parallel</code> modules).   You can use the <code>module spider</code> command to see all available modules, including   hidden ones.</li> <li>There are two MPI transport layers available: OpenFabrics (OFI) and UCX.   In some cases, you may see performance and/or scaling improvements by switching   to UCX rather than the default OFI transport layer. For more information on   when to switch and how to switch, see   the Application Development Environment section of the User Guide</li> </ul>"},{"location":"archer2-migration/data-migration/","title":"Data migration from the ARCHER2 4-cabinet system to the ARCHER2 full system","text":"<p>This short guide explains how to move data from from the work file system on the ARCHER2 4-cabinet system to the ARCHER2 full system. Your space on the home file system is shared between the ARCHER2 4-cabinet system  and the ARCHER2 full system so everything from your home directory is already effectively transferred.</p> <p>Note</p> <p>This section assumes that you have an active ARCHER2 4-cabinet system  and ARCHER2 full system account, and that you have successfully logged  in to both accounts.</p> <p>Tip</p> <p>Unlike normal access, ARCHER2 4-cabinet system to ARCHER2 full system transfer  has been set up to require only one form of authentication. You will only need one factor to authenticate from the 4-cab to the full system or vice versa. This factor can be either an SSH key (that has been registered against your account in  SAFE) or you can use your passowrd. If you have a large amount of data to transfer you may want to setup a passphrase-less SSH key on ARCHER2 full system and use the data analysis nodes to run transfers via a Slurm job.</p>"},{"location":"archer2-migration/data-migration/#transferring-data-interactively-from-the-4-cabinet-system-to-the-full-system","title":"Transferring data interactively from the 4-cabinet system to the full system","text":"<p>First, login to the ARCHER2 4-cabinet system (making sure to change <code>auser</code>  to your username):</p> <pre><code>ssh auser@login-4c.archer2.ac.uk\n</code></pre> <p>Then, combine important research data into a single archive file using the  following command:</p> <pre><code>tar -czf all_my_files.tar.gz file1.txt file2.txt directory1/\n</code></pre> <p>Please be selective -- the more data you want to transfer, the more time it  will take.</p> <p>Unpack the archive file in the destination directory</p> <pre><code>tar -xzf all_my_files.tar.gz\n</code></pre>"},{"location":"archer2-migration/data-migration/#transferring-data-using-rsync-recommended","title":"Transferring data using <code>rsync</code> (recommended)","text":"<p>Begin the data transfer from the ARCHER2 4-cabinet system to the ARCHER2 full  system using <code>rsync</code>:</p> <pre><code>rsync -Pv all_my_files.tar.gz a2user@login.archer2.ac.uk:/work/t01/t01/a2user\n</code></pre> <p>When running this command, you will be prompted to enter your ARCHER2 password -- this is the same password for the ARCHER2 4-cabinet system  and the ARCHER2 full system. Enter it and the data transfer will begin.  Remember to replace <code>a2user</code> with your ARCHER2 username, and <code>t01</code> with  the budget associated with that username.</p> <p>We use the <code>-P</code> flag to allow partial transfer -- the same command could be used to restart the transfer after a loss of connection. We move our research archive to our project work directory  on the ARCHER2 full system.</p>"},{"location":"archer2-migration/data-migration/#transferring-data-using-scp","title":"Transferring data using scp","text":"<p>If you are unconcerned about being able to restart an interrupted transfer, you could instead use the <code>scp</code> command,</p> <pre><code>scp all_my_files.tar.gz a2user@login.archer2.ac.uk:/work/t01/t01/a2user/\n</code></pre> <p>but <code>rsync</code> is recommended for larger transfers.</p>"},{"location":"archer2-migration/data-migration/#transferring-data-via-the-serial-queue","title":"Transferring data via the serial queue","text":"<p>It may be convenient to submit long data transfers to the serial queue. In this case, a number of simple preparatory steps are required to authenticate:</p> <ol> <li>On the full system, create a new ssh key pair without passphrase (just    press return when prompted).</li> <li>Add the new public key to SAFE against your machine account.</li> <li>Use this key pair for <code>ssh/scp</code> commands in the serial queue to    authenticate. As    it has been arranged that only one of ssh key/password are required    between the serial nodes and the 4-cabinet system,    this is sufficient.</li> </ol> <p>An example serial queue script using <code>rsync</code> might be:</p> <p><pre><code>#!/bin/bash\n\n# Slurm job options (job-name, job time)\n\n#SBATCH --partition=serial\n#SBATCH --qos=serial\n\n#SBATCH --time=02:00:00\n#SBATCH --ntasks=1\n\n# Replace [budget code] below with your budget code\n\n#SBATCH --account=[budget code] \n\n# Issue appropriate rsync command\n\nrsync -av --stats --progress --rsh=\"ssh -i ${HOME}/.ssh/id_rsa_batch\" \\\n      user-01@login-4c.archer2.ac.uk:/work/proj01/proj01/user-01/src \\\n      /work/proj01/proj01/user-01/destination\n</code></pre> where <code>${HOME}/.ssh/id_rsa_batch</code> is the new ssh key. Note that the <code>${HOME}</code> directory is visible from the serial nodes on the full system, so ssh key pairs in <code>${HOME}/.ssh</code> are available. </p>"},{"location":"archer2-migration/porting/","title":"Porting applications to full ARCHER2 system","text":"<p>Porting applications to the full ARCHER2 system has generally  proven straightforward if they are running successfully on  the ARCHER2 4-cabinet system. You should be able to use the  same (or very similar) compile processes on the the full system as you used on ARCHER2.</p> <p>During testing of the ARCHER2 full system, the CSE team at EPCC have seen that application binaries compiled on the 4-cabinet system can usually be copied over to the full system and work well and give good performance. However, if you run into issues with executables taken from the 4-cabinet system on the full system you should recompile in the first instance.</p> <p>Information on compiling applications on the full system can be found in the Application Development Environment section of the User and Best Practice Guide.</p>"},{"location":"data-tools/","title":"Data Analysis and Tools","text":"<p>This section provides information on each of the centrally installed data analysis software and other software tools.</p> <p>The tools currently available in this section are (software that is installed or maintained by third-parties rather than the ARCHER2 service are marked with *):</p> <ul> <li>AMD \u03bcProf: Profiling tools provided by AMD</li> <li>Arm Forge: Provides debugging and profiling tools for MPI parallel applications, and OpenMP or pthreads mutli-threaded applications (and also hydrid MPI/OpenMP)</li> <li>Energy Counters: MPI-based library for reading energy counters</li> <li>Julia(*): The julia language</li> <li>ParaView: A data visualisation and analysis package </li> <li>R: The R statistical language</li> <li>VisiData: An interactive multitool for tabular data</li> </ul>"},{"location":"data-tools/amd-uprof/","title":"AMD \u03bcProf","text":"<p>AMD \u03bcProf (\u201cMICRO-prof\u201d) is a software profiling analysis tool for x86 applications running on Windows, Linux and FreeBSD operating systems and provides event information unique to the AMD \u201cZen\u201d-based processors and AMD INSTINCT\u2122 MI Series accelerators. AMD uProf enables the developer to better understand the limiters of application performance and evaluate improvements.</p>"},{"location":"data-tools/amd-uprof/#accessing-amd-prof-on-archer2","title":"Accessing AMD \u03bcProf on ARCHER2","text":"<p>To gain access to the AMD\u03bcProf tools on ARCHER2, you must load the module:</p> <pre><code>module load amd-uprof\n</code></pre>"},{"location":"data-tools/amd-uprof/#using-amd-prof","title":"Using AMD \u03bcProf","text":"<p>Please see the AMD documentation for information on how to use \u03bcProf:</p> <ul> <li>AMD \u03bcProf documentation</li> </ul>"},{"location":"data-tools/arm-forge/","title":"Arm Forge","text":""},{"location":"data-tools/arm-forge/#arm-forge","title":"Arm Forge","text":"<p>Note</p> <p>What were Arm Forge products (DDT and MAP) were acquired by Linaro in 2023. We may continue to refer to \"Arm Forge\" to prevent confusion, particularly in the context of module files. However, relevant links are now to the Linaro web site</p> <p>Linaro Forge provides debugging and profiling tools for MPI parallel applications, and OpenMP or pthreads multi-threaded applications (and also hydrid MPI/OpenMP). The debugger and profiler are called DDT and MAP, respectively.</p> <p>ARCHER2 has a license for up to 16 nodes (2048 cores) shared between all users at any one time. (Note, cores are counted by the license, not MPI processes, threads, or any other software entity.)</p> <p>There are two ways of running the Forge user interface. If you have a good internet connection to ARCHER2, the GUI can be run on the front-end (with an X-connection). Alternatively, one can download a copy of the Forge remote client to your laptop or desktop, and run it locally. The remote client should be used if at all possible.</p> <p>To download the remote client, see the Forge developer download pages. Version 22.1.1 is known to work at the time of writing. Connecting with the remote client is discussed below.</p>"},{"location":"data-tools/arm-forge/#one-time-set-up-for-using-forge","title":"One time set-up for using Forge","text":"<p>A preliminary step is required to set up the necessary Forge configuration files that allow DDT and MAP to initialise its environment correctly so that it can, for example, interact with the SLURM queue system. These steps should be performed in the <code>/work</code> file system on ARCHER2.</p> <p>It is recommended that these commands are performed in the top-level work file system directory for the user account, i.e., <code>${HOME/home/work}</code>.</p> <pre><code>module load arm/forge\ncd ${HOME/home/work}\nsource ${FORGE_DIR}/config-init\n</code></pre> <p>This will create a directory <code>${HOME/home/work}/.allinea</code> that contains the following files.</p> <pre><code>system.config  user.config\n</code></pre> <p>The directory will also store other relevant files when Forge is run.</p> <p>Warning</p> <p>The <code>config-init</code> script will output a warning, <code>...failed to read system config</code>. Please ignore: subsequent output should indicate that the new configuration files have been created.</p> <p>Once you have created this directory, you also need to modify the <code>system.config</code> file in the directory <code>${HOME/home/work/.allinea}</code>, editing the line</p> <pre><code>shared directory = ~\n</code></pre> <p>To instead point to your <code>${HOME/home/work/.allinea}</code> directory, i.e. if you are in the <code>z19</code> project, that would be:</p> <pre><code>shared directory = /work/z19/z19/$USER/.allinea\n</code></pre>"},{"location":"data-tools/arm-forge/#using-ddt","title":"Using DDT","text":"<p>DDT (Distributed Debugging Tool) provides an easy-to-use graphical interface for source-level debugging of compiled C/C++ or Fortran codes. It can be used for non-interactive debugging, and there is also some limited support for python debugging.</p>"},{"location":"data-tools/arm-forge/#preparation","title":"Preparation","text":"<p>To prepare your program for debugging, compile and link in the normal way but remember to include the <code>-g</code> compiler option to retain symbolic information in the executable. For some programs, it may be necessary to reduce the optimisation to <code>-O0</code> to obtain full and consistent information. However, this in itself can change the behaviour of bugs, so some experimentation may be necessary.</p>"},{"location":"data-tools/arm-forge/#post-mortem-debugging","title":"Post-mortem debugging","text":"<p>A non-interactive method of debugging is available which allows information to be obtained on the state of the execution at the point of failure in a batch job.</p> <p>Such a job can be submitted to the batch system in the usual way. The relevant command to start the executable is as follows.</p> <pre><code># ... SLURM batch commands as usual ...\n\nmodule load arm/forge\n\nexport OMP_NUM_THREADS=16\nexport OMP_PLACES=cores\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nddt --verbose --offline --mpi=slurm --np 8 \\\n--mem-debug=fast --check-bounds=before \\\n./my_executable\n</code></pre> <p>The parallel launch is delegated to <code>ddt</code> and the <code>--mpi=slurm</code> option indicates to <code>ddt</code> that the relevant queue system is SLURM (there is no explicit <code>srun</code>). It will also be necessary to state explicitly to <code>ddt</code> the number of processes required (here <code>--np 8</code>). For other options see, e.g., <code>ddt --help</code>.</p> <p>Note that higher levels of memory debugging can result in extremely slow execution. The example given above uses the default <code>--mem-debug=fast</code> which should be a reasonable first choice.</p> <p>Execution will produce a <code>.html</code> format report which can be used to examine the state of execution at the point of failure.</p>"},{"location":"data-tools/arm-forge/#interactive-debugging-using-the-client-to-submit-a-batch-job","title":"Interactive debugging: using the client to submit a batch job","text":"<p>You can also start the client interactively (for details of remote launch, see below).</p> <pre><code>module load arm/forge\nddt\n</code></pre> <p>This should start a window as shown below. Click on the DDT panel on the left, and then on the Run and debug a program option. This will bring up the Run dialogue as shown.</p> <p>Note:</p> <ul> <li> <p>One can start either DDT or MAP by clicking the appropriate panel on the left-hand side;</p> </li> <li> <p>If the license has connected successfully, a serial number will be shown in small text at the lower left.</p> </li> </ul> <p></p> <p>In the Application sub panel of the Run dialog box, details of the executable, command line arguments or data files, the working directory and so on should be entered.</p> <p>Click the MPI checkbox and specify the MPI implementation. This is done by clicking the Details button and then the Change button. Choose the SLURM (generic) implementation from the drop-down menu and click OK. You can then specify the required number of nodes/processes and so on.</p> <p>Click the OpenMP checkbox and select the relevant number of threads (if there is no OpenMP in the application itself, select 1 thread).</p> <p>Click the Submit to Queue checkbox and then the associated Configure button. A new set of options will appear such as Submission template file, where you can enter <code>${FORGE_DIR}/templates/archer2.qtf</code> and click OK. This template file provides many of the options required for a standard batch job. You will then need to click on the Queue Parameters button in the same section and specify the relevant project budget, see the Account entry.</p> <p>The default queue template file configuration uses the short QoS with the standard time limit of 20 minutes. If something different is required, one can edit the settings. Alternatively, one can copy the <code>archer2.qtf</code> file (to <code>${HOME/home/work}/.allinea</code>) and make the relevant changes. This new template file can then be specified in the dialog window.</p> <p>There may be a short delay while the sbatch job starts. Debugging should then proceed as described in the Allinea documentation.</p>"},{"location":"data-tools/arm-forge/#using-map","title":"Using MAP","text":"<p>Load the <code>arm/forge</code> module:</p> <pre><code>module load arm/forge\n</code></pre>"},{"location":"data-tools/arm-forge/#compilation-and-linking","title":"Compilation and linking","text":"<p>Compilation should take place as usual. However, an additional set of libraries is required at link time.</p> <p>The path to the additional libraries required will depend on the programming environment you are using as well as the Cray programming release. Here are the paths for each of the compiler environments consistent with the Cray Programming Release (CPE) 21.04 using the default OFI as the low-level comms protocol:</p> <ul> <li><code>PrgEnv-cray</code>: <code>${FORGE_DIR}/map/libs/default/cray/ofi</code></li> <li><code>PrgEnv-gnu</code>: <code>${FORGE_DIR}/map/libs/default/gnu/ofi</code></li> <li><code>PrgEnv-aocc</code>: <code>${FORGE_DIR}/map/libs/default/aocc/ofi</code></li> </ul> <p>For example, for <code>PrgEnv-gnu</code> the additional options required at link time are given below. <pre><code>-L${FORGE_DIR}/map/libs/default/gnu/ofi \\\n-lmap-sampler-pmpi -lmap-sampler \\\n-Wl,--eh-frame-hdr -Wl,-rpath=${FORGE_DIR}/map/libs/default/gnu/ofi\n</code></pre></p> <p>The MAP libraries for other Cray programming releases can be found under <code>${FORGE_DIR}/map/libs</code>. If you require MAP libraries built for the UCX comms protocol, simply replace <code>ofi</code> with <code>ucx</code> in the library path.</p>"},{"location":"data-tools/arm-forge/#generating-a-profile","title":"Generating a profile","text":"<p>Submit a batch job in the usual way, and include the lines:</p> <pre><code># ... SLURM batch commands as usual ...\n\nmodule load arm/forge\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nmap -n &lt;number of MPI processes&gt; --mpi=slurm --mpiargs=\"--hint=nomultithread --distribution=block:block\" --profile ./my_executable\n</code></pre> <p>Successful execution will generate a file with a <code>.map</code> extension.</p> <p>This <code>.map</code> file may be viewed via the GUI (start with either <code>map</code> or <code>forge</code>) by selecting the Load a profile data file from a previous run option. The resulting file selection dialog box can then be used to locate the <code>.map</code> file.</p>"},{"location":"data-tools/arm-forge/#connecting-with-the-remote-client","title":"Connecting with the remote client","text":"<p>If one starts the Forge client on e.g., a laptop, one should see the main window as shown above. Select Remote Launch and then Configure from the drop-down menu. In the Configure Remote Connections dialog box click Add. The following window should be displayed. Fill in the fields as shown. The Connection Name is just a tag for convenience (useful if a number of different accounts are in use). The Host Name should be as shown with the appropriate username. The Remote Installation Directory should be exactly as shown. The Remote Script is needed to execute additional environment commands on connection. A default script is provided in the location shown.</p> <pre><code>/work/y07/shared/utils/core/arm/forge/latest/remote-init\n</code></pre> <p>Other settings can be as shown. Remember to click OK when done.</p> <p></p> <p>From the Remote Launch menu you should now see the new Connection Name. Select this, and enter the relevant ssh passphase and machine password to connect. A remote connection will allow you to debug, or view a profile, as discussed above.</p> <p>If different commands are required on connection, a copy of the <code>remote-init</code> script can be placed in, e.g., <code>${HOME/home/work}/.allinea</code> and edited as necessary. The full path of the new script should then be specified in the remote launch settings dialog box. Note that the script changes the directory to the <code>/work/</code> file system so that batch submissions via <code>sbatch</code> will not be rejected.</p> <p>Finally, note that <code>ssh</code> may need to be configured so that it picks up the correct local public key file. This may be done, e.g., via the local <code>.ssh/config</code> configuration file.</p>"},{"location":"data-tools/arm-forge/#useful-links","title":"Useful links","text":"<ul> <li>Forge User Guide</li> <li>More information on X-window connections to ARCHER2.</li> </ul>"},{"location":"data-tools/cray-r/","title":"R","text":""},{"location":"data-tools/cray-r/#r-for-statistical-computing","title":"R for statistical computing","text":"<p>R is a software environment for statistical computing and graphics. It provides a wide variety of statistical and graphical techniques (linear and nonlinear modelling, statistical tests, time-series analysis, classification, clustering, and so on).</p> <p>Note</p> <p>When you log onto ARCHER2, no R module is loaded by default. You need to load the <code>cray-R</code> module to access the functionality described below.</p> <p>The recommended version of R to use on ARCHER2 is the HPE Cray R distribution, which can be loaded using:</p> <pre><code>module load cray-R\n</code></pre> <p>The HPE Cray R distribution includes a range of common R packages, including all of the base packages, plus a few others.</p> <p>To see what packages are available, run the R command</p> <pre><code>library()\n</code></pre> <p>--from the R command prompt.</p> <p>At the time of writing, the HPE Cray R distribution included the following packages:</p> Full System <pre><code>Packages in library \u2018/opt/R/4.0.3.0/lib64/R/library\u2019:\n\nbase                    The R Base Package\nboot                    Bootstrap Functions (Originally by Angelo Canty\n                        for S)\nclass                   Functions for Classification\ncluster                 \"Finding Groups in Data\": Cluster Analysis\n                        Extended Rousseeuw et al.\ncodetools               Code Analysis Tools for R\ncompiler                The R Compiler Package\ndatasets                The R Datasets Package\nforeign                 Read Data Stored by 'Minitab', 'S', 'SAS',\n                        'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ...\ngraphics                The R Graphics Package\ngrDevices               The R Graphics Devices and Support for Colours\n                        and Fonts\ngrid                    The Grid Graphics Package\nKernSmooth              Functions for Kernel Smoothing Supporting Wand\n                        &amp; Jones (1995)\nlattice                 Trellis Graphics for R\nMASS                    Support Functions and Datasets for Venables and\n                        Ripley's MASS\nMatrix                  Sparse and Dense Matrix Classes and Methods\nmethods                 Formal Methods and Classes\nmgcv                    Mixed GAM Computation Vehicle with Automatic\n                        Smoothness Estimation\nnlme                    Linear and Nonlinear Mixed Effects Models\nnnet                    Feed-Forward Neural Networks and Multinomial\n                        Log-Linear Models\nparallel                Support for Parallel computation in R\nrpart                   Recursive Partitioning and Regression Trees\nspatial                 Functions for Kriging and Point Pattern\n                        Analysis\nsplines                 Regression Spline Functions and Classes\nstats                   The R Stats Package\nstats4                  Statistical Functions using S4 Classes\nsurvival                Survival Analysis\ntcltk                   Tcl/Tk Interface\ntools                   Tools for Package Development\nutils                   The R Utils Package\n</code></pre> 4-cabinet system <pre><code>Packages in library \u2018/opt/R/4.0.2.0/lib64/R/library\u2019:\n\nbase                    The R Base Package\nboot                    Bootstrap Functions (Originally by Angelo Canty\n                        for S)\nclass                   Functions for Classification\ncluster                 \"Finding Groups in Data\": Cluster Analysis\n                        Extended Rousseeuw et al.\ncodetools               Code Analysis Tools for R\ncompiler                The R Compiler Package\ndatasets                The R Datasets Package\nforeign                 Read Data Stored by 'Minitab', 'S', 'SAS',\n                        'SPSS', 'Stata', 'Systat', 'Weka', 'dBase', ...\ngraphics                The R Graphics Package\ngrDevices               The R Graphics Devices and Support for Colours\n                        and Fonts\ngrid                    The Grid Graphics Package\nKernSmooth              Functions for Kernel Smoothing Supporting Wand\n                        &amp; Jones (1995)\nlattice                 Trellis Graphics for R\nMASS                    Support Functions and Datasets for Venables and\n                        Ripley's MASS\nMatrix                  Sparse and Dense Matrix Classes and Methods\nmethods                 Formal Methods and Classes\nmgcv                    Mixed GAM Computation Vehicle with Automatic\n                        Smoothness Estimation\nnlme                    Linear and Nonlinear Mixed Effects Models\nnnet                    Feed-Forward Neural Networks and Multinomial\n                        Log-Linear Models\nparallel                Support for Parallel computation in R\nrpart                   Recursive Partitioning and Regression Trees\nspatial                 Functions for Kriging and Point Pattern\n                        Analysis\nsplines                 Regression Spline Functions and Classes\nstats                   The R Stats Package\nstats4                  Statistical Functions using S4 Classes\nsurvival                Survival Analysis\ntcltk                   Tcl/Tk Interface\ntools                   Tools for Package Development\nutils                   The R Utils Package\n</code></pre>"},{"location":"data-tools/cray-r/#running-r-on-the-compute-nodes","title":"Running R on the compute nodes","text":"<p>In this section, we provide an example R job submission scripts for using R on the ARCHER2 compute nodes.</p>"},{"location":"data-tools/cray-r/#serial-r-submission-script","title":"Serial R submission script","text":"<pre><code>#!/bin/bash --login\n\n#SBATCH --job-name=r_test\n#SBATCH --ntasks=1\n#SBATCH --time=00:10:00\n\n# Replace [budget code] below with your project code (e.g., t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=serial\n#SBATCH --qos=serial\n\n# Load the R module\nmodule load cray-R\n\n# Run your R progamme\nRscript serial_test.R\n</code></pre> <p>On completion, the output of the R script will be available in the job output file.</p>"},{"location":"data-tools/julia/","title":"Julia","text":"<p>Julia is a general purpose software used widely in datascience and for data visualisation.</p> <p>Important</p> <p>This documentation is provided by an external party (i.e. not by the ARCHER2 service itself). Julia is not part of the officially supported software on ARCHER2. While the ARCHER2 service desk is able to provide support for basic use of this software (e.g. access to software, writing job submission scripts) it does not generally provide detailed technical support for the software and you may be directed to seek support from other places if the service desk cannot answer the questions.</p>"},{"location":"data-tools/julia/#first-time-installation","title":"First time installation","text":"<p>Note</p> <p>There is no centrally installed version of Julia, so you will have to manually install it and any packages you may need. The following guide was tested on julia-1.6.6.</p> <p>You will first need to download Julia into your work directory and untar the folder. You should then add the folder to your system path so you can use the <code>julia</code> executable. Finally, you need to tell Julia to install any packages in the work directory as opposed to the default home directory,  which can only be accessed from the login nodes. This can be done with the following code</p> <pre><code>export WORK=/work/t01/t01/auser\ncd $WORK\n\nwget https://julialang-s3.julialang.org/bin/linux/x64/1.6/julia-1.6.6-linux-x86_64.tar.gz\ntar zxvf julia-1.6.6-linux-x86_64.tar.gz\nrm ./julia-1.6.6-linux-x86_64.tar.gz\n\nexport PATH=\"$PATH:$WORK/julia-1.6.6/bin\"\n\nmkdir ./.julia\nexport JULIA_DEPOT_PATH=\"$WORK/.julia\"\nexport PATH=\"$PATH:$WORK/$JULIA_DEPOT_PATH/bin\"\n</code></pre> <p>At this point you should have a working installation of Julia! The environment variables will however be cleared when you log out of the terminal. You can set them in the <code>.bashrc</code> file so that they're automatically defined every time you log in by adding the following lines to the end of the file <code>~/.bashrc</code></p> <pre><code>export WORK=\"/work/t01/t01/auser\"\nexport JULIA_DEPOT_PATH=\"$WORK/.julia\"\nexport PATH=\"$PATH:$WORK/julia-1.6.6/bin\"\nexport PATH=\"$PATH:$JULIA_DEPOT_PATH/bin\"\n</code></pre>"},{"location":"data-tools/julia/#installing-packages-and-using-environments","title":"Installing packages and using environments","text":"<p>Julia has a built in package manager which can be used to install registered packages quickly and easily. Like with many other high level programming languages we can make use of environments to control dependencies etc.</p> <p>To make an environment, first navigate to where you want your environment to be (ideally a subfolder of your <code>/work/</code> directory) and create an empty folder to store the environment in. Then launch Julia with the --project flag.</p> <pre><code>cd $WORK\nmkdir ./MyTestEnv\njulia --project=$WORK/MyTestEnv\n</code></pre> <p>This launches Julia in the <code>MyTestEnv</code> environment. You can then install packages as usual using the normal commands in the Julia terminal. E.g.</p> <pre><code>using Pkg\nPkg.add(\"Oceananigans\")\n</code></pre>"},{"location":"data-tools/julia/#configuring-mpijl","title":"Configuring MPI.jl","text":"<p>The <code>MPI.jl</code> package doesn't use the system MPICH implementation by default. You can set it up to do this by following the steps below. First you will need to load the <code>cray-mpich</code> module and define some environment variables (see here for further details). Then you can launch Julia in an environment of your choice, ready to build.</p> <pre><code>module load cray-mpich/8.1.4\nexport JULIA_MPI_BINARY=\"system\"\nexport JULIA_MPI_PATH=\"\"\nexport JULIA_MPI_LIBRARY=\"/opt/cray/pe/mpich/8.1.4/ofi/cray/9.1/lib/libmpi.so\"\nexport JULIA_MPIEXEC=\"srun\"\n\njulia --project=&lt;&lt;path to environment&gt;&gt;\n</code></pre> <p>Once in the Julia terminal you can build the <code>MPI.jl</code> package using the following code. The final line installs the <code>mpiexecjl</code> command which should be used instead of <code>srun</code> to launch mpi processes.</p> <p><pre><code>using Pkg\nPkg.build(\"MPI\"; verbose=true)\nMPI.install_mpiexecjl(command = \"mpiexecjl\", force = false, verbose = true)\n</code></pre> The <code>mpiexecjl</code> command will be installed in the directory that <code>JULIA_DEPOT_PATH</code> points too.</p> <p>Note</p> <p>You only need to do this once per environment.</p>"},{"location":"data-tools/julia/#running-julia-on-the-compute-nodes","title":"Running Julia on the compute nodes","text":"<p>Below is an example script for running Julia with mpi on the compute nodes</p> <pre><code>#!/bin/bash\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=&lt;&lt;job-name&gt;&gt;\n#SBATCH --time=00:19:00\n\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=24\n#SBATCH --cpus-per-task=1\n\n#SBATCH --qos=short\n#SBATCH --reservation=shortqos\n\n#SBATCH --account=&lt;&lt;your account&gt;&gt;\n#SBATCH --partition=standard\n\n# Setup the job environment (this module needs to be loaded before any other modules)\nmodule load PrgEnv-cray\nmodule load cray-mpich/8.1.4\n\n# Set the number of threads to 1\n#   This prevents any threaded system libraries from automatically\n#   using threading.\nexport OMP_NUM_THREADS=1\nexport JULIA_NUM_THREADS=1\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Define some paths\nexport WORK=/work/t01/t01/auser\n\nexport JULIA=\"$WORK/julia-1.6.6/bin/julia\"  # The julia executable\nexport PATH=\"$PATH:$WORK/julia-1.6.6/bin\"  # The folder of the julia executable\nexport JULIA_DEPOT_PATH=\"$WORK/.julia\"\nexport MPIEXECJL=\"$JULIA_DEPOT_PATH/bin/mpiexecjl\"  # The path to the mpiexexjl executable\n\n$MPIEXECJL --project=$WORK/MyTestEnv -n 24 $JULIA ./MyMpiJuliaScript.jl\n</code></pre> <p>The above script uses MPI but you can also use multithreading instead by setitng the <code>JULIA_NUM_THREADS</code> environment variable.</p>"},{"location":"data-tools/papi-mpi-lib/","title":"PAPI MPI Library","text":"<p>The Performance Application Programming Interface (PAPI) is an API that facilitates the  reading of performance counter data without needing to know the details of the underlying hardware. </p> <p>For convenience, we have developed an MPI-based wrapper for PAPI, called <code>papi_mpi_lib</code>, which can be found via the link below.</p> <p>https://github.com/cresta-eu/papi_mpi_lib</p> <p>The PAPI MPI Library makes it possible to monitor a user-defined set of hardware performance counters during the execution of an MPI code running across multiple compute nodes. The library is lightweight, containing just four functions, and is intended to be straightforward to use. Once you've decided where in your code you wish to record counter values, you can control which counters are read at runtime by setting the <code>PAT_RT_PERFCTR</code> environment variable in the job submission script. As your code executes, the specified counters will be read at various points. After each reading, the counter values are summed by rank 0 (via an MPI reduction) before being output to a log file.</p> <p>You can discover which counters are available on ARCHER2 compute nodes by submitting the following single node job.</p> <pre><code>#!/bin/bash --login\n\n#SBATCH -J papi\n#SBATCH --time=00:20:00\n#SBATCH --exclusive\n#SBATCH --nodes=1\n#SBATCH --tasks-per-node=1\n#SBATCH --cpus-per-task=1\n#SBATCH --account=&lt;budget code&gt;\n#SBATCH --partition=standard\n#SBATCH --qos=short\n#SBATCH --export=none\n\nfunction papi_query() {\nexport LD_LIBRARY_PATH=/opt/cray/pe/papi/$2/lib64:/opt/cray/libfabric/$3/lib64\n  module -q restore\n\n  module -q load cpe/$1\nmodule -q load papi/$2\n\nmkdir -p $1\npapi_component_avail -d &amp;&gt; $1/papi_component_avail.txt\n  papi_native_avail -c &amp;&gt; $1/papi_native_avail.txt\n  papi_avail -c -d &amp;&gt; $1/papi_avail.txt\n}\n\npapi_query 22.12 6.0.0.17 1.12.1.2.2.0.0\n</code></pre> <p>The job runs various <code>papi</code> commands with the output being directed to specific text files. Please consult the text files to see which counters are available. Note, counters that are not available may still be listed in the file, but with a label such as <code>&lt;NA&gt;</code>.</p> <p>As of July 2023, the Cray Programming Environment (CPE), PAPI and libfabric versions on ARCHER2, were <code>22.12</code>, <code>6.0.0.17</code> and <code>1.12.1.2.2.0.0</code> respectively; these versions may change in the future.</p> <p>Alternatively, you can run <code>pat_help counters rome</code> from a login node to check the availability of individual counters.</p> <p>Further information on <code>papi_mpi_lib</code> along with test harnesses and example scripts can be found by reading the PAPI MPI Library readme file.</p>"},{"location":"data-tools/paraview/","title":"ParaView","text":"<p>ParaView ParaView is a data visualisation and analysis package. Whilst ARCHER2 compute or login nodes do not have graphics cards installed  in them paraview is installed so the visualisation libraries and applications  can be used to post-process simulation data. The ParaView server (<code>pvserver</code>), batch application (<code>pvbatch</code>) and the Python interface (<code>pvpython</code>) are all available. Users are able to run the server on the compute nodes and connect to a local ParaView client running on their own computer.</p>"},{"location":"data-tools/paraview/#useful-links","title":"Useful links","text":"<ul> <li>Paraview webpage</li> <li>ParaView quick-start guide</li> </ul>"},{"location":"data-tools/paraview/#using-paraview-on-archer2","title":"Using ParaView on ARCHER2","text":"<p>ParaView is available through the <code>paraview</code> module.</p> <pre><code>module load paraview\n</code></pre> <p>Once the module has been added the ParaView executables, tools,  and libraries will be able available.</p>"},{"location":"data-tools/paraview/#connecting-to-pvserver-on-archer2","title":"Connecting to pvserver on ARCHER2","text":"<p>For doing visualisation you should connect to pvserver from a local paraview client running on your own computer.</p> <p>Note</p> <p>You should make sure the version of ParaView you have installed locally is the same as  the one on ARCHER2 (version 5.10.1).</p> <p>The following instructions are for running pvserver in an interactive job.  Start an iteractive job using:</p> <pre><code>srun --nodes=1 --exclusive --time=00:20:00 \\\n               --partition=standard --qos=short --reservation=shortqos \\\n               --pty /bin/bash\n</code></pre> <p>Once the job starts the command prompt will change to show you are now on the compute node e.g.</p> <pre><code>auser@nid001023:/work/t01/t01/auser&gt; \n</code></pre> <p>Then load the ParaView module and start pvserver with the srun command,</p> <pre><code>auser@nid001023:/work/t01/t01/auser&gt; module load paraview\nauser@nid001023:/work/t01/t01/auser&gt; srun --overlap --oversubscribe -n 4 pvserver --mpi --force-offscreen-rendering\nWaiting for client...\nConnection URL: cs://nid001023:11111\nAccepting connection(s): nid001023:11111\n</code></pre> <p>In a separate terminal you can now set up an ssh tunnel with the node ID and port number which the pvserver is using, e.g.</p> <pre><code>ssh -L 11111:nid001023:11111 auser@login.archer2.ac.uk \n</code></pre> <p>enter your password and phasephrase as usual.</p> <p>You can then connect from your local client using the following connection settings:</p> <pre><code>Name:           archer2 \nServer Type:    Client/Server \nHost:           localhost \nPort:           11111\n</code></pre> <p>Note</p> <p>The Host from the local client should be set to \"localhost\" when using the ssh tunnel. The \"Name\" field can be set to a name of your choosing.  11111 is the default port for pvserver.</p> <p>If it has connected correctly you should see the following:</p> <pre><code>Waiting for client...\nConnection URL: cs://nid001023:11111\nAccepting connection(s): nid001023:11111\nClient connected.\n</code></pre>"},{"location":"data-tools/paraview/#using-batch-mode-pvbatch","title":"Using batch-mode (pvbatch)","text":"<p>A pvbatch script can be run in a standard job script. For example the following will run on a single node:</p> <pre><code>#!/bin/bash\n\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=example_paraview_job\n#SBATCH --time=0:20:00\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n\n# Replace [budget code] below with your budget code (e.g. t01)\n#SBATCH --account=[budget code]             \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\nmodule load paraview\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nsrun --distribution=block:block --hint=nomultithread pvbatch pvbatchscript.py\n</code></pre>"},{"location":"data-tools/paraview/#compiling-paraview","title":"Compiling ParaView","text":"<p>The latest instructions for building ParaView on ARCHER2 may be found in the GitHub repository of build instructions:</p> <ul> <li>Build instructions for Paraview on      GitHub</li> </ul>"},{"location":"data-tools/pm-mpi-lib/","title":"Power Management MPI Library","text":"<p>The ARCHER2 compute nodes each have a set of so-called Power Management (PM) counters. These cover point-in-time power readings for the whole node, and for the CPU and memory domains. The accumulated energy use is also recorded at the same level of detail. Further, there are two temperature counters, one for each socket/processor on the node. The counters are read ten times per second and the data written to a set of files stored within node memory (located at <code>/sys/cray/pm_counters/</code>).</p> <p>For convenience, we have developed an MPI-based wrapper, called <code>pm_mpi_lib</code> that facilitates the reading of the PM counter files, see the link below.</p> <p>https://github.com/cresta-eu/pm_mpi_lib</p> <p>The PM MPI Library makes it possible to monitor the Power Management counters during the execution of an MPI code running across multiple compute nodes. The library is lightweight, containing just three functions, and is intended to be straightforward to use. You simply decide which parts of your code you wish to profile as regards energy usage and/or power consumption.</p> <p>As your code executes, the PM counters will be read at various points by a single designated monitor rank on each node assigned to the job. These readings are then written to a log file, which, after the job completes, will contain one set of time-stamped readings per node for every call to the <code>pm_mpi_record</code> function made from within your code. The readings can then be aggregated according to preference.</p> <p>Further information along with test harnesses and example scripts can be found by reading the PM MPI Library readme file.</p>"},{"location":"data-tools/visidata/","title":"VisiData","text":"<p>VisiData is an interactive multitool for tabular data. It combines the clarity of a spreadsheet, the efficiency of the terminal, and the power of Python, into a lightweight utility which can handle millions of rows with ease.</p>"},{"location":"data-tools/visidata/#useful-links","title":"Useful links","text":"<ul> <li>VisiData online tutorial</li> <li>10 ways to use VisiData</li> <li>VisiData documentation</li> <li>Using VisiData to analyse HPC code performance:    The ARCHER2 /Understanding Package Performance/ course uses VisiData to analyse the   performance of an HPC application.</li> </ul>"},{"location":"data-tools/visidata/#visidata-on-archer2","title":"VisiData on ARCHER2","text":"<p>You can access VisiData on ARCHER2 by loading the <code>visidata</code> module:</p> <pre><code>module load visidata\n</code></pre> <p>Once the module has been loaded, VisiData is available via the <code>vd</code> command.</p> <p>Visidata can also be used in scripts by saving a command log and replaying it. See the VisiData documentation on saving and restoring VisiData sessions.</p>"},{"location":"essentials/","title":"Essential Skills","text":"<p>This section provides information and links on essential skills required to use ARCHER2 efficiently: e.g. using Linux command line, accessing help and documentation.</p>"},{"location":"essentials/#terminal","title":"Terminal","text":"<p>In order to access HPC machines such as ARCHER2 you will need to use a Linux command line terminal window</p> <p>Options for Linux, MacOS and Windows are described under our Connecting to ARCHER2 guide</p>"},{"location":"essentials/#linux-command-line","title":"Linux Command Line","text":"<p>A guide to using the Unix Shell for complete novices</p> <p>For those already familiar with the basics there is also a lesson on shell extras</p>"},{"location":"essentials/#basic-slurm-commands","title":"Basic Slurm commands","text":"<p>Slurm is the scheduler used on ARCHER2 and we provide a guide to using the basic Slurm commands including how to find out:</p> <ul> <li>what resources are available to you </li> <li>how to submit jobs to the scheduler  </li> <li>the status of jobs submitted</li> </ul>"},{"location":"essentials/#text-editors","title":"Text Editors","text":"<p>The following text editors are available on ARCHER2</p> Name Description Examples emacs A widely used editor  with a focus on extensibility. <code>emacs    -nw    sharpen.pbs</code> <code>CTRL+X CTRL+C</code> quits   <code>CTRL+X CTRL+S</code> saves nano A small, free editor  with a focus on user friendliness. <code>nano sharpen.pbs</code> <code>CTRL+X</code> quits  <code>CTRL+O</code> saves vi A mode based editor  with a focus on aiding code development. <code>vi cfd.f90</code> <code>:q</code> in command mode quits   <code>:q!</code> in command mode quits without saving  <code>:w</code> in command mode saves   <code>i</code> in command mode switches to insert mode   <code>ESC</code> in insert mode switches to command mode <p>If you are using MobaXterm on Windows you can use the inbuilt MobaTextEditor text file editor.</p> <p>You can edit on your local machine using your preferred text editor, and then upload the file to ARCHER2.  Make sure you can save the file using Linux line-endings. Notepad, for example, will support Unix/Linux line endings (LF), Macintosh line endings (CR), and Windows Line endings (CRLF) </p>"},{"location":"essentials/#quick-reference-sheet","title":"Quick Reference Sheet","text":"<p>We have produced this Quick Reference Sheet which you may find useful.</p>"},{"location":"faq/","title":"ARCHER2 Frequently Asked Questions","text":"<p>This section documents some of the questions raised to the Service Desk on ARCHER2, and the advice and solutions.</p>"},{"location":"faq/#user-accounts","title":"User accounts","text":""},{"location":"faq/#username-already-in-use","title":"Username already in use","text":"<p>Q. I created a machine account on ARCHER2 for a training course, but now I want to use that machine username for my main ARCHER2 project, and the system will not let me, saying \"that name is already in use\".  How can I re-use that username.</p> <p>A.  Send an email to the service desk, letting us know the username and project that you set up previously, and asking for that account and any associated data to be deleted.  Once deleted, you can then re-use that username to request an account in your main ARCHER2 project.</p>"},{"location":"faq/#data","title":"Data","text":""},{"location":"faq/#undeleteable-file-nfsxxxxxxxxxxx","title":"Undeleteable file .nfsXXXXXXXXXXX","text":"<p>Q.  I have a file called .nfsXXXXXXXXXXX (where XXXXXXXXXXX is a long hexadecimal string) in my /home folder but I can't delete it.</p> <p>A. This file will have been created during a file copy which failed.  Trying to delete it will give an error \"Device or resource busy\", even though the copy has ended and no active task is locking it.</p> <p><code>echo -n &gt;.nfsXXXXXXXXXXX</code></p> <p>will remove it.</p>"},{"location":"faq/#running-on-archer2","title":"Running on ARCHER2","text":""},{"location":"faq/#oom-error-on-archer2","title":"OOM error on ARCHER2","text":"<p>Q. Why is my code failing on ARCHER2 with an out of memory (OOM) error?</p> <p>A. You are requesting too much memory per process. We recommend that you try running the same job on underpopulated nodes. This can be done by editing reducing the <code>--ntasks-per-node</code> in your Slurm submission script. Please lower it to half of its value when it fails (so if you have <code>--ntasks-per-node=128</code>, reduce it to <code>--ntasks-per-node=64</code>).</p>"},{"location":"faq/#checking-budgets","title":"Checking budgets","text":"<p>Q.  How can I check which budget code(s) I can use?</p> <p>A.  You can check in SAFE by selecting <code>Login accounts</code> from the menu, select the login account you want to query.</p> <p>Under <code>Login account details</code> you will see each of the budget codes you have access to listed e.g. <code>e123 resources</code> and then under Resource Pool to the right of this, a note of the remaining budget.</p> <p>When logged in to the machine you can also use the command</p> <pre><code>sacctmgr show assoc where user=$LOGNAME format=user,Account%12,MaxTRESMins,QOS%40\n</code></pre> <p>This will list all the budget codes that you have access to (but not the amount of budget available) e.g.</p> <pre><code>    User      Account  MaxTRESMins                                 QOS\n-------- ------------ ------------ -----------------------------------\n   userx    e123-test                   largescale,long,short,standard\n   userx         e123        cpu=0      largescale,long,short,standard\n</code></pre> <p>This shows that <code>userx</code> is a member of budgets <code>e123-test</code> and <code>e123</code>.  However, the <code>cpu=0</code> indicates that the <code>e123</code> budget is empty or disabled.   This user can submit jobs using the <code>e123-test</code> budget.</p> <p>You can only check the amount of available budget via SAFE - see above.</p>"},{"location":"faq/#estimated-start-time-of-queued-jobs","title":"Estimated start time of queued jobs","text":"<p>Q.  I\u2019ve checked the estimated start time for my queued jobs using \u201csqueue -u $USER --start\u201d. Why does the estimated start time keep changing?</p> <p>A.  ARCHER2 uses the Slurm scheduler to queue jobs for the compute nodes. Slurm attempts to find a better schedule as jobs complete and new jobs are added to the queue. This helps to maximise the use of resources by minimising the number of idle compute nodes, in turn reducing your wait time in the queue.  </p> <p>However, If you periodically check the estimated start time of your queued jobs, you may notice that the estimate changes or even disappears. This is because Slurm only assigns the top entries in the queue with an estimated start time. As the schedule changes, your jobs could move in and out of this top region and thus gain or lose an estimated start time.</p>"},{"location":"faq/network-upgrade-2023/","title":"ARCHER2 data centre network upgrade: 2023","text":"<p>During September 2023 the data centre that houses ARCHER2 will be undergoing a  major network upgrade.</p> <p>On this page we describe the impact this will have and links to further information.</p> <p>If you have any questions or concerns, please contact the ARCHER2 Service Desk.</p>"},{"location":"faq/network-upgrade-2023/#when-will-the-upgrade-happen-and-how-long-will-it-take","title":"When will the upgrade happen and how long will it take?","text":""},{"location":"faq/network-upgrade-2023/#the-outage-dates-will-be","title":"The outage dates will be:","text":"<ul> <li>Start:  Monday 18th September 2023  09:00</li> <li>Scheduled End:  Friday 22nd September 2023</li> </ul> <p>We will notify users if we are able to complete this work ahead of schedule and restore  ARCHER2 access earlier than expected.</p>"},{"location":"faq/network-upgrade-2023/#what-are-the-impacts-on-users-from-the-upgrade","title":"What are the impacts on users from the upgrade?","text":""},{"location":"faq/network-upgrade-2023/#during-the-upgrade-process","title":"During the upgrade process","text":"<ul> <li>No login access</li> <li>No access to any data on the system for users</li> <li>User jobs will continue to run during the upgrade process - we provide more information on this below</li> <li>SAFE will be available during the outage - there will be reduced functionality due to the unavailability of the connection to ARCHER2 such as resetting of passwords or new account creation. </li> </ul>"},{"location":"faq/network-upgrade-2023/#submitting-new-work-and-running-work","title":"Submitting new work, and running work","text":"<ul> <li>With no login access, it will not be possible to submit new jobs to the queues</li> <li>Jobs will continue to run, and queued jobs will be started as usual</li> <li>Serial QoS will not be available. However, serial jobs can be submitted using the standard and low-priority queues.</li> </ul> <p>We will therefore be encouraging users to submit jobs in the period prior to the work, so that your work can continue on the system during the upgrade process.</p>"},{"location":"faq/network-upgrade-2023/#relaxing-of-queue-limits","title":"Relaxing of queue limits","text":"<p>In preparation for the Data Centre Network (DCN) upgrade we have relaxed the queue limits on all the QoS\u2019s, so that users can submit a significantly larger number of jobs to ARCHER2. These changes are intended to allow users to submit jobs that they wish to run during the upgrade, in advance of the start of the upgrade. The changes will be in place until the end of the Data Centre Network upgrade.</p> <p>For the low priority QoS, as well as relaxing the number of jobs you can submit, we have also increased the maximum job length to 48 hours and the maximum number of nodes per job to 5,860, so users can submit using their own allocation or using the low-priority QoS.</p> <p>Can we encourage users to make use of these changes, this is a good opportunity for users to queue and run a greater number of jobs than usual. The relaxation of limits on the low-priority queue also offers an opportunity to run a wider range of jobs through this queue than is normally possible.</p> <p>Due to the unavailability of the DCN, users will not be able to connect to ARCHER2 via the login nodes during the upgrade. The serial QoS will be disabled during the upgrade period. However, serial jobs can be submitted using the standard and low-priority queues.</p>"},{"location":"faq/upgrade-2023/","title":"ARCHER2 Upgrade: 2023","text":"<p>During the first half of 2023 ARCHER went through a major software upgrade.</p> <p>On this page we describe the background to the changes what impact the changes have had for users, any action you should expect to take following the upgrade and information on the versions on updated software.</p> <p>If you have any questions or concerns, please contact the ARCHER2 Service Desk.</p>"},{"location":"faq/upgrade-2023/#why-did-the-upgrade-happen","title":"Why did the upgrade happen?","text":"<p>There are a number of reasons why ARCHER2 needed to go through this major software upgrade. All of these reasons are related to the fact that the previous system software setup was out of date; due to this, maintenance of the service was very difficult and updating software within the current framework was not possible. Some specific issues were:</p> <ul> <li>Ongoing access to security updates -- the vendor (HPE) could not provide support for    security updates for the previous system software on ARCHER2 indefinitely, this would have    been an issue if we had continued with the previous release.</li> <li>Improvements to interconnect reliability and performance -- the Slingshot interconnect    that links compute nodes together and to the high-performance Lustre file systems    was running an old version of management software that had a number of known    limitations and bugs. These affected our ability to monitor the health of the interconnect    and led to reliability issues for calculations using large numbers of compute nodes.    Without the major system software upgrade, we could not move to an up to date version of the    Slingshot software that addressed these limitations.</li> <li>Improvements to upgradeability, maintainability and monitoring -- the previous system software    was based on a collection of early versions from the hardware vendor that did not provide    the system health monitoring characteristics of more recent versions or the ability to    flexibly update the system with low impact on user service that were available in more     recent versions.</li> <li>Access to more recent compilers, software libraries and tools -- the previous system    software did not provide the ability to access improvements in compilers and libraries    (both bug fixes and performance improvements) that were available from HPE.</li> </ul>"},{"location":"faq/upgrade-2023/#when-did-the-upgrade-happen-and-how-long-did-it-take","title":"When did the upgrade happen and how long did it take?","text":"<p>This major software upgrade involved a complete re-install of system software followed by a reinstatement of local configurations (e.g. Slurm, authentication services, SAFE integration). Unfortunately, this major work required a long period of downtime but this was planned with all service partners to minimise the outage and give as much notice to users as possible so that they could plan accordingly.</p> <p>The outage dates were:</p> <ul> <li>Start: 14:00 BST, Fri 19th May 2023</li> <li>End: 12:00 BST, Mon 12th June 2023</li> </ul>"},{"location":"faq/upgrade-2023/#what-are-the-impacts-on-users-from-the-upgrade","title":"What are the impacts on users from the upgrade?","text":""},{"location":"faq/upgrade-2023/#during-the-upgrade-process","title":"During the upgrade process","text":"<ul> <li>No login access</li> <li>No access to any data on the system</li> <li>Some of the SAFE functionality will be removed during the upgrade such as user account requests</li> </ul>"},{"location":"faq/upgrade-2023/#after-the-upgrade-process","title":"After the upgrade process","text":"<p>The allocation periods (where appropriate) were extended for the outage period. The changes were in place when the service was returned.</p> <p>After the upgrade process there are a number of changes that may require action from users</p>"},{"location":"faq/upgrade-2023/#updated-login-node-host-keys","title":"Updated login node host keys","text":"<p>If you previously logged into the ARCHER2 system before the upgrade you may see an error from SSH that looks like:</p> <pre><code>@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@       WARNING: POSSIBLE DNS SPOOFING DETECTED!          @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nThe ECDSA host key for login.archer2.ac.uk has changed,\nand the key for the corresponding IP address 193.62.216.43\nhas a different value. This could either mean that\nDNS SPOOFING is happening or the IP address for the host\nand its host key have changed at the same time.\nOffending key for IP in /Users/auser/.ssh/known_hosts:11\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\nIt is also possible that a host key has just been changed.\nThe fingerprint for the ECDSA key sent by the remote host is\nSHA256:UGS+LA8I46LqnD58WiWNlaUFY3uD1WFr+V8RCG09fUg.\nPlease contact your system administrator.\n</code></pre> <p>If you see this, you should delete the offending host key from your ~/.ssh/known_hosts file (in the example above the offending line is line #11).</p> <p>The current login node host keys are always documented in the User Guide</p>"},{"location":"faq/upgrade-2023/#recompile-and-test-software","title":"Recompile and test software","text":"<p>As the new system is based on a new OS version and new versions of compilers and libraries we strongly recommend that all users recompile and test all software on the service. The ARCHER2 CSE service recompiled all centrally installed software.</p>"},{"location":"faq/upgrade-2023/#no-python-2-installation","title":"No Python 2 installation","text":"<p>There is no Python 2 installation available as part of supported software following the upgrade. Python 3 continues to be fully-supported.</p>"},{"location":"faq/upgrade-2023/#impact-on-data-on-the-service","title":"Impact on data on the service","text":"<ul> <li>No data in /home, /work, NVMe or RDFaaS was removed or moved as part of the upgrade</li> </ul>"},{"location":"faq/upgrade-2023/#slurm-cpus-per-task-setting-no-longer-inherited-by-srun","title":"Slurm: cpus-per-task setting no longer inherited by <code>srun</code>","text":"<p>Change in Slurm behaviour. The setting from the <code>--cpus-per-task</code> option to sbatch/salloc is no longer propagated by default to <code>srun</code> commands in the job script.</p> <p>This can lead to very poor performance due to oversubscription of cores with processes/threads if job submission scripts are not updated. The simplest workaround is to add the command:</p> <pre><code>export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n</code></pre> <p>before any srun commands in the script. You can also explicitly use the <code>--cpus-per-task</code> option to srun if you prefer.</p>"},{"location":"faq/upgrade-2023/#change-of-slurm-socket-definition","title":"Change of Slurm \"socket\" definition","text":"<p>This change only affects users who use a placement scheme where placement of processes on sockets is cyclic (e.g. <code>--distribution=block:cyclic</code>). The Slurm definition of a \u201csocket\u201d has changed. The previous setting on ARCHER2 was that a socket = 16 cores (all share a DRAM memory controller). On the updated ARCHER2, the setting of a socket = 4 cores (corresponding to a CCX - Core CompleX). Each CCX shares 16 MB L3 Cache.</p>"},{"location":"faq/upgrade-2023/#changes-to-bind-paths-and-library-paths-for-singularity-with-mpi","title":"Changes to bind paths and library paths for Singularity with MPI","text":"<p>The paths you need to bind and the <code>LD_LIBRARY_PATH</code> settings required to use Cray MPICH with MPI  in Singularity containers have changed. The updated settings are documented in the Containers section of the User and Best Practice Guide. This also includes updated information on building containers with MPI to use on ARCHER2.</p>"},{"location":"faq/upgrade-2023/#amd-prof-not-available","title":"AMD \u03bcProf not available","text":"<p>The AMD \u03bcProf tool is not available on the upgraded system yet. We are working to get this  fixed as soon as possible.</p>"},{"location":"faq/upgrade-2023/#what-software-versions-will-be-available-after-the-upgrade","title":"What software versions will be available after the upgrade?","text":"<p>System software:</p> <ul> <li>Base operating system<ul> <li>Compute nodes: Cray OS (COS) 2.4.109 based on SLES 15 SP4</li> <li>Login nodes: UAN 2.5.8 based on SLES 15 SP4</li> </ul> </li> <li>Slingshot interconnect system software: 2.0.2</li> <li>HPE Cray Management Software (CMS): 1.3.1</li> <li>ARCHER2 CSE supported software</li> </ul>"},{"location":"faq/upgrade-2023/#programming-environment-2212","title":"Programming environment: 22.12","text":"<p>Compilers:</p> <ul> <li>CCE: 15.0.0</li> <li>GCC: 11.2.0 (10.3.0 also available)</li> <li>AOCC: 3.2</li> </ul> <p>Communication libraries:</p> <ul> <li>Cray MPICH: 8.1.23 <ul> <li>Based on MPICH 3.4a2</li> <li>Supports OpenFabrics (OFI) and UCX</li> </ul> </li> <li>Cray OpenSHMEMX: 11.5.7</li> </ul> <p>Numerical libraries:</p> <ul> <li>Cray LibSci: 22.12.1.1</li> <li>FFTW: 3.3.10.3</li> </ul> <p>IO Libraries:</p> <ul> <li>HDF5: 1.12.2.1</li> <li>NetCDF: 4.9.0.1</li> <li>Parallel NetCDF: 1.12.3.1</li> </ul> <p>Tools:</p> <ul> <li>Python: 3.9.13.1<ul> <li>numpy: 1.21.5</li> <li>scipy: 1.6.2</li> <li>mpi4py: 3.1.3</li> <li>dask: 2022.2.1</li> </ul> </li> <li>R: 4.2.1.1</li> <li>CrayPAT/Perftools: 22.12.0</li> <li>gdb4hpc: 4.14.6</li> <li>valgrind4hpc: 2.12.10</li> <li>sanitizers4hpc: 1.0.4</li> <li>Lmod: 3.1.4</li> </ul>"},{"location":"faq/upgrade-2023/#summary-of-user-and-application-impact-of-pe-software","title":"Summary of user and application impact of PE software","text":"<p>For full information, see CPE 22.12 Release Notes</p> <p>CCE 15</p> <p>C++ applications built using CCE 13 or earlier should be recompiled due to the significant changes that were necessary to implement C++17.  This is expected to be a one-time requirement.</p> <p>Some non-standard Cray Fortran extensions supporting shorthand notation for logical operations will be removed in a future release.  CCE 15 will issue warning messages when these are encountered, providing time to adapt the application to use standard Fortran.  </p> <p>HPE Cray MPICH 8.1.23</p> <p>Cray MPICH 8.1.23 can support only ~2040 simultaneous MPI communicators.</p>"},{"location":"faq/upgrade-2023/#cse-supported-software","title":"CSE supported software","text":"<p>Default version in italics</p> Software Versions CASTEP 22.11, 23.11 Code_Saturne 7.0.1 ChemShell/PyChemShell 3.7.1/21.0.3 CP2K 2023.1 FHI-aims 221103 GROMACS 2022.4 LAMMPS 17_FEB_2023 NAMD 2.14 Nektar++ 5.2.0 NWChem 7.0.2 ONETEP 6.9.1.0 OpenFOAM v10.20230119 (.org), v2212 (.com) Quantum Espresso 6.8, 7.1 VASP 5.4.4.pl2, 6.3.2, 6.4.1-vtst, 6.4.1 Software Versions AOCL 3.1, 4.0 Boost 1.81.0 GSL 2.7 HYPRE 2.18.0, 2.25.0 METIS/ParMETIS 5.1.0/4.0.3 MUMPS 5.3.5, 5.5.1 PETSc 13.14.2, 13.18.5 PT/Scotch 6.1.0, 07.0.3 SLEPC 13.14.1, 13.18.3 SuperLU/SuperLU_Dist 5.2.2 / 6.4.0, 8.1.2 Trilinos 12.18.1"},{"location":"known-issues/","title":"ARCHER2 Known Issues","text":"<p>This section highlights known issues on ARCHER2, their potential impacts and any known workarounds. Many of these issues are under active investigation by HPE Cray and the wider service.</p> <p>Info</p> <p>This page was last reviewed on 20 July 2023</p>"},{"location":"known-issues/#open-issues","title":"Open Issues","text":""},{"location":"known-issues/#excessive-memory-use-when-using-ucx-communications-protocol-added-2023-07-20","title":"Excessive memory use when using UCX communications protocol (Added: 2023-07-20)","text":"<p>We have seen cases when using the (non-default) UCX communications protocol where the peak in memory use is much higher than would be expected. This leads to jobs failing unexpectedly with an OOM (Out Of Memory) error. The workaround is to use Open Fabrics (OFI) communication protocol instead. OFI is the default protocol on  ARCHER2 and so does not usually need to be explicitly loaded; but if you have UCX loaded, you can switch to OFI by adding the following lines to your submission script before you run your application:</p> <pre><code>module load craype-network-ofi\nmodule load cray-mpich\n</code></pre> <p>It can be very useful to track the memory usage of your job as it runs, for example to see whether there is high usage on all nodes, or a single node, if usage increases gradually or rapidly etc.</p> <p>Here are instructions on how to do this using a couple of small scripts.</p>"},{"location":"known-issues/#slurm-cpu-freqx-option-is-not-respected-when-used-with-sbatch-added-2023-01-18","title":"Slurm <code>--cpu-freq=X</code> option is not respected when used with <code>sbatch</code> (Added: 2023-01-18)","text":"<p>If you specify the CPU frequency using the <code>--cpu-freq</code> option with the <code>sbatch</code> command (either using the script <code>#SBATCH --cpu-freq=X</code> method or the <code>--cpu-freq=X</code> option directly) then this option will not be respected as the default setting for ARCHER2 (2.0 GHz) will override the option. You should specify the <code>--cpu-freq</code> option to <code>srun</code> directly instead within the job submission script. i.e.:</p> <pre><code>srun --cpu-freq=2250000 ...\n</code></pre> <p>You can find more information on setting the CPU frequency in the User Guide.</p>"},{"location":"known-issues/#research-software","title":"Research Software","text":"<p>There are several outstanding issues for the centrally installed Research Software:</p> <ul> <li>PLUMED is not yet available. Currently, we recommend affected users to install a local version of the software.</li> </ul> <p>Users should also check individual software pages, for known limitations/ caveats, for the use of software on the Cray EX platform and Cray Linux Environment.</p>"},{"location":"known-issues/#issues-with-rpath-for-non-default-library-versions","title":"Issues with RPATH for non-default library versions","text":"<p>When you compile applications against non-default versions of libraries within the HPE Cray software stack and use the environment variable <code>CRAY_ADD_RPATH=yes</code> to try and encode the paths to these libraries within the binary this will not be respected at runtime and the binaries will use the default versions instead.</p> <p>The workaround for this issue is to ensure that you set:</p> <pre><code>export LD_LIBRARY_PATH=$CRAY_LD_LIBRARY_PATH:$LD_LIBRARY_PATH\n</code></pre> <p>at both compile and runtime. For more details on using non-default versions of libraries, see the description in the User and Best Practice Guide</p>"},{"location":"known-issues/#mpi-ucx-error-ivb_reg_mr","title":"MPI <code>UCX ERROR: ivb_reg_mr</code>","text":"<p>If you are using the UCX layer for MPI communication you may see an error such as:</p> <pre><code>[1613401128.440695] [nid001192:11838:0] ib_md.c:325 UCX ERROR ibv_reg_mr(address=0xabcf12c0, length=26400, access=0xf) failed: Cannot allocate memory\n[1613401128.440768] [nid001192:11838:0] ucp_mm.c:137 UCX ERROR failed to register address 0xabcf12c0 mem_type bit 0x1 length 26400 on md[4]=mlx5_0: Input/output error (md reg_mem_types 0x15)\n[1613401128.440773] [nid001192:11838:0] ucp_request.c:269 UCX ERROR failed to register user buffer datatype 0x8 address 0xabcf12c0 len 26400: Input/output error\nMPICH ERROR [Rank 1534] [job id 114930.0] [Mon Feb 15 14:58:48 2021] [unknown] [nid001192] - Abort(672797967) (rank 1534 in comm 0): Fatal error in PMPI_Isend: Other MPI error, error stack:\nPMPI_Isend(160)......: MPI_Isend(buf=0xabcf12c0, count=3300, MPI_DOUBLE_PRECISION, dest=1612, tag=4, comm=0x84000004, request=0x7fffb38fa0fc) failed\nMPID_Isend(416)......:\nMPID_isend_unsafe(92):\nMPIDI_UCX_send(95)...: returned failed request in UCX netmod(ucx_send.h 95 MPIDI_UCX_send Input/output error)\naborting job:\nFatal error in PMPI_Isend: Other MPI error, error stack:\nPMPI_Isend(160)......: MPI_Isend(buf=0xabcf12c0, count=3300, MPI_DOUBLE_PRECISION, dest=1612, tag=4, comm=0x84000004, request=0x7fffb38fa0fc) failed\nMPID_Isend(416)......:\nMPID_isend_unsafe(92):\nMPIDI_UCX_send(95)...: returned failed request in UCX netmod(ucx_send.h 95 MPIDI_UCX_send Input/output error)\n[1613401128.457254] [nid001192:11838:0] mm_xpmem.c:82 UCX WARN remote segment id 200002e09 apid 200002e3e is not released, refcount 1\n[1613401128.457261] [nid001192:11838:0] mm_xpmem.c:82 UCX WARN remote segment id 200002e08 apid 100002e3e is not released, refcount 1\n</code></pre> <p>You can add the following line to your job submission script before the <code>srun</code> command to try and workaround this error:</p> <pre><code>export UCX_IB_REG_METHODS=direct\n</code></pre> <p>Note</p> <p>Setting this flag may have an impact on code performance.</p>"},{"location":"known-issues/#aocc-compiler-fails-to-compile-with-netcdf-added-2021-11-18","title":"AOCC compiler fails to compile with NetCDF (Added: 2021-11-18)","text":"<p>There is currently a problem with the module file which means cray-netcdf-hdf5parallel will not operate correctly in PrgEnv-aocc. An example of the error seen is:  </p> <pre><code>F90-F-0004-Corrupt or Old Module file /opt/cray/pe/netcdf-hdf5parallel/4.7.4.3/crayclang/9.1/include/netcdf.mod (netcdf.F90: 8)\n</code></pre> <p>The current workaround for this is to load module epcc-netcdf-hdf5parallel instead if PrgEnv-aocc is required.</p>"},{"location":"known-issues/#slurm-export-option-does-not-work-in-job-submission-script","title":"Slurm  <code>--export</code> option does not work in job submission script","text":"<p>The option <code>--export=ALL</code> propagates all the environment variables from the login node to the compute node. If you include the option in the job submission script, it is wrongly ignored by Slurm. The current workaround is to include the option when the job submission script is launched. For instance:</p> <pre><code>sbatch --export=ALL myjob.slurm\n</code></pre>"},{"location":"known-issues/#recently-resolved-issues","title":"Recently Resolved Issues","text":""},{"location":"other-software/","title":"Software provided by external parties","text":"<p>This section describes software that has been installed on ARCHER2 by external parties (i.e. not by the ARCHER2 service itself) for general use by ARCHER2 users or provides useful notes on software that is not installed centrally.</p> <p>Important</p> <p>While the ARCHER2 service desk is able to provide support for basic use of this software (e.g. access to software, writing job submission scripts) it does not generally provide detailed technical support for the software and you may be directed to seek support from other places if the service desk cannot answer the questions.</p>"},{"location":"other-software/#research-software","title":"Research Software","text":"<ul> <li>CASINO</li> <li>CESM</li> <li>CRYSTAL</li> </ul>"},{"location":"other-software/casino/","title":"Casino","text":"<p>This page has moved</p>"},{"location":"other-software/cesm-further-examples/","title":"Cesm further examples","text":"<p>This page has moved</p>"},{"location":"other-software/cesm213/","title":"Cesm213","text":"<p>This page has moved</p>"},{"location":"other-software/cesm213_run/","title":"Cesm213 run","text":"<p>This page has moved</p>"},{"location":"other-software/cesm213_setup/","title":"Cesm213 setup","text":"<p>This page has moved</p>"},{"location":"other-software/crystal/","title":"Crystal","text":"<p>This page has moved</p>"},{"location":"publish/","title":"ARCHER2 and publications","text":"<p>This section provides information on how to acknowledge the use of ARCHER2 in your published work and how to register your work on ARCHER2 into the ARCHER2 publications database via SAFE.</p>"},{"location":"publish/#acknowledging-archer2","title":"Acknowledging ARCHER2","text":"<p>We will shortly be publishing a description of the ARCHER2 service with a DOI that you can cite in your published work that arises from the use of ARCHER2. Until that time, please add the following words to any work you publish that arises from your use of ARCHER2:</p> <p>This work used the ARCHER2 UK National Supercomputing Service (https://www.archer2.ac.uk).</p> <p>You should also tag outputs with the keyword \"ARCHER2\" whenever possible.</p>"},{"location":"publish/#archer2-publication-database","title":"ARCHER2 publication database","text":"<p>The ARCHER2 service maintains a publication database of works that have arisen from ARCHER2 and links them to project IDs that have ARCHER2 access. We ask all users of ARCHER2 to register any publications in the database - all you need is your publication's DOI.</p> <p>Registering your publications in SAFE has a number of advantages:</p> <ul> <li>For large projects in particular, it allows the project lead to collect publications from all    the project members to assist with ResearchFish submissions</li> <li>Your publication automatically gets added to the ARCHER2 publications page</li> <li>Your publication is included in reports to UKRI</li> <li>The better the record we have of publications arising from the ARCHER2 service, the easier it    is to demonstrate the impacts and benefits of the service; allowing UKRI to secure funding for    future national supercomputing services.</li> </ul>"},{"location":"publish/#how-to-register-a-publication-in-the-database","title":"How to register a publication in the database","text":"<p>You will need a DOI for the publication you wish to register. A DOI  has the form of an set of ID strings separated by slashes. For example, <code>10.7488/ds/1505</code>, you should not include the web host address which provides a link to the DOI.</p> <p>Login to SAFE. Then:</p> <ol> <li>Go to the Menu Your details and select Publications </li> <li>Select the project you wish to associate the publication with from the list and click View.</li> <li>The next page will list currently registered publications, to add one click Add.</li> <li>Enter the DOI in the text field provided and click Add</li> </ol>"},{"location":"publish/#how-to-list-your-publications","title":"How to list your publications","text":"<p>Login to SAFE. Then:</p> <ol> <li>Go to the Menu Your details and select Publications </li> <li>Select the project you wish to list the publications from using the dropdown menu and click View.</li> <li>The next page will list your currently registered publications.</li> </ol>"},{"location":"publish/#how-to-export-your-publications","title":"How to export your publications","text":"<p>At the moment we support export lists of DOIs to comma-separated values (CSV) files. This does not export all the metadata, just the DOIs themselves with a maximum of 25 DOIs per line. This format is primarily useful for importing into ResearchFish (where you can paste in the comma-separated lists to import publications). We plan to add further export formats in the future.</p> <p>Login to SAFE. Then:</p> <ol> <li>Go to the Menu Your details and select Publications </li> <li>Select the project you wish to list the publications from using the dropdown menu and click View.</li> <li>The next page will list your currently registered publications.</li> <li>Click Export to generate a plain text comma-separated values (CSV)   file that lists all DOIs.</li> <li>If required, you can save this file using the Save command your web browser.</li> </ol>"},{"location":"quick-start/overview/","title":"Quickstart","text":"<p>The ARCHER2 quickstart guides provide the minimum information for new users or users transferring from ARCHER. There are two sections available which are meant to be followed in sequence.</p> <ul> <li>Quickstart for users: Covers the basics of ARCHER2 useful for all     users, including: applying for an account, logging in and     transferring data, accessing software and running jobs.</li> <li>Quickstart for developers: Covers additional topics around compiling     your own programs on ARCHER2, debugging and profiling. If you are not going to be compiling your     own programs on ARCHER2, you do not need to follow this guide.</li> <li>Next steps: Covers the range of support available, getting funding and time on ARCHER2 and the training programme and resources.</li> </ul>"},{"location":"quick-start/quickstart-developers/","title":"Quickstart for developers","text":"<p>This guide aims to quickly enable developers to work on ARCHER2. It assumes that you are familiar with the material in the Quickstart for users section.</p>"},{"location":"quick-start/quickstart-developers/#compiler-wrappers","title":"Compiler wrappers","text":"<p>When compiling code on ARCHER2, you should make use of the HPE Cray compiler wrappers. These ensure that the correct libraries and headers (for example, MPI or HPE LibSci) will be used during the compilation and linking stages. These wrappers should be accessed by providing the following compiler names.</p> Language Wrapper name C cc C++ CC Fortran ftn <p>This means that you should use the wrapper names whether on the command line, in build scripts, or in configure options. It could be helpful to set some or all of the following environment variables before running a build to ensure that the build tool is aware of the wrappers.</p> <p>export CC=cc   export CXX=CC   export FC=ftn   export F77=ftn   export F90=ftn</p> <p><code>man</code> pages are available for each wrapper. You can also see the full set of compiler and linker options being used by passing the <code>-craype-verbose</code> option to the wrapper.</p> <p>Tip</p> <p>The HPE Cray compiler wrappers should be used instead of the MPI compiler wrappers such as <code>mpicc</code>, <code>mpicxx</code> and <code>mpif90</code> that you may have used on other HPC systems.</p>"},{"location":"quick-start/quickstart-developers/#programming-environments","title":"Programming environments","text":"<p>On login to ARCHER2, the <code>PrgEnv-cray</code> compiler environment will be loaded, as will a <code>cce</code> module. The latter makes available the Cray compilers from the Cray Compiling Environment (CCE), while the former provides the correct wrappers and support to use them. The GNU Compiler Collection (GCC) and the AMD compiler environment (AOCC) are also available.</p> <p>To make use of any particular compiler environment, you load the correct <code>PrgEnv</code> module. After doing so the compiler wrappers (<code>cc</code>, <code>CC</code> and <code>ftn</code>) will correctly call the compilers from the new suite. The default version of the corresponding compiler suite will also be loaded, but you may swap to another available version if you wish.</p> <p>The following table summarises the suites and associated compiler environments.</p> Suite name Module Programming environment collection CCE <code>cce</code> <code>PrgEnv-cray</code> GCC <code>gcc</code> <code>PrgEnv-gnu</code> AOCC <code>aocc</code> <code>PrgEnv-aocc</code> <p>As an example, after logging in you may wish to use GCC as your compiler suite. Running <code>module load PrgEnv-gnu</code> will replace the default CCE (Cray) environment with the GNU environment. It will also unload the <code>cce</code> module and load the default version of the <code>gcc</code> module; at the time of writing, this is GCC 11.2.0. If you need to use a different version of GCC, for example 10.3.0, you would follow up with <code>module load gcc/10.3.0</code>. At this point you may invoke the compiler wrappers and they will correctly use the HPE libraries and tools in conjunction with GCC 10.3.0.</p> <p>When choosing the compiler environment, a big factor will likely be which compilers you have previously used for your code's development. The Cray Fortran compiler is similar to the compiler you may be familiar with from ARCHER, while the Cray C and C++ compilers provided on ARCHER2 are new versions that are now derived from Clang. The GCC suite provides gcc/g++ and gfortran. The AOCC suite provides AMD Clang/Clang++ and AMD Flang.</p> <p>Note</p> <p>The Intel compilers are not available on ARCHER2.</p>"},{"location":"quick-start/quickstart-developers/#useful-compiler-options","title":"Useful compiler options","text":"<p>The compiler options you use will depend on both the software you are building and also on the current stage of development. The following flags should be a good starting point for reasonable performance.</p> Compilers Optimisation flags Cray C/C++ <code>-O2 -funroll-loops -ffast-math</code> Cray Fortran Default options GCC <code>-O2 -ftree-vectorize -funroll-loops -ffast-math</code> <p>Tip</p> <p>If you want to use GCC version 10 or greater to compile MPI Fortran code, you must add the <code>-fallow-argument-mismatch</code> option when compiling otherwise you will see compile errors associated with MPI functions.</p> <p>When you are happy with your code's performance you may wish to enable more aggressive optimisations; in this case you could start using the following flags. Please note, however, that these optimisations may lead to deviations from IEEE/ISO specifications. If your code relies on strict adherence then using these flags may cause incorrect output.</p> Compilers Optimisation flags Cray C/C++ <code>-Ofast -funroll-loops</code> Cray Fortran <code>-O3 -hfp3</code> GCC <code>-Ofast -funroll-loops</code> <p>Vectorisation is enabled by the Cray Fortran compiler at <code>-O1</code> and above, by Cray C and C++ at <code>-O2</code> and above or when using <code>-ftree-vectorize</code>, and by the GCC compilers at <code>-O3</code> and above or when using <code>-ftree-vectorize</code>.</p> <p>You may wish to promote default <code>real</code> and <code>integer</code> types in Fortran codes from 4 to 8 bytes. In this case, the following flags may be used.</p> Compiler Fortran <code>real</code> and <code>integer</code> promotion flags Cray Fortran <code>-s real64 -s integer64</code> gfortran <code>-freal-4-real-8 -finteger-4-integer-8</code> <p>More documentation on the compilers is available through <code>man</code>. The pages to read are accessed as follow.</p> Compiler suite C C++ Fortran Cray <code>man craycc</code> <code>man crayCC</code> <code>man crayftn</code> GNU <code>man gcc</code> <code>man g++</code> <code>man gfortran</code> <p>Tip</p> <p>There are no <code>man</code> pages for the AOCC compilers at the moment.</p>"},{"location":"quick-start/quickstart-developers/#linking-on-archer2","title":"Linking on ARCHER2","text":"<p>Executables on ARCHER2 link dynamically, and the Cray Programming Environment does not currently support static linking. This is in contrast to ARCHER where the default was to build statically.</p> <p>If you attempt to link statically, you will see errors similar to:</p> <pre><code>/usr/bin/ld: cannot find -lpmi\n/usr/bin/ld: cannot find -lpmi2\ncollect2: error: ld returned 1 exit status\n</code></pre> <p>The compiler wrapper scripts on ARCHER link runtime libraries in using the <code>RUNPATH</code> by default. This means that the paths to the runtime libraries are encoded into the executable so you do not need to load the compiler environment in your job submission scripts.</p>"},{"location":"quick-start/quickstart-developers/#using-runpaths-to-link","title":"Using RUNPATHs to link","text":"<p>The default behaviour of a dynamically linked executable will be to allow the linker to provide the libraries it needs at runtime by searching the paths in the <code>LD_LIBRARY_PATH</code> environment  and then by searching the paths in the <code>RUNPATH</code> variable setting of the binary. This is flexible in that it allows an executable to use newly installed library versions without rebuilding, but in some cases you may prefer to bake the paths to specific libraries into the executable <code>RUNPATH</code>, keeping them constant. While the libraries are still dynamically loaded at run time, from the end user's point of view the resulting behaviour will be similar to that of a statically compiled executable in that they will not need to concern themselves with ensuring the linker will be able to find the libraries.</p> <p>This is achieved by providing additional paths to add to <code>RUNPATH</code> to the compiler as options. To set the compiler wrappers to do this, you can set the following environment variable.</p> <pre><code>export CRAY_ADD_RPATH=yes\n</code></pre>"},{"location":"quick-start/quickstart-developers/#using-rpaths-to-link","title":"Using RPATHs to link","text":"<p><code>RPATH</code> differs from <code>RUNPATH</code> in that it searches RPATH directories for libraries before searching the paths in <code>LD_LIBRARY_PATH</code> so they cannot be overridden in the same way at runtime.</p> <p>You can provide RPATHs directly to the compilers using the <code>-Wl,-rpath=&lt;path-to-directory&gt;</code> flag, where the provided path is to the directory containing the libraries which are themselves typically specified with flags of the type <code>-l&lt;library-name&gt;</code>.</p>"},{"location":"quick-start/quickstart-developers/#debugging-tools","title":"Debugging tools","text":"<p>The following debugging tools are available on ARCHER2:</p> <ul> <li>gdb4hpc is a command-line tool working similarly to     gdb that allows users to debug     parallel programs. It can launch parallel programs or attach to ones     already running and allows the user to step through the execution to     identify the causes of any unexpected behaviour. Available via     <code>module load gdb4hpc</code>.</li> <li>valgrind4hpc is a parallel memory debugging tool that aids in     detection of memory leaks and errors in parallel applications. It     aggregates like errors across processes and threads to simplify     debugging of parallel appliciations. Available via <code>module load     valgrind4hpc</code>.</li> <li>STAT, the Stack Trace Analysis Tool, generates merged stack     traces for parallel applications. It also provides visualisation     tools. Available via <code>module load cray-stat</code>.</li> </ul> <p>To get started debugging on ARCHER2, you might like to use gdb4hpc. You should first of all compile your code using the <code>-g</code> flag to enable debugging symbols. Once compiled, load the gdb4hpc module and start it:</p> <pre><code>module load gdb4hpc\ngdb4hpc\n</code></pre> <p>Once inside gdb4hpc, you can start your program's execution with the <code>launch</code> command:</p> <pre><code>dbg all&gt; launch $my_prog{128} ./prog\n</code></pre> <p>In this example, a job called <code>my_prog</code> will be launched to run the executable file <code>prog</code> over 128 cores on a compute node. If you run <code>squeue</code> in another terminal you will be able to see it running. Inside gdb4hpc you may then <code>step</code> through the code's execution, <code>continue</code> to breakpoints that you set with <code>break</code>, <code>print</code> the values of variables at these points, and perform a <code>backtrace</code> on the stack if the program crashes. Debugging jobs will end when you exit gdb4hpc, or you can end them yourself by running, in this example, <code>release $my_prog</code>.</p> <p>For more information on debugging parallel codes, see the documentation in the Debugging section of the ARCHER2 User and Best Practice Guide.</p>"},{"location":"quick-start/quickstart-developers/#profiling-tools","title":"Profiling tools","text":"<p>Profiling on ARCHER2 is provided through the Cray Performance Measurement and Analysis Tools (CrayPAT). This has a number of different components:</p> <ul> <li>CrayPAT the full-featured program analysis tool set. CrayPAT     consists of <code>pat_build</code>, the utility used to instrument programs, the     CrayPat run time environment, which collects the specified     performance data during program execution, and <code>pat_report</code>, the     first-level data analysis tool, used to produce text reports or     export data for more sophisticated analysis.</li> <li>CrayPAT-lite a simplified and easy-to-use version of CrayPAT     that provides basic performance analysis information automatically,     with a minimum of user interaction.</li> <li>Reveal the next-generation integrated performance analysis and     code optimization tool, which enables the user to correlate     performance data captured during program execution directly to the     original source, and identify opportunities for further     optimization.</li> <li>Cray PAPI components, which are support packages for those who     want to access performance counters.</li> <li>Cray Apprentice2 the second-level data analysis tool, used to     visualize, manipulate, explore, and compare sets of program     performance data in a GUI environment.</li> </ul> <p>The above tools are made available for use by firstly loading the <code>perftools-base</code> module followed by either <code>perftools</code> (for CrayPAT, Reveal and Apprentice2) or one of the <code>perftools-lite</code> modules.</p> <p>The simplest way to get started profiling your code is with CrayPAT-lite. For example, to sample a run of a code you would load the <code>perftools-base</code> and <code>perftools-lite</code> modules, and then compile (you will receive a message that the executable is being instrumented). Performing a batch run as usual with this executable will produce a directory such as <code>my_prog+74653-2s</code> which can be passed to <code>pat_report</code> to view the results. In this example,</p> <pre><code>pat_report -O calltree+src my_prog+74653-2s\n</code></pre> <p>will produce a report containing the call tree. You can view available report keywords to be provided to the <code>-O</code> option by running <code>pat_report -O -h</code>. The available <code>perftools-lite</code> modules are:</p> <ul> <li><code>perftools-lite</code>, instrumenting a basic sampling experiment.</li> <li><code>perftools-lite-events</code>, instrumenting a tracing experiment.</li> <li><code>perftools-lite-gpu</code>, instrumenting OpenACC and OpenMP 4 use of     GPUs.</li> <li><code>perftools-lite-hbm</code>, instrumenting for memory bandwidth usage.</li> <li><code>perftools-lite-loops</code>, instrumenting a loop work estimate     experiment.</li> </ul> <p>Tip</p> <p>For more information on profiling parallel codes, see the documentation in the Profiling section of the ARCHER2 User and Best Practice Guide.</p>"},{"location":"quick-start/quickstart-developers/#useful-links","title":"Useful Links","text":"<p>Links to other documentation you may find useful:</p> <ul> <li>ARCHER2 User and Best Practice Guide -     Covers all aspects of use of the ARCHER2 service. This includes     fundamentals (required by all users to use the system effectively),     best practice for getting the most out of ARCHER2, and more advanced     technical topics.</li> <li>HPE Cray Programming Environment User     Guide</li> <li>HPE Cray Performance Measurement and Analysis Tools User     Guide</li> </ul>"},{"location":"quick-start/quickstart-next-steps/","title":"Next Steps","text":"<p>Once you have set up your machine account and logged on, run a job or two and possibly updated and compiled your code: what next?</p> <p>There is still loads of support and advice available to you:</p> <p>Getting Started on ARCHER2 gives an overview of some of this help.</p> <p>Advice on how to Get Access with different funding routes, and if your chosen route requires you to complete a Technical Assessment, we have advice on How to prepare a successful TA</p> <p>And we also have a comprehensive Training Programme for all levels of experience and a wide range of different uses.  All our training is free for UK Academics and we have a list of upcoming training and also all the materials and resources from previous training events.</p>"},{"location":"quick-start/quickstart-users/","title":"Quickstart for users","text":"<p>This guide aims to quickly enable new users to get up and running on ARCHER2. It covers the process of getting an ARCHER2 account, logging in and running your first job.</p>"},{"location":"quick-start/quickstart-users/#request-an-account-on-archer2","title":"Request an account on ARCHER2","text":"<p>Important</p> <p>You need to use both a password and a passphrase-protected SSH key pair to log into ARCHER2. You get the password from SAFE, but, you will also need to setup your own SSH key pair and add the public part to your account via SAFE before you will be able to log in. We cover the authentication steps below.</p>"},{"location":"quick-start/quickstart-users/#obtain-an-account-on-the-safe-website","title":"Obtain an account on the SAFE website","text":"<p>Warning</p> <p>We have seen issues with Gmail blocking emails from SAFE so we recommend that users use their institutional/work email address rather than Gmail addresses to register  for SAFE accounts.</p> <p>The first step is to sign up for an account on the ARCHER2 SAFE website. The SAFE account is used to manage all of your login accounts, allowing you to report on your usage and quotas. To do this:</p> <ol> <li>Go to the SAFE New User Signup     Form</li> <li>Fill in your personal details. You can come back later and change     them if you wish</li> <li>Click Submit</li> </ol> <p>You are now registered. Your SAFE password will be emailed to the email address you provided. You can then login with that email address and password. (You can change your initial SAFE password whenever you want by selecting the Change SAFE password option from the Your details menu.)</p>"},{"location":"quick-start/quickstart-users/#request-an-archer2-login-account","title":"Request an ARCHER2 login account","text":"<p>Once you have a SAFE account and an SSH key you will need to request a user account on ARCHER2 itself. To do this you will require a Project Code; you usually obtain this from the Principle Investigator (PI) or project manager for the project you will be working on. Once you have the Project Code:</p> Full system <ol> <li>Log into SAFE</li> <li>Use the Login accounts - Request new account menu item</li> <li>Select the correct project from the drop down list</li> <li>Select the archer2 machine in the list of available machines</li> <li>Click Next</li> <li>Enter a username for the account and the public part of an SSH key pair <ol> <li>More information on generating SSH key pair can be found in the ARCHER2 User and Best Practice Guide</li> <li>You can add additional SSH keys using the process described below if you so wish.</li> </ol> </li> <li>Click Request</li> </ol> <p>The PI or project manager of the project will be asked to approve your request. After your request has been approved the account will be created and when this has been done you will receive an email. You can then come back to SAFE and pick up the initial single-use password for your new account.</p> <p>Note</p> <p>ARCHER2 account passwords are also sometimes referred to as LDAP passwords by the system.</p>"},{"location":"quick-start/quickstart-users/#generating-and-adding-an-ssh-key-pair","title":"Generating and adding an SSH key pair","text":"<p>How you generate your SSH key pair depends on which operating system you use and which SSH client you use to connect to ARCHER2. We will not cover the details on generating an SSH key pair here, but detailed information on this topic is available in the ARCHER2 User and Best Practice Guide.</p> <p>After generating your SSH key pair, add the public part to your login account using SAFE:</p> <ol> <li>Log into SAFE</li> <li>Use the menu Login accounts and select the ARCHER2 account to be     associated with the SSH key</li> <li>On the subsequent Login account details page, click the Add     Credential button</li> <li>Select SSH public key as the Credential Type and click Next</li> <li>Either copy and paste the public part of your SSH key into the SSH     Public key box or use the button to select the public key file on     your computer</li> <li>Click Add to associate the public SSH key part with your account</li> </ol> <p>Once you have done this, your SSH key will be added to your ARCHER2 account.</p> <p>Remember, you will need to use both an SSH key and password to log into ARCHER2 so you will also need to collect your initial password before you can log into ARCHER2 for the first time. We cover this next.</p> <p>Note</p> <p>If you want to connect to ARCHER2 from more than one machine, e.g. from your home laptop as well as your work laptop, you should generate an ssh key on each machine, and add each of the public keys into SAFE.  </p>"},{"location":"quick-start/quickstart-users/#collecting-your-archer2-password","title":"Collecting your ARCHER2 password","text":"<p>You should now collect your ARCHER2 password:</p> <ol> <li>Log into SAFE</li> <li>Use the Login accounts menu to select your new login account</li> <li>Use the View Login Account Password button to view your single-use     ARCHER2 password</li> </ol> <p>This password is generated randomly by the software. It's best to copy-and-paste it across when you log in to ARCHER2. After you login, you will immediately be prompted to begin the process of changing your password. You should now enter the initial password again, and then you will be prompted for your new, easy-to-remember password. Your new password should conform to the ARCHER2 Password Policy.</p> <p>Note</p> <p>The View Login Account Password option within SAFE will continue to display your old initial password. Your SAFE account has no knowledge of your new machine account password.</p>"},{"location":"quick-start/quickstart-users/#login-to-archer2","title":"Login to ARCHER2","text":"<p>To log into ARCHER2 you should use the address:</p> Full system <p>ssh [userID]@login.archer2.ac.uk</p> <p>The order in which you are asked for credentials depends on the system you are accessing:</p> Full system <p>You will first be prompted for the passphrase associated with your SSH key pair. Once you have entered this passphrase successfully, you will then be prompted for your machine account password. You need to enter both credentials correctly to be able to access ARCHER2.</p> <p>Tip</p> <p>If you previously logged into the ARCHER2 system before the major upgrade in May/June 2023 with your account you may see an error from SSH that looks like</p> <pre><code>@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@       WARNING: POSSIBLE DNS SPOOFING DETECTED!          @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nThe ECDSA host key for login.archer2.ac.uk has changed,\nand the key for the corresponding IP address 193.62.216.43\nhas a different value. This could either mean that\nDNS SPOOFING is happening or the IP address for the host\nand its host key have changed at the same time.\nOffending key for IP in /Users/auser/.ssh/known_hosts:11\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\nIt is also possible that a host key has just been changed.\nThe fingerprint for the ECDSA key sent by the remote host is\nSHA256:UGS+LA8I46LqnD58WiWNlaUFY3uD1WFr+V8RCG09fUg.\nPlease contact your system administrator.\n</code></pre> <p>If you see this, you should delete the offending host key from your <code>~/.ssh/known_hosts</code> file (in the example above the offending line is line #11)</p> <p>Tip</p> <p>If your SSH key pair is not stored in the default location (usually <code>~/.ssh/id_rsa</code>) on your local system, you may need to specify the path to the private part of the key wih the <code>-i</code> option to <code>ssh</code>. For example, if your key is in a file called <code>keys/id_rsa_archer2</code> you would use the command <code>ssh -i keys/id_rsa_archer2 username@login.archer2.ac.uk</code> to log in.</p> <p>Tip</p> <p>When you first log into ARCHER2, you will be prompted to change your initial password. This is a three step process:</p> <ol> <li>When prompted to enter your ldap password: re-enter the password     you retrieved from SAFE</li> <li>When prompted to enter your new password: type in a new password</li> <li>When prompted to re-enter the new password: re-enter the new     password</li> </ol> <p>Your password has now been changed.</p> <p>Hint</p> <p>More information on connecting to ARCHER2 is available in the Connecting to ARCHER2 section of the User Guide.</p>"},{"location":"quick-start/quickstart-users/#file-systems-and-manipulating-data","title":"File systems and manipulating data","text":"<p>ARCHER2 has a number of different file systems and understanding the difference between them is crucial to being able to use the system. In particular, transferring and moving data often requires a bit of thought in advance to ensure that the data is secure and in a useful form.</p> <p>ARCHER2 file systems are:</p> <ul> <li>home file systems: backed up. Available on login and data analysis nodes.</li> <li>work file systems: not backed-up. Available on login, data analysis and     compute nodes.</li> </ul> <p>All users have a directory on one of the home file systems and on one of the work file systems. The directories are located at:</p> <ul> <li><code>/home/[project ID]/[project ID]/[user ID]</code> (this is also set as your home directory)</li> <li><code>/work/[project ID]/[project ID]/[user ID]</code></li> </ul> <p>Top tips for managing data on ARCHER2:</p> <ul> <li>Do not generate huge numbers of files (&gt;1000) in a single     directory.</li> <li>Poor performance relating to file transfer is often due to the     number of files involved in the transfer - minimise the number of     files that you have to transfer by using archiving tools to improve     performance.</li> <li>Archive directories or large numbers of files before moving them     between file systems (e.g. by using commands like <code>tar</code> or <code>zip</code>).</li> <li>When using <code>tar</code> or <code>rsync</code> between file systems mounted on ARCHER2     avoid the use of compression options as these can slow performance     (time saved by transferring smaller compressed files is usually less     than the overhead added by having to compress files on the fly).</li> <li>Think about automating the merging and transfer of multiple files     output by software on ARCHER2 to other resources. The Data     Management Guide linked below provides examples of how to     automatically verify the integrity of an archive.</li> </ul> <p>Hint</p> <p>Information on the file systems and best practice in managing you data is available in the Data management and transfer section of the User and Best Practice Guide.</p>"},{"location":"quick-start/quickstart-users/#accessing-software","title":"Accessing software","text":"<p>Software on ARCHER2 is principally accessed through modules. These load and unload the desired applications, compilers, tools and libraries through the <code>module</code> command and its subcommands. Some modules will be loaded by default on login, providing a default working environment; many more will be available for use but initially unloaded, allowing you to set up the environment to suit your needs.</p> <p>At any stage you can check which modules have been loaded by running</p> <pre><code>module list\n</code></pre> <p>Running the following command will display all environment modules available on ARCHER2, whether loaded or unloaded</p> <pre><code>module avail\n</code></pre> <p>The search field for this command may be narrowed by providing the first few characters of the module name being queried. For example, all available versions and variants of VASP may be found by running</p> <pre><code>module avail vasp\n</code></pre> <p>You will see that different versions are available for many modules. For example, <code>vasp/5/5.4.4.pl2</code> and <code>vasp/6/6.3.2</code> are two available versions of VASP on the full system. Furthermore, a default version may be specified; this is used if no version is provided by the user.</p> <p>Important</p> <p>VASP is licensed software, as are other software packages on ARCHER2. You must have a valid licence to use licensed software on ARCHER2. Often you will need to request access through the SAFE. More on this below.</p> <p>The <code>module load</code> command loads a module for use. Following the above,</p> <pre><code>module load vasp/6\n</code></pre> <p>would load the default version of VASP 6, while</p> <pre><code>module load vasp/6/6.3.2\n</code></pre> <p>would specifically load version <code>6.3.2</code>. A loaded module may be unloaded through the identical <code>module remove</code> command, e.g.</p> <pre><code>module unload vasp\n</code></pre> <p>The above unloads whichever version of VASP is currently in the environment. Rather than issuing separate unload and load commands, versions of a module may be swapped as follows:</p> <pre><code>module swap vasp vasp/5/5.4.4.pl2\n</code></pre> <p>Other helpful commands are:</p> <ul> <li><code>module help &lt;modulename&gt;</code> which provides a short description of the     module</li> <li><code>module show &lt;modulename&gt;</code> which displays the contents of the     modulefile</li> <li><code>module restore</code> which returns you to the default module setup as if     you had just logged in</li> </ul> <p>Tip</p> <p>You should not use the <code>module purge</code> command on ARCHER2 as this will cause issues for the HPE Cray programming environment. If you wish to  reset your modules, you should use the <code>module restore</code> command instead.</p> <p>Points to be aware of include:</p> <ul> <li>Some modules will conflict with others. A simple example would be     the conflict arising when trying to load a different version of an     already loaded module. When a conflict occurs, the loading process     will fail and an error message will be displayed. Examination of the     message and the module output (via <code>module show</code>) should reveal the     cause of the conflict and how to resolve it.</li> <li>The order in which modules are loaded can matter. Consider two     modules which set the same variable to a different value. The final     value would be that set by the module which loaded last. If you     suspect that two modules may be interfering with one another, you     can examine their contents with <code>module show</code>.</li> </ul> <p>More information on modules and the software environment on  ARCHER2 can be found in the Software environment section of the User and Best Practice Guide.</p>"},{"location":"quick-start/quickstart-users/#requesting-access-to-licensed-software","title":"Requesting access to licensed software","text":"<p>Some of the software installed on ARCHER2 requires a user to have a valid licence agreed with the software owners/developers to be able to use it (for example, VASP). Although you will be able to load this software on ARCHER2, you will be barred from actually using it until your licence has been verified.</p> <p>You request access to licensed software through the SAFE  (the web administration tool you used to apply for your account and retrieve your initial password) by being added to the appropriate Package Group. To request access to licensed software:</p> <ol> <li>Log in to SAFE</li> <li>Go to the Menu Login accounts and select the login account which     requires access to the software</li> <li>Click New Package Group Request</li> <li>Select the software from the list of available packages and click     Select Package Group</li> <li>Fill in as much information as possible about your license; at the     very least provide the information requested at the top of the     screen such as the licence holder's name and contact details. If you     are covered by the license because the licence holder is your     supervisor, for example, please state this.</li> <li>Click Submit</li> </ol> <p>Your request will then be processed by the ARCHER2 Service Desk who will confirm your license with the software owners/developers before enabling your access to the software on ARCHER2. This can take several days (depending on how quickly the software owners/developers take to respond) but you will be advised once this has been done.</p>"},{"location":"quick-start/quickstart-users/#create-a-job-submission-script","title":"Create a job submission script","text":"<p>To run a program on the ARCHER2 compute nodes you need to write a job submission script that tells the system how many compute nodes you want to reserve and for how long. You also need to use the <code>srun</code> command to launch your parallel executable.</p> <p>Hint</p> <p>For a more details on the Slurm scheduler on ARCHER2 and writing job submission scripts see the Running jobs on ARCHER2 section of the User and Best Practice Guide.</p> <p>Important</p> <p>Parallel jobs on ARCHER2 should be run from the work file systems as the home file systems are not available on the compute nodes - you will see a <code>chdir</code> or file not found error if you try to access data on the home file system within a parallel job running on the compute nodes.</p> <p>Create a job submission script called <code>submit.slurm</code> in your space on the work file systems using your favourite text editor. For example, using <code>vim</code>:</p> <pre><code>auser@ln01:~&gt; cd /work/t01/t01/auser\nauser@ln01:/work/t01/t01/auser&gt; vim submit.slurm\n</code></pre> <p>Tip</p> <p>You will need to use your project code and username to get to the correct directory. i.e. replace the <code>t01</code> above with your project code and replace the username <code>auser</code> with your ARCHER2 username.</p> <p>Paste the following text into your job submission script, replacing <code>ENTER_YOUR_BUDGET_CODE_HERE</code> with your budget code e.g. <code>e99-ham</code>, <code>ENTER_PARTITION_HERE</code> with the partition you wish to run on (e.g <code>standard</code>), and <code>ENTER_QOS_HERE</code> with the quality of service you want (e.g. <code>standard</code>).</p> Full system <pre><code>#!/bin/bash --login\n\n#SBATCH --job-name=test_job\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=0:5:0\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the xthi module to get access to the xthi program\nmodule load xthi\n\n# Recommended environment settings\n# Stop unintentional multi-threading within software libraries\nexport OMP_NUM_THREADS=1\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# srun launches the parallel program based on the SBATCH options\nsrun --distribution=block:block --hint=nomultithread xthi_mpi\n</code></pre>"},{"location":"quick-start/quickstart-users/#submit-your-job-to-the-queue","title":"Submit your job to the queue","text":"<p>You submit your job to the queues using the <code>sbatch</code> command:</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; sbatch submit.slurm\nSubmitted batch job 23996\n\nThe value returned is your *Job ID*.\n</code></pre>"},{"location":"quick-start/quickstart-users/#monitoring-your-job","title":"Monitoring your job","text":"<p>You use the <code>squeue</code> command to examine jobs in the queue. To list all the jobs you have in the queue, use:</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; squeue -u $USER\n</code></pre> <p><code>squeue</code> on its own lists all jobs in the queue from all users.</p>"},{"location":"quick-start/quickstart-users/#checking-the-output-from-the-job","title":"Checking the output from the job","text":"<p>The job submission script above should write the output to a file called <code>slurm-&lt;jobID&gt;.out</code> (i.e. if the Job ID was 23996, the file would be <code>slurm-23996.out</code>), you can check the contents of this file with the <code>cat</code> command. If the job was successful you should see output that looks something like:</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; cat slurm-23996.out\nNode    0, hostname nid001020\nNode    0, rank    0, thread   0, (affinity =    0)\nNode    0, rank    1, thread   0, (affinity =    1)\nNode    0, rank    2, thread   0, (affinity =    2)\nNode    0, rank    3, thread   0, (affinity =    3)\nNode    0, rank    4, thread   0, (affinity =    4)\nNode    0, rank    5, thread   0, (affinity =    5)\nNode    0, rank    6, thread   0, (affinity =    6)\nNode    0, rank    7, thread   0, (affinity =    7)\nNode    0, rank    8, thread   0, (affinity =    8)\nNode    0, rank    9, thread   0, (affinity =    9)\nNode    0, rank   10, thread   0, (affinity =   10)\nNode    0, rank   11, thread   0, (affinity =   11)\nNode    0, rank   12, thread   0, (affinity =   12)\nNode    0, rank   13, thread   0, (affinity =   13)\nNode    0, rank   14, thread   0, (affinity =   14)\nNode    0, rank   15, thread   0, (affinity =   15)\nNode    0, rank   16, thread   0, (affinity =   16)\nNode    0, rank   17, thread   0, (affinity =   17)\nNode    0, rank   18, thread   0, (affinity =   18)\nNode    0, rank   19, thread   0, (affinity =   19)\nNode    0, rank   20, thread   0, (affinity =   20)\nNode    0, rank   21, thread   0, (affinity =   21)\n... output trimmed ...\n</code></pre> <p>If something has gone wrong, you will find any error messages in the file instead of the expected output.</p>"},{"location":"quick-start/quickstart-users/#acknowledging-archer2","title":"Acknowledging ARCHER2","text":"<p>You should use the following phrase to acknowledge ARCHER2 for all research outputs that were generated using the ARCHER2 service:</p> <p>This work used the ARCHER2 UK National Supercomputing Service (https://www.archer2.ac.uk).</p> <p>You should also tag outputs with the keyword \"ARCHER2\" whenever possible.</p>"},{"location":"quick-start/quickstart-users/#useful-links","title":"Useful Links","text":"<p>If you plan to compile your own programs on ARCHER2, you may also want to look at Quickstart for developers.</p> <p>Other documentation you may find useful:</p> <ul> <li>ARCHER2 User and Best Practice Guide:     Covers all aspects of use of the ARCHER2 service. This includes     fundamentals (required by all users to use the system effectively),     best practice for getting the most out of ARCHER2, and more advanced     technical topics.</li> <li>HPE Cray Programming Environment User     Guide</li> </ul>"},{"location":"research-software/","title":"Research Software","text":"<p>ARCHER2 provides a number of research software packages as centrally supported packages. Many of these packages are free to use, but others require a license (which you, or your research group, need to supply).</p> <p>This section also contains information on research software contributed and/or supported by third parties (marked with a * in the list below).</p> <p>For centrally supported packages, the version available will usually be the current stable release, to include major releases and significant updates. We will usually not maintain older versions and versions no longer supported by the developers of the package.</p> <p>The following sections provide details on access to each of the centrally installed packages (software that is not part of the fully-supported software stack are marked with *):</p> <ul> <li>CASINO(*)</li> <li>CASTEP</li> <li>CESM2(*)</li> <li>Chemshell</li> <li>Code_Saturne</li> <li>CP2K</li> <li>CRYSTAL(*)</li> <li>FHI-aims</li> <li>GROMACS</li> <li>LAMMPS</li> <li>MITgcm</li> <li>Met Office Unified Model</li> <li>NAMD</li> <li>Nektar++</li> <li>NEMO</li> <li>NWChem</li> <li>ONETEP</li> <li>OpenFOAM</li> <li>ORCA(*)</li> <li>Quantum Espresso</li> <li>VASP</li> </ul>"},{"location":"research-software/#not-on-the-list","title":"Not on the list?","text":"<p>If the software you are interested in is not in the above list, we may still be able to help you install your own version, either individually, or as a project. Please contact the Service Desk.</p>"},{"location":"research-software/casino/","title":"CASINO","text":"<p>Note</p> <p>CASINO is not available as central install/module on ARCHER2 at this time. This  page provides tips on using CASINO on ARCHER2 for users who have obtained their  own copy of the code.</p> <p>Important</p> <p>CASINO is not part of the officially supported software on ARCHER2. While the ARCHER2 service desk is able to provide support for basic use of this software (e.g. access to software, writing job submission scripts) it does not generally provide detailed technical support for the software and you may be directed to seek support from other places if the service desk cannot answer the questions.</p> <p>CASINO is a computer program system for performing quantum Monte Carlo (QMC) electronic structure calculations that has been developed by a group of researchers initially working in the Theory of Condensed Matter group in the Cambridge University physics department, and their collaborators, over more than 20 years.  It is capable of calculating incredibly accurate solutions to the Schr\u00f6dinger equation of quantum mechanics for realistic systems built from atoms. </p>"},{"location":"research-software/casino/#useful-links","title":"Useful Links","text":"<ul> <li>CASINO User Manual</li> <li>CASINO Licensing</li> </ul>"},{"location":"research-software/casino/#compiling-casino-on-archer2","title":"Compiling CASINO on ARCHER2","text":"<p>You should use the <code>linuxpc-gcc-slurm-parallel.archer2</code> configuration that is supplied along with the CASINO source code to build on ARCHER2 and ensure that you build the \"Shm\" (System-V shared memory) version of the code.</p> <p>Bug</p> <p>The <code>linuxpc-cray-slurm-parallel.archer2</code> configuration produces a binary that crashes with a segfault and should not be used.</p>"},{"location":"research-software/casino/#using-casino-on-archer2","title":"Using CASINO on ARCHER2","text":"<p>The performance of CASINO on ARCHER2 is critically dependent on three things:</p> <ul> <li>The MPI transport layer used: UCX is required for good scaling to multiple nodes</li> <li>The number of cores that share System-V shared memory segments: 8 or 16 cores are   the best performing choices. If memory efficiency is critical, then 32 cores gives   good performance. More than 32 cores sharing a memory segment gives poor performance.</li> <li>Ensuring that MPI processes are pinned to cores in a sequential manner so cores that    are sharing shared memory segments are located as close to each other as possible.</li> </ul> <p>Next, we show how to make sure that the MPI transport layer is set to UCX,  how to set the number of cores sharing the System-V shared memory segments and how to pin MPI processes sequentially to cores.</p> <p>Finally, we provide a job submission script that demonstrates all these options together.</p>"},{"location":"research-software/casino/#setting-the-mpi-transport-layer-to-ucx","title":"Setting the MPI transport layer to UCX","text":"<p>In your job submission script that runs CASINO you switch to using UCX as the MPI transport layer by including the following lines before you run CASINO (i.e. before the <code>srun</code> command that launches the CASINO executable):</p> <pre><code>module load PrgEnv-gnu\nmodule load craype-network-ucx\nmodule load cray-mpich-ucx\n</code></pre>"},{"location":"research-software/casino/#setting-the-number-of-cores-sharing-memory","title":"Setting the number of cores sharing memory","text":"<p>In your job submission script you set the number of cores sharing memory segments  by setting the <code>CASINO_NUMABLK</code> environment variable before you run CASINO. For example, to specify that there should be shared memory segments each shared between 16 cores, you would use:</p> <pre><code>export CASINO_NUMABLK=16\n</code></pre> <p>Tip</p> <p>If you do not set <code>CASINO_NUMABLK</code> then CASINO will use the default of all cores on  a node (the equivalent of setting it to 128) which will give very poor performance so you should always set this environment variable. Setting <code>CASINO_NUMABLK</code> to 8 or 16 cores gives the best performance. 32 cores is acceptable if you want to maximise memory efficiency. Using 64 and 128 gives poor performance.</p>"},{"location":"research-software/casino/#pinning-mpi-processes-sequentially-to-cores","title":"Pinning MPI processes sequentially to cores","text":"<p>For shared memory segments to work efficiently MPI processes must be pinned sequentially to cores on compute nodes (so that cores sharing memory are close in the node memory hierarchy). To do this, you add the following options to the <code>srun</code> command in your job script that runs the CASINO executable:</p> <pre><code>--distribution=block:block --hint=nomultithread\n</code></pre>"},{"location":"research-software/casino/#example-casino-job-submission-script","title":"Example CASINO job submission script","text":"<p>The following script will run a CASINO job using 16 nodes (2048 cores).</p> <pre><code>#!/bin/bash\n\n# Request 16 nodes with 128 MPI tasks per node for 20 minutes\n#SBATCH --job-name=CASINO\n#SBATCH --nodes=16\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Ensure we are using UCX as the MPI transport layer\nmodule load PrgEnv-gnu\nmodule load craype-network-ucx\nmodule load cray-mpich-ucx\n\n# Set CASINO to share memory across 16 core blocks\nexport CASINO_NUMABLK=16\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Set the location of the CASINO executable - this must be on /work\n#   Replace this with the path to your compiled CASINO binary\nCASINO_EXE=/work/t01/t01/auser/CASINO/bin_qmc/linuxpc-gcc-slurm-parallel.archer2/Shm/opt/casino\n\n# Launch CASINO with MPI processes pinned to cores in a sequential order\nsrun --distribution=block:block --hint=nomultithread ${CASINO_EXE}\n</code></pre>"},{"location":"research-software/casino/#casino-performance-on-archer2","title":"CASINO performance on ARCHER2","text":"<p>We have run the benzene_dimer benchmark on ARCHER2 with the following configuration:</p> <ul> <li>Compiler arch: <code>linuxpc-gcc-slurm-parallel.archer2</code>, \"Shm\" version</li> <li>Compiler: GCC 10.2.0</li> <li>MPI Library: HPE Cray MPICH 8.1.4</li> <li>MPI transport layer: UCX</li> <li>128 MPI processes per node</li> </ul> <p>Timings are reported as time taken for 100 equilibration steps in DMC calculation.</p>"},{"location":"research-software/casino/#casino_numablk8","title":"CASINO_NUMABLK=8","text":"Nodes Time taken (s) Speedup 1 289.90 1.0 2 154.93 1.9 4 81.06 3.6 8 41.44 7.0 16 23.16 12.5"},{"location":"research-software/castep/","title":"CASTEP","text":"<p>CASTEP is a leading code for calculating the properties of materials from first principles. Using density functional theory, it can simulate a wide range of properties of materials proprieties including energetics, structure at the atomic level, vibrational properties, electronic response properties etc. In particular it has a wide range of spectroscopic features that link directly to experiment, such as infra-red and Raman spectroscopies, NMR, and core level spectra.</p>"},{"location":"research-software/castep/#useful-links","title":"Useful Links","text":"<ul> <li>CASTEP User Guides</li> <li>CASTEP Tutorials</li> <li>CASTEP Licensing</li> </ul>"},{"location":"research-software/castep/#using-castep-on-archer2","title":"Using CASTEP on ARCHER2","text":"<p>CASTEP is only available to users who have a valid CASTEP licence.</p> <p>If you have a CASTEP licence and wish to have access to CASTEP on ARCHER2, please make a request via the SAFE, see:</p> <ul> <li>How to request access to package groups</li> </ul> <p>Please have your license details to hand.</p>"},{"location":"research-software/castep/#note-on-using-relativistic-j-dependent-pseudopotentials","title":"Note on using Relativistic J-dependent pseudopotentials","text":"<p>These pseudopotentials cannot be generated on the fly by CASTEP and so are available in the following directory on ARCHER2:</p> <pre><code>/work/y07/shared/apps/core/castep/pseudopotentials\n</code></pre>"},{"location":"research-software/castep/#running-parallel-castep-jobs","title":"Running parallel CASTEP jobs","text":"<p>The following script will run a CASTEP job using 2 nodes (256 cores). it assumes that the input files have the file stem <code>text_calc</code>.</p> <pre><code>#!/bin/bash\n\n# Request 2 nodes with 128 MPI tasks per node for 20 minutes\n#SBATCH --job-name=CASTEP\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Load the CASTEP module, avoid any unintentional OpenMP threading by\n# setting OMP_NUM_THREADS, and launch the code.\nmodule load castep\nexport OMP_NUM_THREADS=1\nsrun --distribution=block:block --hint=nomultithread castep.mpi test_calc\n</code></pre>"},{"location":"research-software/castep/#using-serial-castep-tools","title":"Using serial CASTEP tools","text":"<p>Serial CASTEP tools are available in the standard CASTEP module.</p>"},{"location":"research-software/castep/#compiling-castep","title":"Compiling CASTEP","text":"<p>The latest instructions for building CASTEP on ARCHER2 may be found in the GitHub repository of build instructions:</p> <ul> <li>Build instructions for CASTEP on      GitHub</li> </ul>"},{"location":"research-software/cesm-further-examples/","title":"Further Examples CESM 2.1.3","text":"<p>In the process of porting CESM 2.1.3 to ARCHER2, a set of 4 long runs were carried out. This page contains the four example cases which have been validated with longer runs. They vary in the numbers of cores or threads used, but included here are the PE layouts used in these validation runs, which can be used as a guide for other runs. While only these four compsets and grids have been validated, CESM2 is not bound to just these cases. Links to the UCAR/NCAR pages on configurations, compsets and grids are in the useful links section of the CESM2.1.3 on ARCHER2 page, which can be used to find many of the defined compsets for CESM2.1.3.</p>"},{"location":"research-software/cesm-further-examples/#atmosphere-only-f2000climo","title":"Atmosphere-only / F2000climo","text":"<p>This compset uses the F09 grid which is roughly equivalent to a 1 degree resolution. On ARCHER2 with four nodes this configuration should give a throughput of around 7.8 simulated years per (wallclock) day (SYPD). The commands to set up and run the case are as follows:</p> <pre><code>${CIMEROOT}/scripts/create_newcase --case [case name] --compset F2000climo --res f09_f09_mg17 --walltime [enough time] --project [project code]\ncd [case directory]\n./xmlchange NTASKS=512,NTASKS_ESP=1\n[Any other changes e.g. run length or resubmissions]\n./case.setup\n./case.build\n./case.submit\n</code></pre>"},{"location":"research-software/cesm-further-examples/#slab-ocean-etest","title":"Slab Ocean / ETEST","text":"<p>The slab ocean case is similar to the atmosphere-only case in terms of resources needed, as the slab ocean is inexpensive to simulate in comparison to the atmosphere. The setup detailed below uses two OMP threads, and more tasks than were used by the F2000climo case, and so a throughput of around 20 SYPD can be expected. Unlike F2000climo, but like most compsets, this is unsupported (meaning it has not been scientifically verified by NCAR personnel) and as such an extra argument is required when creating the case. The arguments for ROOTPE are to guard against poor decisions being automatically chosen with respect to resources.</p> <pre><code>${CIMEROOT}/scripts/create_newcase --case [case name] --compset ETEST --res f09_g17 --walltime [enough time] --project [project code] --run-unsupported\ncd [case directory]\n./xmlchange NTASKS=1024,NTASKS_ESP=1\n./xmlchange NTHRDS=2\n./xmlchange ROOTPE_ICE=0,ROOTPE_OCN=0\n[Any other changes e.g. run length or resubmissions]\n./case.setup\n./case.build\n./case.submit\n</code></pre>"},{"location":"research-software/cesm-further-examples/#coupled-ocean-b1850","title":"Coupled Ocean / B1850","text":"<p>Compsets with the <code>B</code> prefix are fully coupled, and actively simulate all components. As such, This case is more expensive to run, most especially the ocean component. This case can be set up to run on dedicated nodes by changing the <code>$ROOTPE</code> variables (run the ./pelayout command to check that you have things as you wish). This should give a throughput of just over 10 SYPD.</p> <pre><code>${CIMEROOT}/scripts/create_newcase --case [case name] --compset B1850 --res f09_g17 --walltime [enough time] --project [project name]\ncd [case directory]\n./xmlchange NTASKS_CPL=1024,NTASKS_ICE=256,NTASKS_LND=256,NTASKS_GLC=128,NTASKS_ROF=128,NTASKS_WAV=256,NTASKS_OCN=512,NTASKS_ATM=1024\n./xmlchange ROOTPE_CPL=0,ROOTPE_ICE=0,ROOTPE_LND=256,ROOTPE_GLC=512,ROOTPE_ROF=640,ROOTPE_WAV=768,ROOTPE_OCN=1024,ROOTPE_ATM=0\n[Any other changes e.g. run length or resubmissions]\n./case.setup\n./case.build\n./case.submit\n</code></pre> <p>You can also define the PE layout in terms of full nodes by using negative values. As such, for a <code>$MAX_MPITASKS_PER_NODE=128</code> and <code>$MAX_TASKS_PER_NODE=128</code>, the below is equivalent to the above:</p> <pre><code>${CIMEROOT}/scripts/create_newcase --case [case name] --compset B1850 --res f09_g17 --walltime [enough time] --project [project name]\ncd [case directory]\n./xmlchange NTASKS_CPL=-8,NTASKS_ICE=-2,NTASKS_LND=-2,NTASKS_GLC=-1,NTASKS_ROF=-1,NTASKS_WAV=-2,NTASKS_OCN=-4,NTASKS_ATM=-8\n./xmlchange ROOTPE_CPL=0,ROOTPE_ICE=0,ROOTPE_LND=-2,ROOTPE_GLC=-4,ROOTPE_ROF=-5,ROOTPE_WAV=-6,ROOTPE_OCN=-8,ROOTPE_ATM=0\n[Any other changes e.g. run length or resubmissions]\n./case.setup\n./case.build\n./case.submit\n</code></pre>"},{"location":"research-software/cesm-further-examples/#waccm-x-fxhist","title":"WACCM-X / FXHIST","text":"<p>The WACCM-X case needs care during the set up and running for a couple of reasons. Firstly, as mentioned in the known issues section on archiving errors the short-term archiver can sometimes move too many files and thus create problems with resubmissions. Secondly, it can pick up other files in the cesm_inputdata directory, causing issues when running. WACCM-X is also comparatively very expensive, and so only has an expected throughput of a little over 1.5 SYPD, and that when on a coarser grid than above. The setup for running a WACCM-X case with approximately 2 degree resolution and no short-term archiving is</p> <pre><code>${CIMEROOT}/scripts/create_newcase --case [case name] --compset FXHIST --res f19_f19_mg16 --walltime [enough time] --project [project name] --run-unsupported\ncd [case directory]\n./xmlchange NTASKS=512,NTASKS_ESP=1\n./xmlchange NTHRDS=2\n./xmlchange DOUT_S=FALSE\n[Any other changes e.g. run length or resubmissions]\n./case.setup\n./case.build\n./case.submit\n</code></pre>"},{"location":"research-software/cesm/","title":"Community Earth System Model (CESM2)","text":"<p>CESM2 is a fully-coupled, community, global climate model that provides state-of-the-art computer simulations of the Earth's past, present, and future climate states. It has seven different components: atmosphere, ocean, river run off, sea ice, land ice, waves and adaptive river transport. </p> <p>Important</p> <p>CESM is not part of the officially supported software on ARCHER2. While the ARCHER2 service desk is able to provide support for basic use of this software (e.g. access to software, writing job submission scripts) it does not generally provide detailed technical support for the software and you may be directed to seek support from other places if the service desk cannot answer the questions.</p>"},{"location":"research-software/cesm/#cesm-213","title":"CESM 2.1.3","text":"<p>At the time of writing, CESM 2.1.3 is the latest scientifically verified version of the model.</p>"},{"location":"research-software/cesm/#setting-up-cesm-213-on-archer2","title":"Setting up CESM 2.1.3 on ARCHER2","text":"<p>Due to the nature of CESM2, there is not a centrally installed version of the program available on ARCHER2. Instead, users download their own copy of the program and make use of ARCHER2-specific configurations that have been rigorously tested.</p> <p>The setup process has been streamlined on ARCHER2 and can be carried out by following the instructions on the ARCHER2 CESM2.1.3 setup page</p>"},{"location":"research-software/cesm/#using-cesm-213-on-archer2","title":"Using CESM 2.1.3 on ARCHER2","text":"<p>A quickstart guide for running a simple coupled case of CESM 2.1.3 on ARCHER2 can be found here. It should be noted that this is only a quickstart guide with a focus on the way that CESM 2.1.3 should be run specifically on ARCHER2, and is not intended to replace the larger CESM or CIME documentation linked to below.</p>"},{"location":"research-software/cesm/#useful-links","title":"Useful Links","text":""},{"location":"research-software/cesm/#documentation","title":"Documentation","text":"<p>If this is your first time running CESM2, it is highly recommended that you consult both the CIME documentation and the NCAR CESM pages for the version used in CESM 2.1.3, paying particular attention to the pages on Basic Usage of CIME which gives detailed description of the basic commands needed to get a model running.</p>"},{"location":"research-software/cesm/#compsets-and-configurations","title":"Compsets and Configurations","text":"<p>CESM2 allows simulations to be carried out using a very wide range of configurations. If you are new to CESM2 it is highly recommended that, unless you are running a case you are already familiar with, you consult the CESM2.1 Configurations page. You can also see a list of the defined compsets already available on the component set definitions page. More information about configurations, grids and compsets can be found on the CESM2 Configurations and Grids page, which includes links to the configuration settings of the different components.</p>"},{"location":"research-software/cesm213_run/","title":"Quick Start: CESM Model Workflow (CESM 2.1.3)","text":"<p>This is the procedure for quickly setting up and running a simple CESM2 case on ARCHER2. This document is based on the general quickstart guide for CESM 2.1, with modifications to give instructions specific to ARCHER2. For more expansive instructions on running CESM 2.1, please consult the NCAR CESM pages</p> <p>Before following these instructions, ensure you have completed the setup procedure (see Setting up CESM2 on ARCHER2).</p> <p>For your target case, the first step is to select a component set, and a resolution for your case. For the purposes of this guide, we will be looking at a simple coupled case using the <code>B1850</code> compset and the <code>f19_g17</code> resolution.</p> <p>The current configuration of CESM 2.1.3 on ARCHER2 has been validated with the F2000 (atmosphere only), ETEST (slab ocean), B1850 (fully coupled) and FX2000 (WACCM-X) compsets. Instructions for these are here: CESM2.1.3 further examples.</p> <p>Details of available component sets and resolutions are available from the query_config tool located in the <code>my_cesm_sandbox/cime/scripts</code> directory</p> <pre><code>cd my_cesm_sandbox/cime/scripts\n./query_config --help\n</code></pre> <p>See the supported component sets, supported model resolutions and supported machines for a complete list of CESM2 supported component sets, grids and computational platforms.</p> <p>Note: Variables presented as <code>$VAR</code> in this guide typically refer to variables in XML files in a CESM case. From within a case directory, you can determine the value of such a variable with <code>./xmlquery VAR</code>. In some instances, <code>$VAR</code> refers to a shell variable or some other variable; we try to make these exceptions clear.</p>"},{"location":"research-software/cesm213_run/#preparing-a-case","title":"Preparing a case","text":"<p>There are three stages to preparing the case: create, setup and build. Here you can find information on each of these steps</p>"},{"location":"research-software/cesm213_run/#1-create-a-case","title":"1. Create a case","text":"<p>The create_newcase command creates a case directory containing the scripts and XML files to configure a case (see below) for the requested resolution, component set, and machine. create_newcase has three required arguments: <code>--case</code>, <code>--compset</code> and <code>--res</code> (invoke create_newcase --help for help).</p> <p>On machines where a project or account code is needed (including ARCHER2), you must either specify the <code>--project</code> argument to create_newcase or set the <code>$PROJECT</code> variable in your shell environment.</p> <p>If running on a supported machine, that machine will normally be recognized automatically and therefore it is not required to specify the <code>--machine</code> argument to create_newcase. For CESM 2.1.3, ARCHER2 is classed as an unsupported machine, however the configurations for ARCHER2 are included in the version of cime downloaded in the setup process, and so adding the <code>--machine</code> flag should not be necessary.</p> <p>Invoke create_newcase as follows:</p> <pre><code>./create_newcase --case CASENAME --compset COMPSET --res GRID --project PROJECT\n</code></pre> <p>where:</p> <ul> <li><code>CASENAME</code> defines the name of your case (stored in the <code>$CASE</code> XML     variable). This is a very important piece of metadata that will be     used in filenames, internal metadata and directory paths.     create_newcase will create the case directory with the same     name as the <code>CASENAME</code>. If <code>CASENAME</code> is simply a name (not a path),     the case directory is created in the directory where you executed     create_newcase. If <code>CASENAME</code> is a relative or absolute path, the     case directory is created there, and the name of the case will be     the last component of the path. The full path to the case directory     will be stored in the <code>$CASEROOT</code> XML variable. See CESM2     Experiment     Casenames     for details regarding CESM experiment case naming conventions.</li> <li><code>COMPSET</code> is the component set.</li> <li><code>GRID</code> is the model     resolution.</li> <li><code>PROJECT</code> is you project code on ARCHER2.</li> </ul> <p>Here is an example on ARCHER2 with the CESM2 module loaded:</p> <pre><code>$CIMEROOT/scripts/create_newcase --case $CESM_ROOT/runs/b.e20.B1850.f19_g17.test --compset B1850 --res f19_g17 --project n02\n</code></pre>"},{"location":"research-software/cesm213_run/#2-setting-up-the-case-run-script","title":"2. Setting up the case run script","text":"<p>Issuing the case.setup command creates scripts needed to run the model along with namelist <code>user_nl_xxx</code> files, where xxx denotes the set of components for the given case configuration. Before invoking case.setup, modify the <code>env_mach_pes.xml</code> file in the case directory using the xmlchange command as needed for the experiment.</p> <p>cd to the case directory. Following the example from above:</p> <pre><code>cd $CESM_ROOT/runs/b.e20.B1850.f19_g17.test\n</code></pre> <p>Invoke the case.setup command.</p> <pre><code>./case.setup\n</code></pre> <p>If any changes are made to the case, case.setup can be re-run using</p> <pre><code>./case.setup --reset\n</code></pre>"},{"location":"research-software/cesm213_run/#3-build-the-executable-using-the-casebuild-command","title":"3. Build the executable using the case.build command","text":"<p>Run the build script.</p> <pre><code>./case.build\n</code></pre> <p>This build may take a while to run, and have periods where the build process doesn't seem to be doing anything. You should only cancel the build if there has been no activity by the build script after 15 minutes.</p> <p>The CESM executable will appear in the directory given by the XML variable <code>$EXEROOT</code>, which can be queried using:</p> <pre><code>./xmlquery EXEROOT\n</code></pre> <p>by default, this will be the <code>bld</code> directory in your case directory.</p> <p>If any changes are made to xml parameters that would necessitate rebuilding (see the Making Changes section below), then you can apply these by running</p> <pre><code>./case.setup --reset\n./case.build --clean-all\n./case.build\n</code></pre>"},{"location":"research-software/cesm213_run/#input-data","title":"Input Data","text":"<p>Each case of CESM will require input data, which is downloaded from UCAR servers. Input data from similar compsets is often reused, so running two similar cases may not require downloading any additional input data for the second case.</p> <p>You can check to see if the required input data is already in your input data directory using</p> <pre><code>./check_input_data\n</code></pre> <p>If it is not present you can download the input data for the case prior to running the case using</p> <pre><code>./check_input_data --download\n</code></pre> <p>This can be useful for cases where a large amount of data is needed, as you can write a simple slurm script to run this download on the serial queue. Information on creating job submission scripts can be found on the ARCHER2 page on Running Jobs.</p> <p>Downloading the case input data at this stage is optional, and if skipped the data will be downloaded using the login node when you run the case.submit script. This may cause the case.submit script to take a long time to download.</p> <p>An important thing to note is that your input data will be stored in your /work area, and will contribute to your storage allocation. These input files can sometimes take up a large amount of space, and so it is recommended that you do not keep any input data that is no longer needed.</p>"},{"location":"research-software/cesm213_run/#making-changes-to-a-case","title":"Making changes to a case","text":"<p>After creating a new case, the CIME functions can be used to make changes to the case setup, such as changing the wallclock time, number of cores etc.</p> <p>You can query settings using the xmlquery script from your case directory:</p> <pre><code>./xmlquery &lt;name_of_setting&gt;\n</code></pre> <p>Adding the <code>-p</code> flag allows you to look up partial names, for example</p> <pre><code>$ ./xmlquery -p JOB\n\nOutput:\nResults in group case.run\n        JOB_QUEUE: standard\n        JOB_WALLCLOCK_TIME: 01:30:00\n\nResults in group case.st_archive\n        JOB_QUEUE: short\n        JOB_WALLCLOCK_TIME: 0:20:00\n</code></pre> <p>Here all parameters that match the <code>JOB</code> pattern are returned. It is worth noting that the parameters <code>JOB_QUEUE</code> and <code>JOB_WALLCLOCK_TIME</code> are present for both the case.run job and the case.st_archive job. To view just one of these, you can use the <code>--subgroup</code> flag:</p> <pre><code>$ ./xmlquery -p JOB --subgroup case.run\n\nOutput:\nResults in group case.run\n        JOB_QUEUE: standard\n        JOB_WALLCLOCK_TIME: 01:30:00\n</code></pre> <p>When you know which setting you want to change, you can do so using the xmlchange command</p> <pre><code>./xmlchange &lt;name_of_setting&gt;=&lt;new_value&gt;\n</code></pre> <p>For example to change the wallclock time for the case.run job to 30 minutes, without knowing the exact name, you could do</p> <pre><code>$ ./xmlquery -p WALLCLOCK\n\nOutput:\nResults in group case.run\n        JOB_WALLCLOCK_TIME: 24:00:00\n\nResults in group case.st_archive\n        JOB_WALLCLOCK_TIME: 0:20:00\n\n$ ./xmlchange JOB_WALLCLOCK_TIME=00:30:00 --subgroup case.run\n\n$ ./xmlquery JOB_WALLCLOCK_TIME\n\nOutput:\nResults in group case.run\n        JOB_WALLCLOCK_TIME: 00:30:00\n\nResults in group case.st_archive\n        JOB_WALLCLOCK_TIME: 0:20:00\n</code></pre> <p>Note: If you try to set a parameter equal to a value that is not known to the program, it might suggest using a <code>--force</code> flag. This may be useful, for example, in the case of using a queue that has not been configured yet, but use with care!</p> <p>Some changes to the case must be done before calling <code>./case.setup</code> or <code>./case.build</code>, otherwise the case will need to be reset or cleaned, using <code>./case.setup --reset</code> and <code>./case.build --clean-all</code>. These are as follows:</p> <ul> <li> <p>Before calling <code>./case.setup</code>, changes to <code>NTASKS</code>, <code>NTHRDS</code>, <code>ROOTPE</code>, <code>PSTRID</code> and <code>NINST</code> must be made, as well as any changes to the <code>env_mach_specific.xml</code> file, which contains some configuration for the module environment and environment variables.</p> </li> <li> <p>Before calling <code>./case.build</code>, <code>./case.setup</code> must have been called and any changes to <code>env_build.xml</code> and <code>Macros.make</code> must have been made. This includes whether you have edited the file directly, or used <code>./xmlchange</code> to alter the variables.</p> </li> </ul> <p>Many of the namelist variables can be changed just before calling <code>./case.submit</code>.</p>"},{"location":"research-software/cesm213_run/#run-the-case","title":"Run the case","text":"<p>Modify runtime settings in <code>env_run.xml</code> (optional). At this point you may want to change the running parameters of your case, such as run length. By default, the model is set to run for 5 days based on the <code>$STOP_N</code> and <code>$STOP_OPTION</code> variables:</p> <pre><code>./xmlquery STOP_OPTION,STOP_N\n</code></pre> <p>These default settings can be useful in troubleshooting runtime problems before submitting for a longer time, but will not allow the model to run long enough to produce monthly history climatology files. In order to produce history files, increase the run length to a month or longer:</p> <pre><code>./xmlchange STOP_OPTION=nmonths,STOP_N=1\n</code></pre> <p>If you want a longer run, for example 30 years, this cannot be done in a single job as the amount of wallclock time required would be considerably longer than the maximum allowed by the ARCHER2 queue system. To do this, you would split the simulation into appropriate chunks, such as 6 chunks of 5 years (assuming a simulated years per day (SYPD) of greater than 5 - some values for SYPD on ARCHER2 are given in the further examples page). Using the <code>$RESUBMIT</code> xml variable and setting the values of the <code>$STOP_OPTION</code> and <code>$STOP_N</code> variables accordingly you can then chain the running of these chunks:</p> <pre><code>./xmlchange RESUBMIT=6, STOP_OPTION= nyears, and STOP_N= 5\n</code></pre> <p>This would then run 6 resubmissions, each new job picking back up where the previous job had stopped. For more information about this, see the user guide page on running a case.</p> <p>Once you have set your job to run for the correct length of time, it is a good idea to check the correct amount of resource is available for the job. You can quickly check the job submission parameters by running</p> <pre><code>./preview_run\n</code></pre> <p>which will show you at a glance the wallclock times, job queues and the list of jobs to be submitted, as well as other parameters such as the number of MPI tasks, number of OpenMP threads.</p> <p>Submit the job to the batch queue using the case.submit command.</p> <pre><code>./case.submit\n</code></pre> <p>The case.submit script will submit a job called .case.run, and if <code>$DOUT_S</code> is set to <code>TRUE</code> it will also submit a short-term archiving job. By default, the queue these jobs are submitted to is the <code>standard</code> queue. For information on the resources available on each queue, see the QOS guide.</p> <p>Note: There is a small possibility that your job may initially fail with the error message <code>ERROR: Undefined env var 'CESM_ROOT'</code>. This could have two causes: 1. You do not have the CESM2/2.1.3 module loaded. This module needs to be loaded when running the case as well as when building the case. Try running again after having run <code>module load CESM2/2.1.3</code> 2. This could also be due to a known issue with ARCHER2 where adding the SBATCH directive <code>export=ALL</code> to a slurm script will not work (see the ARCHER2 known issues entry on the subject). The ARCHER2 configuration included in the version of cime that was downloaded during setup should apply a work-around to this, and so you should not see this error in this case. It may still occur in some corner cases however. To avoid this, ensure that the environment from which you are submitting your case has the CESM2/2.1.3 module loaded and run the case.submit script with the following command <pre><code>./case.submit -a=--export=ALL\n</code></pre></p> <p>When the job is complete, most output will not necessarily be written under the case directory, but instead under some other directories. Review the following directories and files, whose locations can be found with xmlquery (note: xmlquery can be run with a list of comma separated names and no spaces):</p> <pre><code>./xmlquery RUNDIR,CASE,CASEROOT,DOUT_S,DOUT_S_ROOT\n</code></pre> <ul> <li> <p><code>$RUNDIR</code></p> <p>This directory is set in the <code>env_run.xml</code> file. This is the location where CESM2 was run. There should be log files there for every component (i.e. of the form cpl.log.yymmdd-hhmmss) if <code>$DOUT_S == FALSE</code>. Each component writes its own log file. Also see whether any restart or history files were written. To check that a run completed successfully, check the last several lines of the cpl.log file for the string \\\"SUCCESSFUL TERMINATION OF CPL7-cesm\\\".</p> </li> <li> <p><code>$DOUT_S_ROOT/$CASE</code></p> <p><code>$DOUT_S_ROOT</code> refers to the short-term archive path location on local disk. This path is used by the case.st_archive script when <code>$DOUT_S = TRUE</code>. See CESM Model Output File Locations for details regarding the component model output filenames and locations.</p> <p><code>$DOUT_S_ROOT/$CASE</code> is the short-term archive directory for this case. If <code>$DOUT_S</code> is FALSE, then no archive directory should exist. If <code>$DOUT_S</code> is TRUE, then log, history, and restart files should have been copied into a directory tree here.</p> </li> <li> <p><code>$DOUT_S_ROOT/$CASE/logs</code></p> <p>The log files should have been copied into this directory if the run completed successfully and the short-term archiver is turned on with <code>$DOUT_S = TRUE</code>. Otherwise, the log files are in the <code>$RUNDIR</code>.</p> </li> <li> <p><code>$CASEROOT</code></p> <p>There could be standard out and/or standard error files output from the batch system.</p> </li> <li> <p><code>$CASEROOT/CaseDocs</code></p> <p>The case namelist files are copied into this directory from the <code>$RUNDIR</code>.</p> </li> <li> <p><code>$CASEROOT/timing</code></p> <p>There should be two timing files there that summarize the model performance.</p> </li> </ul>"},{"location":"research-software/cesm213_run/#monitoring-jobs","title":"Monitoring Jobs","text":"<p>As CESM jobs are submitted to the ARCHER2 batch system, they can be monitored in the same way as other jobs, using the command</p> <pre><code>squeue -u $USER\n</code></pre> <p>You can get more details about the batch scheduler by consulting the ARCHER2 scheduling guide.</p>"},{"location":"research-software/cesm213_run/#archiving","title":"Archiving","text":"<p>The CIME framework allows for short-term and long-term archiving of model output. This is particularly useful when the model is configured to output to a small storage space and large files may need to be moved during larger simulations. On ARCHER2, the model is configured to use short-term archiving, but not yet configured for long-term archiving.</p> <p>Short-term archiving is on by default for compsets and can be toggled on and off using the DOUT_S parameter set to True or False using the xmlchange script:</p> <pre><code>./xmlchange DOUT_S=FALSE\n</code></pre> <p>When <code>DOUT_S=TRUE</code>, calling ./case.submit will automatically submit a \u201cst_archive\u201d job to the batch system that will be held in the queue until the main job is complete. This can be configured in the same way as the main job for a different queue, wallclock time, etc. One change that may be advisable to make would be to change the queue your st_archive job is submitted to, as archiving does not require a large amount of resources and the short and serial queues on ARCHER2 do not use your project allowance. This would be done using the xmlchange script almost the same as for the case.run job. Note that the main job and the archiving job share some parameter names such as <code>JOB_QUEUE</code>, and so a flag (--subgroup) specifying which you want to change should be used, as below:</p> <pre><code>./xmlchange JOB_QUEUE=short --subgroup case.st_archive\n</code></pre> <p>If the <code>--subgroup</code> flag is not used, then the <code>JOB_QUEUE</code> value for both the case.run and case.st_archive jobs will be changed. You can verify that they are different by running</p> <pre><code>./xmlquery JOB_QUEUE\n</code></pre> <p>which will show the value of this parameter for both jobs.</p> <p>The archive is set up to move <code>.nc</code> files and logs from <code>$CESM_ROOT/runs/$CASE</code> to <code>$CESM_ROOT/archive/$CASE</code>. As such, your <code>/work</code> storage quota is being used whether archiving is switched on or off, and so it would be recommended that data you wish to retain be moved to another service such as a group workspace on JASMIN. See the Data Management and Transfer guide for more information on archiving data from ARCHER2. If you want to archive your files directly to a different location than the default, this can be set using the <code>$DOUT_S_ROOT</code> parameter.</p>"},{"location":"research-software/cesm213_run/#troubleshooting","title":"Troubleshooting","text":"<p>If a run fails, the first place to check is the run submission output file, usually located at</p> <pre><code>$CASEROOT/run.$CASE\n</code></pre> <p>so, for the example job run in this guide, the output file will be at</p> <pre><code>$CESM_ROOT/runs/b.e20.B1850.f19_g17.test/run.b.e20.B1850.f19_g17.test\n</code></pre> <p>If any errors have occurred, the location of the relevant log in which you can examine this error will be printed towards the end of this output file. The log will usually be located at</p> <pre><code>$CASEROOT/run/cesm.log.*\n</code></pre> <p>so in this case, the path would be</p> <pre><code>$CESM_ROOT/runs/b.e20.B1850.f19_g17.test/run/cesm.log.*\n</code></pre>"},{"location":"research-software/cesm213_run/#known-issues-and-common-problems","title":"Known Issues and Common Problems","text":""},{"location":"research-software/cesm213_run/#input-data-errors","title":"Input data errors","text":"<p>Occasionally, the input data for a case is not downloaded correctly. Unfortunately, in these cases the checksum test run by the <code>check_input_data</code> script will not catch the corrupted fields in the file. The error message displayed can vary somewhat, but a common error message is</p> <pre><code>ERROR timeaddmonths(): MM out of range\"\n</code></pre> <p>You can often spot these errors by examining the log as described above, as the error will occur shortly after a file has been read. If this happens, delete the file in question from your <code>cesm_inputdata</code> directory and rerun</p> <p><pre><code>./check_input_data --download\n</code></pre> to ensure that the data is downloaded correctly.</p>"},{"location":"research-software/cesm213_run/#sigfpe-errors","title":"SIGFPE errors","text":"<p>If running a case with the DEBUG flag enabled, you may see some SIGFPE errors. In this case, the traceback shown in the logs will show the error as originating in one of three places:</p> <ul> <li>$CESM_ROOT/components/cam/src/physics/cam/micro_mg2_0.F90:1651</li> <li>$CESM_ROOT/components/clm/src/biogeochem/ch4Mod.F90:3555</li> <li>$CESM_ROOT/components/ww3/src/cpl_mct/wav_comp_mct.F90:761</li> </ul> <p>This problem is caused by 'short-circuit' logic in the affected files, where there may be a conditional of the form</p> <p><pre><code>if (A .and. B) then....\n</code></pre> where B cannot be properly evaluated if A fails, for example</p> <p><pre><code>if ( x /= 0 .and. y/x &gt; c ) then....\n</code></pre> which would result in a divide-by-zero error if the second condition was evaluated after the first condition had already failed.</p> <p>In standard simulations, the second condition would be skipped in these cases however if the user has set</p> <pre><code>./xmlchange DEBUG=TRUE\n</code></pre> <p>then the second condition will not be skipped and a SIGFPE error will occur.</p> <p>If encountering these errors, a user can do one of two things. The simplest solution is to turn off the DEBUG flag with</p> <p><pre><code>./xmlchange DEBUG=TRUE\n</code></pre> If this option is not possible however, and your simulation absolutely needs to be run in DEBUG mode, then the conditional can be modified in the program code. THIS IS DONE AT YOUR OWN RISK!!! The fix that has been applied for the WW3 component can be seen here. It is recommended that if you are making any changes to the code for this reason, that you revert your changes back once you no longer need to run your case in DEBUG mode.</p>"},{"location":"research-software/cesm213_run/#sigsegv-errors","title":"SIGSEGV errors","text":"<p>Sometimes an error will occur where a run is ended prematurely and gives an error of the form</p> <pre><code>Program received signal SIGSEGV: Segmentation fault - invalid memory reference.\n</code></pre> <p>This can often be solved by increasing the amount of available memory per task, either by changing the maximum number of MPI tasks per node by using</p> <pre><code>./xmlchange MAX_TASKS_PER_NODE=64\n</code></pre> <p>or by increasing the number of threads used by using</p> <pre><code>./xmlchange NTHRDS=2\n</code></pre> <p>This will double the amount of memory available for each physical core</p>"},{"location":"research-software/cesm213_run/#archiving-errors","title":"Archiving Errors","text":"<p>When running WACCM-X cases (compsets starting FX*), there can sometimes be problems when running restart jobs. This is caused by the short-term archiving job mistakenly moving files needed for restarts to the archive. To ensure this does not happen, it can be a good idea when running WACCM-X simulations to turn off the short-term archiver using</p> <pre><code>./xmlchange DOUT_S=FALSE\n</code></pre> <p>While this behaviour has so far only been observed for WACCM-X jobs, it is possible that this behaviour can occur with other compsets</p>"},{"location":"research-software/cesm213_run/#job-failing-instantly-with-undefined-environment-variable","title":"Job Failing instantly with undefined environment variable","text":"<p>There is a small possibility that your job may initially fail with the error message</p> <p><pre><code>ERROR: Undefined env var 'CESM_ROOT'\n</code></pre> This could have two causes: 1. You do not have the CESM2/2.1.3 module loaded. This module needs to be loaded when running the case as well as when building the case. Try running again after having run <code>module load CESM2/2.1.3</code> 2. This could also be due to a known issue with ARCHER2 where adding the SBATCH directive <code>export=ALL</code> to a slurm script will not work (see the ARCHER2 known issues entry on the subject). The ARCHER2 configuration included in the version of cime that was downloaded during setup should apply a work-around to this, and so you should not see this error in this case. It may still occur in some corner cases however. To avoid this, ensure that the environment from which you are submitting your case has the CESM2/2.1.3 module loaded and run the case.submit script with the following command <pre><code>./case.submit -a=--export=ALL\n</code></pre></p>"},{"location":"research-software/cesm213_setup/","title":"First-Time setup of CESM 2.1.3","text":"<p>Due to the nature of the CESM program, a centrally installed version of the code is not provided on ARCHER2. Instead, a user needs to download and set up the program themselves in their <code>/work</code> area. The installation is done in three steps:</p> <ol> <li>Download the code and set up the directory structure</li> <li>Link and Download Components</li> <li>Build CPRNC</li> </ol> <p>After setup, CESM is ready to run a simple case.</p>"},{"location":"research-software/cesm213_setup/#downloading-cesm-213-and-setting-up-the-directory-structure","title":"Downloading CESM 2.1.3 And Setting Up The Directory Structure","text":"<p>For ease of use, a setup script has been created which downloads CESM 2.1.3, creates the directory structure needed for running CESM2 cases and creates a hidden file in your home directory containing environment variables needed by CESM.</p> <p>To execute this script, run the following in an archer2 terminal</p> <pre><code>source /work/n02/shared/CESM2/setup_cesm213.sh\n</code></pre> <p>This script will create a directory, defaulting to <code>/work/$GROUP/$GROUP/$USER/cesm/CESM2.1.3</code>, where <code>$GROUP</code> is your default group, for example n02, and populate it with the following subdirectories: * <code>archive</code> - short-term archiving for completed runs, * <code>ccsm_baselines</code> - baseline files, * <code>cesm_inputdata</code> - input data downloaded and used when running cases, * <code>runs</code> - location of the case files used when running a case, * cesm directory - location of the cesm source code and the various components. Defaults to <code>my_cesm_sandbox</code></p> <p>The default locations for the CESM root directory and the CESM location can be overridden during installation either by entering new paths at runtime when prompted or by providing them as command line arguments, for example</p> <pre><code>source /work/n02/shared/CESM2/setup_cesm213.sh -p /work/n03/n03/$USER/CESM213 -l cesm_prog\n</code></pre>"},{"location":"research-software/cesm213_setup/#manual-setup-instructions","title":"Manual setup instructions","text":"<p>If you have trouble with running the setup script, you can install manually by running the following commands:</p> <pre><code>PREFIX=\"path/to/your/desired/cesm/root/location\"\nCESM_DIR_LOC=\"name_of_install_directory_for_cesm\"\n\nmkdir -p $PREFIX\ncd $PREFIX\nmkdir -p archive\nmkdir -p ccsm_baselines\nmkdir -p cesm_inputdata\nmkdir -p runs\n\nCESM_LOC=$PREFIX/$CESM_DIR_LOC\n\ngit clone -b release-cesm2.1.3  https://github.com/ESCOMP/CESM.git $CESM_LOC\ncd $CESM_LOC\ngit checkout release-cesm2.1.3\n\ntee ${HOME}/.cesm213 &lt;&lt;EOF &gt; /dev/null\n### CESM 2.1.3 on ARCHER2 Path File\n### Do Not Edit This File Unless You Know What You Are Doing\nCIME_MODEL=cesm\nCESM_ROOT=$PREFIX\nCESM_LOC=$PREFIX/$CESM_DIR_LOC\nCIMEROOT=$PREFIX/$CESM_DIR_LOC/cime\nEOF\n\necho \"module use /work/n02/shared/CESM2/module\" &gt;&gt; ~/.bashrc\nmodule use /work/n02/shared/CESM2/module\nmodule load CESM2/2.1.3\n</code></pre>"},{"location":"research-software/cesm213_setup/#linking-and-downloading-components","title":"Linking And Downloading Components","text":"<p>CESM utilises multiple components, including CAM (atmosphere), CICE (sea ice), CISM (ice sheets), CTSM (land), MOSART (adaptive river transport), POP2 (ocean), RTM (river transport) and WW3 (waves), all of which are connected using the Common Infrastructure for Modelling the Earth (CIME). These components are hosted on github, and during the setup process they are downloaded.</p> <p>Before downloading the external components, you must first modify the file <code>$CESM_LOC/Externals.cfg</code>. This will change the version of CIME from the default cime 5.6.32 to the maintained cime 5.6 branch. This is done by modifying the file so that the cime section goes from</p> <pre><code>[cime]\ntag = cime5.6.32\nprotocol = git\nrepo_url = https://github.com/ESMCI/cime\nlocal_path = cime\nrequired = True\n</code></pre> <p>to</p> <pre><code>[cime]\nbranch = maint-5.6\nprotocol = git\nrepo_url = https://github.com/ESMCI/cime\nlocal_path = cime\nrequired = True\n</code></pre> <p>By making this change, the configurations for archer2 are brought in along with some bug fixes</p> <p>Once this has been done you are free to download the external components by executing the commands</p> <pre><code>cd $CESM_LOC\n./manage_externals/checkout_externals\n</code></pre> <p>The first time you run the checkout_externals script, you may be asked to accept a certificate, and you may also get an error of the form</p> <p><pre><code>    svn: E120108: Error running context: The server unexpectedly closed the connection.\n</code></pre> If this happens, rerun the checkout_externals script and it should download the external components correctly.</p>"},{"location":"research-software/cesm213_setup/#building-cprnc","title":"Building cprnc","text":"<p>cprnc is a generic tool for analyzing a netcdf file or comparing two netcdf files. It is used in various places by CESM and the source is included with cime.</p> <p>To build, execute the following commands</p> <pre><code>module load CESM2/2.1.3\ncd $CIMEROOT/tools/cprnc\n../configure --macros-format=Makefile --mpilib=mpi-serial\nsed -i '/}}/d' .env_mach_specific.sh\nsource ./.env_mach_specific.sh &amp;&amp; make\n</code></pre> <p>It is likely you will see a warning message of the form</p> <pre><code>The following dependent module(s) are not currently loaded: cray-hdf5-parallel (required by: CESM2/2.1.3), cray-netcdf-hdf5parallel (required by: CESM2/2.1.3), cray-parallel-netcdf (required by: CESM2/2.1.3)\n</code></pre> <p>This is due to serial netCDF and hdf5 libraries being loaded as a result of the <code>--mpilib=mpi-serial</code> flag. This warning message is safe to ignore.</p> <p>In a small number of cases you may also see a warning of the form</p> <pre><code>-bash: export: '}}': not a valid identifier\n</code></pre> <p>This warning should also be safe to ignore, but can be solved by opening the file <code>./.env_mach_specific.sh</code> in a text editor and commenting out or deleting the line</p> <pre><code>export OMP_NUM_THREADS={{ thread_count }}\n</code></pre> <p>Then rerunning the command</p> <pre><code>source ./.env_mach_specific.sh &amp;&amp; make\n</code></pre> <p>Once this step has been completed, you are ready to run a simple test case.</p>"},{"location":"research-software/chemshell/","title":"ChemShell","text":"<p>ChemShell is a script-based chemistry code focusing on hybrid QM/MM calculations with support for standard quantum chemical or force field calculations. There are two versions: an older Tcl-based version Tcl-ChemShell and a more recent python-based version Py-ChemShell.</p> <p>The advice from https://www.chemshell.org/licence on the difference is:</p> <p>We regard Py-ChemShell 21.0 as suitable for production calculations on  materials systems, and would encourage materials modellers to consider  switching from Tcl-ChemShell to Py-ChemShell if they haven't already  done so.</p> <p>Py-ChemShell 21.0 is the first beta release to include support for  calculations on biomolecular systems, including a guided protein solvation  workflow and automated import of CHARMM and AMBER forcefields for  biomolecular QM/MM calculations. We encourage experienced ChemShell users  to try the new functionality and send us feedback on your experience. For  new users, we would currently still recommend using Tcl-ChemShell for  biomolecular calculations until the next beta release of Py-ChemShell,  which is anticipated for summer 2022.</p>"},{"location":"research-software/chemshell/#useful-links","title":"Useful Links","text":"<ul> <li>ChemShell home page https://www.chemshell.org</li> <li>ChemShell documentation https://www.chemshell.org/documentation</li> <li>ChemShell forums https://www.chemshell.org/forum</li> </ul>"},{"location":"research-software/chemshell/#using-py-chemshell-on-archer2","title":"Using Py-ChemShell on ARCHER2","text":"<p>The python-based version of ChemShell is open-source and is freely available to all users on ARCHER2. The version of Py-ChemShell  pre-installed on ARCHER2 is compiled with NWChem and GULP as  libraries.</p> <p>Warning</p> <p>Py-ChemShell on ARCHER2 is compiled with  GULP 6.0. This is a licenced  software that is free to use for academics. If you are not an  academic user (or if you are using Py-ChemShell for non-academic  work), please ensure that you have the correct GULP licence before  using GULP functionalities in py-ChemShell or make sure that you  are not using any of the GULP functionalities in your code (i.e.,  do not set theory=GULP in your calculations).</p>"},{"location":"research-software/chemshell/#running-parallel-py-chemshell-jobs","title":"Running parallel Py-ChemShell jobs","text":"<p>Unlike most other ARCHER2 software packages, the Py-ChemShell module is built  in such a way as to enable users to create and submit jobs to the compute  nodes by running a <code>chemsh</code> script from the login node rather than by creating  and submitting a Slurm submission script. Below is an example command for  submitting a pure MPI Py-ChemShell job running on 8 nodes (128x8 cores) with  the <code>chemsh</code> command:</p> <pre><code>    # Run this from the login node\nmodule load py-chemshell\n\n    # Replace [budget code] below with your project code (e.g. t01)\nchemsh --submit               \\\n--jobname pychmsh      \\\n--account [budget code] \\\n--partition standard   \\\n--qos standard         \\\n--walltime 0:10:0      \\\n--nnodes 8             \\\n--nprocs 1024          \\ \npy-chemshell-job.py\n</code></pre>"},{"location":"research-software/chemshell/#using-tcl-chemshell-on-archer2","title":"Using Tcl-ChemShell on ARCHER2","text":"<p>The older version of Tcl-based ChemShell requires a license. Users with a valid license should request access via the ARCHER2 SAFE.</p>"},{"location":"research-software/chemshell/#running-parallel-tcl-chemshell-jobs","title":"Running parallel Tcl-ChemShell jobs","text":"<p>The following script will run a pure MPI Tcl-based ChemShell job using 8  nodes (128x8 cores).</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=lammps_test\n#SBATCH --nodes=8\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code] \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\nmodule load tcl-chemshell/3.7.1\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nsrun --distribution=block:block --hint=nomultithread chemsh.x input.chm\n</code></pre>"},{"location":"research-software/code-saturne/","title":"Code_Saturne","text":"<p>Code_Saturne solves the Navier-Stokes equations for 2D, 2D-axisymmetric and 3D flows, steady or unsteady, laminar or turbulent, incompressible or weakly dilatable, isothermal or not, with scalar transport if required. Several turbulence models are available, from Reynolds-averaged models to large-eddy simulation (LES) models. In addition, a number of specific physical models are also available as \"modules\": gas, coal and heavy-fuel oil combustion, semi-transparent radiative transfer, particle-tracking with Lagrangian modeling, Joule effect, electrics arcs, weakly compressible flows, atmospheric flows, rotor/stator interaction for hydraulic machines.</p>"},{"location":"research-software/code-saturne/#useful-links","title":"Useful Links","text":"<ul> <li>Code_Saturne home page</li> <li>Code_Saturne user guides</li> <li>Code_Saturne users' forum</li> </ul>"},{"location":"research-software/code-saturne/#using-code_saturne-on-archer2","title":"Using Code_Saturne on ARCHER2","text":"<p>Code_Saturne is released under the GNU General Public Licence v2 and so is freely available to all users on ARCHER2.</p> <p>You can load the default GCC build of Code_Saturne for use by running the following command:</p> <pre><code>module load code_saturne\n</code></pre> <p>This will load the default <code>code_saturne/7.0.1-gcc11</code> module. A build using the CCE compilers, <code>code_saturne/7.0.1-cce12</code>, has also been made optionally available to users on the full ARCHER2 system as testing indicates that this may provide improved performance over the GCC build.</p>"},{"location":"research-software/code-saturne/#running-parallel-code_saturne-jobs","title":"Running parallel Code_Saturne jobs","text":"<p>After setting up a case it should be initialized by running the following command from the case directory, where setup.xml is the input file:</p> <pre><code>code_saturne run --initialize --param setup.xml\n</code></pre> <p>This will create a directory named for the current date and time (e.g. 20201019-1636) inside the RESU directory. Inside the new directory will be a script named run_solver. You may alter this to resemble the script below, or you may wish to simply create a new one with the contents shown.</p> <p>If you wish to alter the existing run_solver script you will need to add all the <code>#SBATCH</code> options shown to set the job name, size and so on. You should also add the two <code>module</code> commands, and <code>srun --distribution=block:block --hint=nomultithread</code> as well as the <code>--mpi</code> option to the line executing <code>./cs_solver</code> to ensure parallel execution on the compute nodes. The <code>export LD_LIBRARY_PATH=...</code> and <code>cd</code> commands are redundant and may be retained or removed.</p> <p>This script will run an MPI-only Code_Saturne job using the default GCC build and UCX over 4 nodes (128 x 4 = 512 cores) for a maximum of 20 minutes.</p> <pre><code>#!/bin/bash\n#SBATCH --export=none\n#SBATCH --job-name=CSExample\n#SBATCH --time=0:20:0\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the GCC build of Code_Saturne 7.0.1\nmodule load cpe/21.09\nmodule load PrgEnv-gnu\nmodule load code_saturne\n\n# Switch to mpich-ucx implementation (see info note below)\nmodule swap craype-network-ofi craype-network-ucx\nmodule swap cray-mpich cray-mpich-ucx\n\n# Prevent threading.\nexport OMP_NUM_THREADS=1\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Run solver.\nsrun --distribution=block:block --hint=nomultithread ./cs_solver --mpi $@\n</code></pre> <p>The script can then be submitted to the batch system with <code>sbatch</code>.</p> <p>Info</p> <p>There is a known issue with the default MPI collectives which is causing performance issues on Code_Saturne. The suggested workaround is to switch to the mpich-ucx implementation. For this to link correctly on the full system, the extra <code>cpe/21.09</code> and <code>PrgEnv-gnu</code> modules also have to be explicitly loaded.</p>"},{"location":"research-software/code-saturne/#compiling-code_saturne","title":"Compiling Code_Saturne","text":"<p>The latest instructions for building Code_Saturne on ARCHER2 may be found in the GitHub repository of build instructions:</p> <ul> <li>Build instructions for Code_Saturne on      GitHub</li> </ul>"},{"location":"research-software/cp2k/","title":"CP2K","text":"<p>CP2K is a quantum chemistry and solid state physics software package that can perform atomistic simulations of solid state, liquid, molecular, periodic, material, crystal, and biological systems. CP2K provides a general framework for different modelling methods such as DFT using the mixed Gaussian and plane waves approaches GPW and GAPW. Supported theory levels include DFTB, LDA, GGA, MP2, RPA, semi-empirical methods (AM1, PM3, PM6, RM1, MNDO), and classical force fields (AMBER, CHARMM). CP2K can do simulations of molecular dynamics, metadynamics, Monte Carlo, Ehrenfest dynamics, vibrational analysis, core level spectroscopy, energy minimisation, and transition state optimisation using NEB or dimer method.</p>"},{"location":"research-software/cp2k/#useful-links","title":"Useful links","text":"<ul> <li>CP2K Reference Manual</li> <li>CP2K HOWTOs</li> <li>CP2K FAQs</li> </ul>"},{"location":"research-software/cp2k/#using-cp2k-on-archer2","title":"Using CP2K on ARCHER2","text":"<p>CP2K is available through the <code>cp2k</code> module. MPI only <code>cp2k.popt</code> and MPI/OpenMP Hybrid <code>cp2k.psmp</code> binaries are available.</p> <p>For ARCHER2, CP2K has been compiled with the following optional features: <code>FFTW</code> for fast Fourier transforms, <code>libint</code> to enable methods including Hartree-Fock exchange, <code>libxc</code> to provide a wider choice of exchange-correlation functionals, <code>ELPA</code> for improved performance of matrix diagonalisation, <code>PLUMED</code> to allow enhanced sampling methods.</p> <p>See CP2K compile instructions for a full list of optional features.</p> <p>If there is an optional feature not available, and which you would like, please contact the Service Desk. Experts may also wish to compile their own versions of the code (see below for instructions).</p>"},{"location":"research-software/cp2k/#running-parallel-cp2k-jobs","title":"Running parallel CP2K jobs","text":""},{"location":"research-software/cp2k/#mpi-only-jobs","title":"MPI only jobs","text":"<p>To run CP2K using MPI only, load the <code>cp2k</code> module and use the <code>cp2k.psmp</code> executable.</p> <p>For example, the following script will run a CP2K job using 4 nodes (128x4 cores):</p> <pre><code>#!/bin/bash\n\n# Request 4 nodes using 128 cores per node for 128 MPI tasks per node.\n\n#SBATCH --job-name=CP2K_test\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the relevent CP2K module\nmodule load cp2k\n\nexport OMP_NUM_THREADS=1\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nsrun --hint=nomultithread --distribution=block:block cp2k.psmp -i MYINPUT.inp\n</code></pre>"},{"location":"research-software/cp2k/#mpiopenmp-hybrid-jobs","title":"MPI/OpenMP hybrid jobs","text":"<p>To run CP2K using MPI and OpenMP, load the <code>cp2k</code> module and use the <code>cp2k.psmp</code> executable.</p> <pre><code>#!/bin/bash\n\n# Request 4 nodes with 16 MPI tasks per node each using 8 threads;\n# note this means 128 MPI tasks in total.\n# Remember to replace [budget code] below with your account code,\n# e.g. '--account=t01'.\n\n#SBATCH --job-name=CP2K_test\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=16\n#SBATCH --cpus-per-task=8\n#SBATCH --time=00:20:00\n\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the relevant CP2K module\nmodule load cp2k\n\n# Ensure OMP_NUM_THREADS is consistent with cpus-per-task above\nexport OMP_NUM_THREADS=8\nexport OMP_PLACES=cores\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nsrun --hint=nomultithread --distribution=block:block cp2k.psmp -i MYINPUT.inp\n</code></pre>"},{"location":"research-software/cp2k/#compiling-cp2k","title":"Compiling CP2K","text":"<p>The latest instructions for building CP2K on ARCHER2 may be found in the GitHub repository of build instructions:</p> <ul> <li>Build instructions for CP2K on      GitHub</li> </ul>"},{"location":"research-software/crystal/","title":"CRYSTAL","text":"<p>CRYSTAL is a general-purpose program for the study of crystalline solids. The CRYSTAL program computes the electronic structure of periodic systems within Hartree Fock, density functional or various hybrid approximations (global, range-separated and double-hybrids). The Bloch functions of the periodic systems are expanded as linear combinations of atom centred Gaussian functions. Powerful screening techniques are used to exploit real space locality. Restricted (Closed Shell) and Unrestricted (Spin-polarized) calculations can be performed with all-electron and valence-only basis sets with effective core pseudo-potentials. The current release is CRYSTAL23.</p> <p>Important</p> <p>CRYSTAL is not part of the officially supported software on ARCHER2. While the ARCHER2 service desk is able to provide support for basic use of this software (e.g. access to software, writing job submission scripts) it does not generally provide detailed technical support for the software and you may be directed to seek support from other places if the service desk cannot answer the questions.</p>"},{"location":"research-software/crystal/#useful-links","title":"Useful Links","text":"<ul> <li>CRYSTAL home site</li> <li>CRYSTAL tutorials</li> <li>CRYSTAL licensing</li> </ul>"},{"location":"research-software/crystal/#using-crystal-on-archer2","title":"Using CRYSTAL on ARCHER2","text":"<p>CRYSTAL is only available to users who have a valid CRYSTAL license. You  request access through SAFE:</p> <ul> <li>How to request access to package groups</li> </ul> <p>Please have your license details to hand.</p>"},{"location":"research-software/crystal/#running-parallel-crystal-jobs","title":"Running parallel CRYSTAL jobs","text":"<p>The following script will run CRYSTAL using pure MPI for parallelisation using 256 MPI processes, 1 per core across 2 nodes. It assumes that the input file is tio2.d12</p> <pre><code>#!/bin/bash\n#SBATCH --nodes=2\n#SBATCH --time=0:20:00\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n\n# Replace [budget code] below with your project code (e.g. e05)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\nmodule load other-software\nmodule load crystal/23-1.0.1-2\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Change this to the name of your input file\ncp tio2.d12 INPUT\n\nsrun --hint=nomultithread --distribution=block:block MPPcrystal\n</code></pre> <p>An equivalent 2 node job using MPI+OpenMP parallelism with 4 threads per MPI process, 64 MPI processes, 1 thread per core across 2 nodes would be:</p> <pre><code>#!/bin/bash\n#SBATCH --nodes=2\n#SBATCH --time=0:20:00\n#SBATCH --ntasks-per-node=32\n#SBATCH --cpus-per-task=4\n\n# Replace [budget code] below with your project code (e.g. e05)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\nmodule load other-software\nmodule load crystal/23-1.0.1-2\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Change this to the name of your input file\ncp tio2.d12 INPUT\n\nexport OMP_NUM_THREADS=4\nexport OMP_PLACES=cores\nexport OMP_STACKSIZE=16M\n\nsrun --hint=nomultithread --distribution=block:block MPPcrystalOMP\n</code></pre>"},{"location":"research-software/crystal/#tips-and-known-issues","title":"Tips and known issues","text":""},{"location":"research-software/crystal/#cpu-frequency","title":"CPU frequency","text":"<p>You should run some short (1 or 2 SCF cycles) jobs to test the scaling of your job so you can decide on the balance between cost to your budget and the time it takes to get a result. You now should include a few tests at different clock rates as part of this process.</p> <p>Based on a few simple tests we have run it is likely that jobs dominated by building the Kohn-Sham matrix (SHELLX+MONMO3+NUMDFT in the output) will see minimal energy savings and better performance at 2.25GHz. Jobs dominated by the ScaLapack calls (MPP_DIAG in the output) may show useful energy savings at 2.0GHz.</p>"},{"location":"research-software/crystal/#out-of-memory-errors","title":"Out-of-memory errors","text":"<p>Long-running jobs may encounter unexpected errors of the form <pre><code>slurmstepd: error: Detected 1 oom-kill event(s) in step 411502.0 cgroup.\n</code></pre> These are related to a memory leak in the underlying libfabric communication layer, which will be fixed in a future release. In the meantime, it should be possible to work around the problem by adding <pre><code>export FI_MR_CACHE_MAX_COUNT=0 \n</code></pre> to the SLURM submission script.</p>"},{"location":"research-software/fhi-aims/","title":"FHI-aims","text":"<p>FHI-aims is an all-electron electronic structure code based on numeric atom-centered orbitals. It enables first-principles simulations with very high numerical accuracy for production calculations, with excellent scalability up to very large system sizes (thousands of atoms) and up to very large, massively parallel supercomputers (ten thousand CPU cores).</p>"},{"location":"research-software/fhi-aims/#useful-links","title":"Useful Links","text":"<ul> <li>FHI-aims website</li> <li>FHI-aims Tutorials</li> </ul>"},{"location":"research-software/fhi-aims/#using-fhi-aims-on-archer2","title":"Using FHI-aims on ARCHER2","text":"<p>FHI-aims is only available to users who have a valid FHI-aims licence.</p> <p>If you have a FHI-aims licence and wish to have access to FHI-aims on ARCHER2, please make a request via the SAFE, see:</p> <ul> <li>How to request access to package      groups</li> </ul> <p>Please have your license details to hand.</p>"},{"location":"research-software/fhi-aims/#running-parallel-fhi-aims-jobs","title":"Running parallel FHI-aims jobs","text":"<p>The following script will run a FHI-aims job using 8 nodes (1024 cores). The script assumes that the input have the default names <code>control.in</code> and <code>geometry.in</code>.</p> <pre><code>#!/bin/bash\n\n# Request 2 nodes with 128 MPI tasks per node for 20 minutes\n#SBATCH --job-name=FHI-aims\n#SBATCH --nodes=8\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the FHI-aims module, avoid any unintentional OpenMP threading by\n# setting OMP_NUM_THREADS, and launch the code.\nmodule load fhiaims\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nexport OMP_NUM_THREADS=1\nsrun --distribution=block:block --hint=nomultithread aims.mpi.x\n</code></pre>"},{"location":"research-software/fhi-aims/#compiling-fhi-aims","title":"Compiling FHI-aims","text":"<p>The latest instructions for building FHI-aims on ARCHER2 may be found in the GitHub repository of build instructions:</p> <ul> <li>Build instructions for FHI-aims on      GitHub</li> </ul>"},{"location":"research-software/gromacs/","title":"GROMACS","text":"<p>GROMACS is a versatile package to perform molecular dynamics, i.e. simulate the Newtonian equations of motion for systems with hundreds to millions of particles. It is primarily designed for biochemical molecules like proteins, lipids and nucleic acids that have a lot of complicated bonded interactions, but since GROMACS is extremely fast at calculating the nonbonded interactions (that usually dominate simulations) many groups are also using it for research on non-biological systems, e.g. polymers.</p>"},{"location":"research-software/gromacs/#useful-links","title":"Useful Links","text":"<ul> <li>GROMACS User Guides</li> <li>GROMACS Tutorials</li> </ul>"},{"location":"research-software/gromacs/#using-gromacs-on-archer2","title":"Using GROMACS on ARCHER2","text":"<p>GROMACS is Open Source software and is freely available to all users. Three versions are available:</p> <ul> <li>Parallel MPI/OpenMP, single precision: <code>gmx_mpi</code></li> <li>Parallel MPI/OpenMP, double precision: <code>gmx_mpi_d</code></li> <li>Serial, single precision: <code>gmx</code></li> </ul> <p>Important</p> <p>The <code>gromacs</code> modules reset the CPU frequency to the highest possible value (2.25 GHz) as this generally achieves the best balance of performance to  energy use. You can change this setting by following the instructions in the Energy use section of the User Guide.</p>"},{"location":"research-software/gromacs/#running-parallel-gromacs-jobs","title":"Running parallel GROMACS jobs","text":""},{"location":"research-software/gromacs/#running-mpi-only-jobs","title":"Running MPI only jobs","text":"<p>The following script will run a GROMACS MD job using 4 nodes (128x4 cores) with pure MPI.</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=mdrun_test\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Setup the environment\nmodule load gromacs\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nexport OMP_NUM_THREADS=1 srun --distribution=block:block --hint=nomultithread gmx_mpi mdrun -s test_calc.tpr\n</code></pre>"},{"location":"research-software/gromacs/#running-hybrid-mpiopenmp-jobs","title":"Running hybrid MPI/OpenMP jobs","text":"<p>The following script will run a GROMACS MD job using 4 nodes (128x4 cores) with 6 MPI processes per node (24 MPI processes in total) and 6 OpenMP threads per MPI process.</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=mdrun_test\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=16\n#SBATCH --cpus-per-task=8\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Setup the environment\nmodule load gromacs\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nexport OMP_NUM_THREADS=8\nsrun --distribution=block:block --hint=nomultithread gmx_mpi mdrun -s test_calc.tpr\n</code></pre>"},{"location":"research-software/gromacs/#compiling-gromacs","title":"Compiling Gromacs","text":"<p>The latest instructions for building GROMACS on ARCHER2 may be found in the GitHub repository of build instructions:</p> <ul> <li>Build instructions for GROMACS on      GitHub</li> </ul>"},{"location":"research-software/lammps/","title":"LAMMPS","text":"<p>LAMMPS (Large-scale Atomic/Molecular Massively Parallel Simulator) is a classical molecular dynamics code. LAMMPS has potentials for solid-state materials (metals, semiconductors) and soft matter (biomolecules, polymers), and coarse-grained or mesoscopic systems. It can be used to model atoms or, more generically, as a parallel particle simulator at the atomic, mesoscopic, or continuum scale.</p>"},{"location":"research-software/lammps/#useful-links","title":"Useful Links","text":"<ul> <li>LAMMPS Documentation</li> <li>LAMMPS Mailing list details</li> </ul>"},{"location":"research-software/lammps/#using-lammps-on-archer2","title":"Using LAMMPS on ARCHER2","text":"<p>LAMMPS is freely available to all ARCHER2 users.</p> <p>The centrally installed version of LAMMPS is compiled with all the standard packages included: <code>ASPHERE</code>, <code>BODY</code>, <code>CLASS2</code>, <code>COLLOID</code>, <code>COMPRESS</code>, <code>CORESHELL</code>, <code>DIPOLE</code>, <code>GRANULAR</code>, <code>KSPACE</code>, <code>MANYBODY</code>, <code>MC</code>, <code>MISC</code>, <code>MOLECULE</code>, <code>OPT</code>, <code>PERI</code>, <code>QEQ</code>, <code>REPLICA</code>, <code>RIGID</code>, <code>SHOCK</code>, <code>SNAP</code>, <code>SRD</code>.</p> <p>We do not install any <code>USER</code> packages. If you are interested in a <code>USER</code> package, we would encourage you to try to compile your own version and we can help out if necessary (see below).</p> <p>Important</p> <p>The <code>lammps</code> modules reset the CPU frequency to the highest possible value (2.25 GHz) as this generally achieves the best balance of performance to  energy use. You can change this setting by following the instructions in the Energy use section of the User Guide.</p>"},{"location":"research-software/lammps/#running-parallel-lammps-jobs","title":"Running parallel LAMMPS jobs","text":"<p>LAMMPS can exploit multiple nodes on ARCHER2 and will generally be run in exclusive mode using more than one node.</p> <p>For example, the following script will run a LAMMPS MD job using 4 nodes (128x4 cores) with MPI only.</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=lammps_test\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code] \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\nmodule load lammps\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nsrun --distribution=block:block --hint=nomultithread lmp -i in.test -l out.test\n</code></pre>"},{"location":"research-software/lammps/#compiling-lammps","title":"Compiling LAMMPS","text":"<p>The large range of optional packages available for LAMMPS, and opportunity for extensibility, may mean that it is convenient for users to compile their own copy. In practice, LAMMPS is relatively easy to compile, so we encourage users to have a go.</p> <p>Compilation instructions for LAMMPS on ARCHER2 can be found on GitHub:</p> <ul> <li>Build instructions for LAMMPS on      GitHub</li> </ul>"},{"location":"research-software/mitgcm/","title":"MITgcm","text":"<p>The Massachusetts Institute of Technology General Circulation Model (MITgcm) is a numerical model designed for study of the atmosphere, ocean, and climate. MITgcm's flexible non-hydrostatic formulation enables it to simulate fluid phenomena over a wide range of scales; its adjoint capabilities enable it to be applied to sensitivity questions and to parameter and state estimation problems. By employing fluid equation isomorphisms, a single dynamical kernel can be used to simulate flow of both the atmosphere and ocean.</p>"},{"location":"research-software/mitgcm/#useful-links","title":"Useful Links","text":"<ul> <li>MITgcm home page</li> <li>MITgcm documentation</li> </ul>"},{"location":"research-software/mitgcm/#building-mitgcm-on-archer2","title":"Building MITgcm on ARCHER2","text":"<p>MITgcm is not available via a module on ARCHER2 as users will build their own executables specific to the problem they are working on. However, we do provide an optfile which will allow <code>genmake2</code> to create Makefiles which will work on ARCHER2.</p> <p>Note</p> <p>The processes to build MITgcm on the ARCHER2 4-cabinet system and full system are slightly different. Please make sure you use the commands for the correct system below.</p> <p>You can obtain the MITgcm source code from the developers by cloning from the GitHub repository with the command</p> <pre><code>git clone https://github.com/MITgcm/MITgcm.git\n</code></pre> <p>You should then copy the ARCHER2 optfile into the MITgcm directories. You may use the files at the locations below for the 4-cabinet and full systems.</p> <pre><code>cp /work/n02/shared/mjmn02/ECCOv4/cases/cce/cce1/scripts/dev_linux_amd64_cray_archer2 MITgcm/tools/build_options/\n</code></pre> <p>You should also set the following environment variables. <code>MITGCM_ROOTDIR</code> is used to locate the source code and should point to the top MITgcm directory. Optionally, adding the MITgcm tools directory to your <code>PATH</code> environment variable makes it easier to use tools such as <code>genmake2</code>, and the <code>MITGCM_OPT</code> environment variable makes it easier to refer to pass the optfile to <code>genmake2</code>.</p> <pre><code>export MITGCM_ROOTDIR=/path/to/MITgcm\nexport PATH=$MITGCM_ROOTDIR/tools:$PATH\nexport MITGCM_OPT=$MITGCM_ROOTDIR/tools/build_options/dev_linux_amd64_cray_archer2\n</code></pre> <p>When using <code>genmake2</code> to create the Makefile, you will need to specify the optfile to use. Other commonly used options might be to use extra source code with the <code>-mods</code> option, to enable MPI with <code>-mpi</code>, and to enable OpenMP with <code>-omp</code>. You might then run a command that resembles the following:</p> <pre><code>genmake2 -mods /path/to/additional/source -mpi -optfile $MITGCM_OPT\n</code></pre> <p>You can read about the full set of options available to <code>genmake2</code> by running</p> <pre><code>genmake2 -help\n</code></pre> <p>Finally, you may then build your executable by running </p> <pre><code>make depend\nmake\n</code></pre>"},{"location":"research-software/mitgcm/#running-mitgcm-on-archer2","title":"Running MITgcm on ARCHER2","text":""},{"location":"research-software/mitgcm/#pure-mpi","title":"Pure MPI","text":"<p>Once you have built your executable you can write a script like the following which will allow it to run on the ARCHER2 compute nodes. This example would run a pure MPI MITgcm simulation over 2 nodes of 128 cores each for up to one hour.</p> <pre><code>#!/bin/bash\n\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=MITgcm-simulation\n#SBATCH --time=1:0:0\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code] \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Set the number of threads to 1\n#   This prevents any threaded system libraries from automatically\n#   using threading.\nexport OMP_NUM_THREADS=1\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Launch the parallel job\n#   Using 256 MPI processes and 128 MPI processes per node\n#   srun picks up the distribution from the sbatch options\nsrun --distribution=block:block --hint=nomultithread ./mitgcmuv\n</code></pre>"},{"location":"research-software/mitgcm/#hybrid-openmp-mpi","title":"Hybrid OpenMP &amp; MPI","text":"<p>Warning</p> <p>Running the model in hybrid mode may lead to performance decreases as well as increases. You should be sure to profile your code both as a pure MPI application and as a hybrid OpenMP-MPI application to ensure you are making efficient use of resources. Be sure to read both the Archer2 advice on OpenMP  and the MITgcm documentation first.</p> <p>Note</p> <p>Early versions of the ARCHER2 MITgcm optfile do not contain an <code>OMPFLAG</code>. Please ensure you have an up to date copy of the optfile before attempting to compile OpenMP enabled codes.</p> <p>Depending upon your model setup, you may wish to run the MITgcm code as a hybrid OpenMP-MPI application. In terms of compiling the model, this is as simple as using the flag <code>-omp</code> when calling <code>genmake2</code>, and updating your <code>SIZE.h</code> file to have multiple tiles per process.</p> <p>The model can be run using a slurm job submission script similar to that shown below. This example will run MITgcm across 2 nodes, with each node using 16 MPI processes, and each process using 4 threads. Note that this would underpopulate the nodes \u2014 i.e. we will only be using 128 of the 256 cores available to us. This can also sometimes lead to performance increases.</p> <pre><code>#!/bin/bash\n\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=MITgcm-hybrid-simulation\n#SBATCH --time=1:0:0\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=16\n#SBATCH --cpus-per-task=4\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code] \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Set the number of threads to 1\n#   This prevents any threaded system libraries from automatically\n#   using threading.\nexport OMP_NUM_THREADS=4  # Set to number of threads per process\nexport OMP_PLACES=\"cores(128)\"  # Set to total number of threads\nexport OMP_PROC_BIND=true  # Required if we want to underpopulate nodes\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Launch the parallel job\n#   Using 256 MPI processes and 128 MPI processes per node\n#   srun picks up the distribution from the sbatch options\nsrun --distribution=block:block --hint=nomultithread ./mitgcmuv\n</code></pre> <p>One final note, is that you should remember to update the <code>eedata</code> file in the model's run directory to ensure the number of threads requested there match those requested in the job submission script.</p>"},{"location":"research-software/mitgcm/#reproducing-the-ecco-version-4-release-4-state-estimate-on-archer2","title":"Reproducing the ECCO version 4 (release 4) state estimate on ARCHER2","text":"<p>The ECCO version 4 state estimate (ECCOv4-r4) is an observationally-constrained numerical solution produced by the ECCO group at JPL. If you would like to reproduce the state estimate on ARCHER2 in order to create customised runs and experiments, follow the instructions below. They have been slightly modified from the JPL instructions for ARCHER2. </p> <p>For more information, see the ECCOv4-r4 website https://ecco-group.org/products-ECCO-V4r4.htm</p>"},{"location":"research-software/mitgcm/#get-the-eccov4-r4-source-code","title":"Get the ECCOv4-r4 source code","text":"<p>First, navigate to your directory on the <code>/work</code> filesystem in order to get access to the compute nodes. Next, create a working directory, perhaps MYECCO, and navigate into this working directory:</p> <pre><code>mkdir MYECCO\ncd MYECCO\n</code></pre> <p>In order to reproduce ECCOv4-r4, we need a specific checkpoint of the MITgcm source code. </p> <pre><code>git clone https://github.com/MITgcm/MITgcm.git -b checkpoint66g\n</code></pre> <p>Next, get the ECCOv4-r4 specific code from GitHub:</p> <pre><code>cd MITgcm\nmkdir -p ECCOV4/release4\ncd ECCOV4/release4\ngit clone https://github.com/ECCO-GROUP/ECCO-v4-Configurations.git\nmv ECCO-v4-Configurations/ECCOv4\\ Release\\ 4/code .\nrm -rf ECCO-v4-Configurations\n</code></pre>"},{"location":"research-software/mitgcm/#get-the-eccov4-r4-forcing-files","title":"Get the ECCOv4-r4 forcing files","text":"<p>The surface forcing and other input files that are too large to be stored on GitHub are available via NASA data servers. In total, these files are about 200 GB in size. You must register for an Earthdata account and connect to a WebDAV server in order to access these files. For more detailed instructions, read the help page https://ecco.jpl.nasa.gov/drive/help.</p> <p>First, apply for an Earthdata account: https://urs.earthdata.nasa.gov/users/new</p> <p>Next, acquire your WebDAV credentials: https://ecco.jpl.nasa.gov/drive (second box from the top)</p> <p>Now, you can use wget to download the required forcing and input files:</p> <pre><code>wget -r --no-parent --user YOURUSERNAME --ask-password https://ecco.jpl.nasa.gov/drive/files/Version4/Release4/input_forcing\nwget -r --no-parent --user YOURUSERNAME --ask-password https://ecco.jpl.nasa.gov/drive/files/Version4/Release4/input_init \nwget -r --no-parent --user YOURUSERNAME --ask-password https://ecco.jpl.nasa.gov/drive/files/Version4/Release4/input_ecco\n</code></pre> <p>After using <code>wget</code>, you will notice that the <code>input*</code> directories are, by default, several levels deep in the directory structure. Use the <code>mv</code> command to move the <code>input*</code> directories to the directory where you executed the <code>wget</code> command. Specifically,</p> <pre><code>mv ecco.jpl.nasa.gov/drive/files/Version4/Release4/input_forcing/ .\nmv ecco.jpl.nasa.gov/drive/files/Version4/Release4/input_init/ .\nmv ecco.jpl.nasa.gov/drive/files/Version4/Release4/input_ecco/ .\nrm -rf ecco.jpl.nasa.gov\n</code></pre>"},{"location":"research-software/mitgcm/#compiling-and-running-eccov4-r4","title":"Compiling and running ECCOv4-r4","text":"<p>The steps for building the ECCOv4-r4 instance of MITgcm are very similar to those for other build cases. First, wou will need to create a build directory:</p> <pre><code>cd MITgcm/ECCOV4/release4\nmkdir build\ncd build\n</code></pre> <p>Load the NetCDF modules:</p> <pre><code>module load cray-hdf5\nmodule load cray-netcdf\n</code></pre> <p>If you haven't already, set your environment variables:</p> <pre><code>export MITGCM_ROOTDIR=../../../../MITgcm\nexport PATH=$MITGCM_ROOTDIR/tools:$PATH\nexport MITGCM_OPT=$MITGCM_ROOTDIR/tools/build_options/dev_linux_amd64_cray_archer2\n</code></pre> <p>Next, compile the executable:</p> <pre><code>genmake2 -mods ../code -mpi -optfile $MITGCM_OPT\nmake depend\nmake\n</code></pre> <p>Once you have compiled the model, you will have the mitgcmuv executable for ECCOv4-r4. </p>"},{"location":"research-software/mitgcm/#create-run-directory-and-link-files","title":"Create run directory and link files","text":"<p>In order to run the model, you need to create a run directory and link/copy the appropriate files. First, navigate to your directory on the <code>work</code> filesystem. From the <code>MITgcm/ECCOV4/release4</code> directory:</p> <pre><code>mkdir run\ncd run\n\n# link the data files\nln -s ../input_init/NAMELIST/* .\nln -s ../input_init/error_weight/ctrl_weight/* .\nln -s ../input_init/error_weight/data_error/* .\nln -s ../input_init/* .\nln -s ../input_init/tools/* .\nln -s ../input_ecco/*/* .\nln -s ../input_forcing/eccov4r4* .\n\npython mkdir_subdir_diags.py\n\n# manually copy the mitgcmuv executable\ncp -p ../build/mitgcmuv .\n</code></pre> <p>For a short test run, edit the <code>nTimeSteps</code> variable in the file <code>data</code>. Comment out the default value and uncomment the line reading <code>nTimeSteps=8</code>. This is a useful test to make sure that the model can at least start up. </p> <p>To run on ARCHER2, submit a batch script to the Slurm scheduler. Here is an example submission script:</p> <pre><code>#!/bin/bash\n\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=ECCOv4r4-test\n#SBATCH --time=1:0:0\n#SBATCH --nodes=8\n#SBATCH --ntasks-per-node=12\n#SBATCH --cpus-per-task=1\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code] \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Set the number of threads to 1\n#   This prevents any threaded system libraries from automatically\n#   using threading.\nexport OMP_NUM_THREADS=1\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Launch the parallel job\n#   Using 256 MPI processes and 128 MPI processes per node\n#   srun picks up the distribution from the sbatch options\nsrun --distribution=block:block --hint=nomultithread ./mitgcmuv\n</code></pre> <p>This configuration uses 96 MPI processes at 12 MPI processes per node. Once the run has finished, in order to check that the run has successfully completed, check the end of one of the standard output files. </p> <pre><code>tail STDOUT.0000\n</code></pre> <p>It should read </p> <pre><code>PROGRAM MAIN: Execution ended Normally\n</code></pre> <p>The files named <code>STDOUT.*</code> contain diagnostic information that you can use to check your results. As a first pass, check the printed statistics for any clear signs of trouble (e.g. NaN values, extremely large values). </p>"},{"location":"research-software/mitgcm/#eccov4-r4-in-adjoint-mode","title":"ECCOv4-r4 in adjoint mode","text":"<p>If you have access to the commercial TAF software produced by http://FastOpt.de, then you can compile and run the ECCOv4-r4 instance of MITgcm in adjoint mode. This mode is useful for comprehensive sensitivity studies and for constructing state estimates. From the <code>MITgcm/ECCOV4/release4</code> directory, create a new code directory and a new build directory:</p> <pre><code>mkdir code_ad\ncd code_ad\nln -s ../code/* .\ncd ..\nmkdir build_ad\ncd build_ad\n</code></pre> <p>In this instance, the <code>code_ad</code> and <code>code</code> directories are identical, although this does not have to be the case. Make sure that you have the <code>staf</code> script in your path or in the <code>build_ad</code> directory itself. To make sure that you have the most up-to-date script, run:</p> <pre><code>./staf -get staf\n</code></pre> <p>To test your connection to the FastOpt servers, try:</p> <pre><code>./staf -test\n</code></pre> <p>You should receive the following message:</p> <pre><code>Your access to the TAF server is enabled.\n</code></pre> <p>The compilation commands are similar to those used to build the forward case.</p> <pre><code># load relevant modules\nmodule load cray-netcdf-hdf5parallel\nmodule load cray-hdf5-parallel\n\n# compile adjoint model\n../../../MITgcm/tools/genmake2 -ieee -mpi -mods=../code_ad -of=(PATH_TO_OPTFILE)\nmake depend\nmake adtaf\nmake adall\n</code></pre> <p>The source code will be packaged and forwarded to the FastOpt servers, where it will undergo source-to-source translation via the TAF algorithmic differentiation software. If the compilation is successful, you will have an executable named <code>mitgcmuv_ad</code>. This will run the ECCOv4-r4 configuration of MITgcm in adjoint mode. As before, create a run directory and copy in the relevant files. The procedure is the same as for the forward model, with the following modifications:</p> <pre><code>cd ..\nmkdir run_ad\ncd run_ad\n# manually copy the mitgcmuv executable\ncp -p ../build_ad/mitgcmuv_ad .\n</code></pre> <p>To run the model, change the name of the executable in the Slurm submission script; everything else should be the same as in the forward case. As above, at the end of the run you should have a set of <code>STDOUT.*</code> files that you can examine for any obvious problems. </p>"},{"location":"research-software/mitgcm/#compile-time-errors","title":"Compile time errors","text":"<p>If TAF compilation fails with an error like <code>failed to convert GOTPCREL relocation; relink with --no-relax</code> then add the following line to the FFLAGS options: <code>-Wl,--no-relax</code>.</p>"},{"location":"research-software/mitgcm/#checkpointing-for-adjoint-runs","title":"Checkpointing for adjoint runs","text":"<p>In an adjoint run, there is a balance between storage (i.e. saving the model state to disk) and recomputation (i.e. integrating the model forward from a stored state). Changing the <code>nchklev</code> parameters in the <code>tamc.h</code> file at compile time is how you control the relative balance between storage and recomputation. </p> <p>A suggested strategy that has been used on a variety of HPC platforms is as follows: 1. Set <code>nchklev_1</code> as large as possible, up to the size allowed by memory on your machine. (Use the <code>size</code> command to estimate the memory per process. This should be just a little bit less than the maximum allowed on the machine. On ARCHER2 this is 2 GB (standard) and 4 GB (high memory)). 2. Next, set <code>nchklev_2</code> and <code>nchklev_3</code> to be large enough to accomodate the entire run. A common strategy is to set <code>nchklev_2 = nchklev_3 = sqrt(numsteps/nchklev_1) + 1</code>.  3. If the <code>nchklev_2</code> files get too big, then you may have to add a fourth level (i.e. <code>nchklev_4</code>), but this is unlikely. </p> <p>This strategy allows you to keep as much in memory as possible, minimising the I/O requirements for the disk. This is useful, as I/O is often the bottleneck for MITgcm runs on HPC. </p> <p>Another way to adjust performance is to adjust how tapelevel I/O is handled. This strategy performs well for most configurations: <pre><code>C o tape settings\n#define ALLOW_AUTODIFF_WHTAPEIO\n#define AUTODIFF_USE_OLDSTORE_2D\n#define AUTODIFF_USE_OLDSTORE_3D\n#define EXCLUDE_WHIO_GLOBUFF_2D\n#define ALLOW_INIT_WHTAPEIO\n</code></pre></p>"},{"location":"research-software/mo-unified-model/","title":"Met Office Unified Model","text":"<p>The Met Office Unified Model (\"the UM\") is a numerical model of the atmosphere used for both weather and climate applications. It is often coupled to the NEMO ocean model using the OASIS coupling framework to provide a full Earth system model.</p>"},{"location":"research-software/mo-unified-model/#useful-links","title":"Useful Links","text":"<ul> <li>Met Office Unified Model home page</li> </ul>"},{"location":"research-software/mo-unified-model/#using-the-um","title":"Using the UM","text":"<p>Information on using the UM is provided by the NCAS Computational Modelling Service (CMS).</p>"},{"location":"research-software/namd/","title":"NAMD","text":"<p>NAMD is an award-winning parallel molecular dynamics code designed for high-performance simulation of large biomolecular systems. Based on Charm++ parallel objects, NAMD scales to hundreds of cores for typical simulations and beyond 500,000 cores for the largest simulations. NAMD uses the popular molecular graphics program VMD for simulation setup and trajectory analysis, but is also file-compatible with AMBER, CHARMM, and X-PLOR.</p>"},{"location":"research-software/namd/#useful-links","title":"Useful Links","text":"<ul> <li>NAMD User Guide</li> <li>NAMD Tutorials</li> </ul>"},{"location":"research-software/namd/#using-namd-on-archer2","title":"Using NAMD on ARCHER2","text":"<p>NAMD is freely available to all ARCHER2 users.</p> <p>ARCHER2 has two versions of NAMD available: no-SMP (<code>namd/2.14-nosmp</code>) or SMP (<code>namd/2.14</code>). The SMP (Shared Memory Parallelism) build of NAMD introduces threaded parallelism to address memory limitations. The no-SMP build will typically provide the best performance but most users will require SMP in order to cope with high memory requirements.</p> <p>Important</p> <p>The <code>namd</code> modules reset the CPU frequency to the highest possible value (2.25 GHz) as this generally achieves the best balance of performance to  energy use. You can change this setting by following the instructions in the Energy use section of the User Guide.</p>"},{"location":"research-software/namd/#running-mpi-only-namd-jobs","title":"Running MPI only NAMD jobs","text":"<p>Using no-SMP NAMD will run jobs with only MPI processes and will not introduce additional threaded parallelism. This is the simplest approach to running NAMD jobs and is likely to give the best performance unless simulations are limited by high memory requirements.</p> <p>The following script will run a pure MPI NAMD MD job using 4 nodes (i.e. 128x4 = 512 MPI parallel processes).</p> <pre><code>#!/bin/bash\n\n# Request four nodes to run a job of 512 MPI tasks with 128 MPI\n# tasks per node, here for maximum time 20 minutes.\n\n#SBATCH --job-name=namd-nosmp\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\nmodule load namd/2.14-nosmp\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nsrun --distribution=block:block --hint=nomultithread namd2 input.namd\n</code></pre>"},{"location":"research-software/namd/#running-smp-namd-jobs","title":"Running SMP NAMD jobs","text":"<p>If your jobs runs out of memory, then using the SMP version of NAMD will reduce the memory requirements. This involves launching a combination of MPI processes for communication and worker threads which perform computation.</p> <p>The following script will run a SMP NAMD MD job using 4 nodes with 8 MPI communication processes per node and 16 worker threads per communication process (i.e. a fully-occupied node with all 512 cores populated with processes).</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=namd-smp\n#SBATCH --ntasks-per-node=32\n#SBATCH --cpus-per-task=4\n#SBATCH --nodes=4\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the relevant modules\nmodule load namd\n\n# Set procs per node (PPN) &amp; OMP_NUM_THREADS\nexport PPN=$(($SLURM_CPUS_PER_TASK-1))\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\nexport OMP_PLACES=cores\n\n# Record PPN in the output file\necho \"Number of worker threads PPN = $PPN\"\n\n# Run NAMD\nsrun --distribution=block:block --hint=nomultithread namd2 +setcpuaffinity +ppn $PPN input.namd\n</code></pre> <p>Important</p> <p>Please do not set <code>SRUN_CPUS_PER_TASK</code> when running the SMP version of NAMD. Otherwise, Charm++ will be unable to pin processes to CPUs, causing NAMD to abort with errors such as <code>Couldn't bind to cpuset 0x00000010,,,0x0: Invalid argument</code>.</p> <p>How do I choose an optimal choice of MPI processes and worker threads for my simulations? The optimal choice for the numbers of MPI processes and worker threads per node depends on the data set and the number of compute nodes. Before running large production jobs, it is worth experimenting with these parameters to find the optimal configuration for your simulation.</p> <p>We recommend that users match the ARCHER2 NUMA architecture to find the optimal balance of thread and process parallelism. The NUMA levels on ARCHER2 compute nodes are: 4 cores per CCX, 8 cores per CCD, 16 cores per memory controller, 64 cores per socket. For example, the above submission script specifies 32 MPI communication processes per node and 4 worker threads per communication process which places 1 MPI process per CCX on each node.</p> <p>Note</p> <p>To ensure fully occupied nodes with the SMP build of NAMD and match the NUMA layout, the optimal values of (<code>tasks-per-node</code>, <code>cpus-per-task</code>) are likely to be (32,4), (16,8) or (8,16).</p> <p>How do I choose a value for the +ppn flag? The number of workers per communication process is specified by the +ppn argument to NAMD, which is set here to equal cpus-per-task - 1, to leave a CPU-core free for the associated MPI process.</p> <p>We recommend that users reserve a thread per process to improve the scalability. Reserving this thread on a many-cores-per-node architecture like ARCHER2 will reduce the communication between threads and improve the scalability.</p>"},{"location":"research-software/namd/#compiling-namd","title":"Compiling NAMD","text":"<p>The latest instructions for building NAMD on ARCHER2 may be found in the GitHub repository of build instructions.</p> <p>ARCHER2 Full System</p>"},{"location":"research-software/nektarplusplus/","title":"Nektar++","text":"<p>Nektar++ is a tensor product based finite element package designed to allow one to construct efficient classical low polynomial order h-type solvers (where h is the size of the finite element) as well as higher p-order piecewise polynomial order solvers.</p> <p>The Nektar++ framework comes with a number of solvers and also allows one to construct a variety of new solvers. Users can therefore use Nektar++ just to run simulations, or to extend and/or develop new functionality.</p>"},{"location":"research-software/nektarplusplus/#useful-links","title":"Useful Links","text":"<ul> <li>Nektar++ home page</li> <li>Nektar++ tutorials</li> <li>Nektar GitLab repository</li> </ul>"},{"location":"research-software/nektarplusplus/#using-nektar-on-archer2","title":"Using Nektar++ on ARCHER2","text":"<p>Nektar++ is released under an MIT license and is available to all users on the ARCHER2 full system.</p>"},{"location":"research-software/nektarplusplus/#where-can-i-get-help","title":"Where can I get help?","text":"<p>Specific issues with Nektar++ itself might be submitted to the issue tracker at the Nektar++ gitlab repository (see link above). More general questions might also be directed to the Nektar-users mailing list. Issues specific to the use or behaviour of Nektar++ on ARCHER2 should be sent to the Service Desk.</p>"},{"location":"research-software/nektarplusplus/#running-parallel-nektar-jobs","title":"Running parallel Nektar++ jobs","text":"<p>Below is the submission script for running the Taylor-Green Vortex, one of the Nektar++ tutorials, see https://doc.nektar.info/tutorials/latest/incns/taylor-green-vortex/incns-taylor-green-vortex.html#incns-taylor-green-vortexch4.html .</p> <p>You first need to download the archive linked on the tutorial page.</p> <pre><code>cd /path/to/work/dir\nwget https://doc.nektar.info/tutorials/latest/incns/taylor-green-vortex/incns-taylor-green-vortex.tar.gz\ntar -xvzf incns-taylor-green-vortex.tar.gz\n</code></pre> <pre><code>#!/bin/bash\n#SBATCH --job-name=nektar\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=32\n#SBATCH --cpus-per-task=1\n#SBATCH --time=02:00:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code] \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\nmodule load nektar\n\nexport OMP_NUM_THREADS=1\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nNEK_INPUT_PATH=/path/to/work/dir/incns-taylor-green-vortex/completed/solver64\n\nsrun --distribution=block:cyclic --hint=nomultithread \\\n${NEK_DIR}/bin/IncNavierStokesSolver \\\n${NEK_INPUT_PATH}/TGV64_mesh.xml \\\n${NEK_INPUT_PATH}/TGV64_conditions.xml\n</code></pre>"},{"location":"research-software/nektarplusplus/#compiling-nektar","title":"Compiling Nektar++","text":"<p>The latest instructions for building Nektar++ on ARCHER2 may be found in the GitHub repository of build instructions.</p> <p>ARCHER2 Full System</p>"},{"location":"research-software/nemo/","title":"NEMO","text":"<p>NEMO (Nucleus for European Modelling of the Ocean) is a state-of-the-art framework for research activities and forecasting services in ocean and climate sciences, developed in a sustainable way by a European consortium.</p>"},{"location":"research-software/nemo/#useful-links","title":"Useful Links","text":"<ul> <li>NEMO home page</li> <li>NEMO documentation</li> <li>NEMO users' area, which includes information on obtaining and downloading the latest source code releases.</li> </ul> <p>NEMO is released under a CeCILL license and is freely available to all users on ARCHER2.</p>"},{"location":"research-software/nemo/#compiling-nemo","title":"Compiling NEMO","text":"<p>A central install of NEMO is not appropriate for most users of ARCHER2 since many configurations will want to add bespoke code changes.</p> <p>The latest instructions for building NEMO on ARCHER2 are found in the Github repository of build instructions:</p> <ul> <li>Build instructions for NEMO on   GitHub</li> </ul>"},{"location":"research-software/nemo/#using-nemo-on-archer2","title":"Using NEMO on ARCHER2","text":"<p>Typical NEMO production runs perform significant I/O management to handle the very large volumes of data associated with ocean modelling. To address this, NEMO ocean clients are interfaced with XIOS I/O servers. XIOS is a library which manages NetCDF outputs for climate models. NEMO uses XIOS to simplify the I/O management and introduce dedicated processors to manage large volumes of data.</p> <p>Users can choose to run NEMO in attached or detached mode: - In attached mode each processor acts as an ocean client and I/O-server process. - In detached mode ocean clients and external XIOS I/O-server processors are separately defined.</p> <p>Running NEMO in attached mode can be done with a simple submission script specifying both the NEMO and XIOS executable to <code>srun</code>. However, typical production runs of NEMO will perform significant I/O management and will be unable to run in attached mode.</p> <p>Detached mode introduces external XIOS I/O-servers to help manage the large volumes of data. This requires users to specify the placement of clients and servers on different cores throughout the node using the <code>\u2013cpu-bind=map_cpu:&lt;cpu map&gt;</code> srun option to define a CPU map or mask. It is tedious to construct these maps by hand. Instead, Andrew Coward provides a tool to aid users in the construction submission scripts:</p> <pre><code>/work/n01/shared/nemo/mkslurm_hetjob\n/work/n01/shared/nemo/mkslurm_hetjob_Gnu\n</code></pre> <p>Usage of the script:</p> <pre><code>usage: mkslurm_hetjob [-h] [-S S] [-s S] [-m M] [-C C] [-g G] [-N N] [-t T]\n                      [-a A] [-j J] [-v]\n\nPython version of mkslurm_alt by Andrew Coward using HetJob. Server placement\nand spacing remains as mkslurm but clients are always tightly packed with a\ngap left every \"NC_GAP\" cores where NC_GAP can be given by the -g argument.\nvalues of 4, 8 or 16 are recommended.\n\noptional arguments:\n  -h, --help  show this help message and exit\n  -S S        num_servers (default: 4)\n  -s S        server_spacing (default: 8)\n  -m M        max_servers_per_node (default: 2)\n  -C C        num_clients (default: 28)\n  -g G        client_gap_interval (default: 4)\n  -N N        ncores_per_node (default: 128)\n  -t T        time_limit (default: 00:10:00)\n  -a A        account (default: n01)\n  -j J        job_name (default: nemo_test)\n  -v          show human readable hetjobs (default: False)\n</code></pre> <p>Note</p> <p>We recommend that you retain your own copy of this script as it is not directly provided by the ARCHER2 CSE team and subject to change. Once obtained, you can set your own defaults for options in the script.</p> <p>For example, to run with 4 XIOS I/O-servers (a maximum of 2 per node), each with sole occupancy of a 16-core NUMA region and 96 ocean cores, spaced with a idle core in between each, use:</p> <pre><code>./mkslurm_hetjob -S 4 -s 16 -m 2 -C 96 -g 2 &gt; myscript.slurm\n\nINFO:root:Running mkslurm_hetjob -S 4 -s 16 -m 2 -C 96 -g 2 -N 128 -t 00:10:00 -a n01 -j nemo_test -v False\nINFO:root:nodes needed= 2 (256)\nINFO:root:cores to be used= 100 (256)\n</code></pre> <p>This has reported that 2 nodes are needed with 100 active cores spread over 256 cores. This will also have produced a submission script \"myscript.slurm\":</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=nemo_test\n#SBATCH --time=00:10:00\n#SBATCH --account=n01\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-core=1\n\n# Created by: mkslurm_hetjob -S 4 -s 16 -m 2 -C 96 -g 2 -N 128 -t 00:10:00 -a n01 -j nemo_test -v False\nmodule swap craype-network-ofi craype-network-ucx\nmodule swap cray-mpich cray-mpich-ucx\nmodule load cray-hdf5-parallel/1.12.0.7\nmodule load cray-netcdf-hdf5parallel/4.7.4.7\nexport OMP_NUM_THREADS=1\n\ncat &gt; myscript_wrapper.sh &lt;&lt; EOFB\n#!/bin/ksh\n#\nset -A map ./xios_server.exe ./nemo\nexec_map=( 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 )\n#\nexec \\${map[\\${exec_map[\\$SLURM_PROCID]}]}\n##\nEOFB\nchmod u+x ./myscript_wrapper.sh\n\nsrun --mem-bind=local \\\n--ntasks=100 --ntasks-per-node=50 --cpu-bind=v,mask_cpu:0x1,0x10000,0x100000000,0x400000000,0x1000000000,0x4000000000,0x10000000000,0x40000000000,0x100000000000,0x400000000000,0x1000000000000,0x4000000000000,0x10000000000000,0x40000000000000,0x100000000000000,0x400000000000000,0x1000000000000000,0x4000000000000000,0x10000000000000000,0x40000000000000000,0x100000000000000000,0x400000000000000000,0x1000000000000000000,0x4000000000000000000,0x10000000000000000000,0x40000000000000000000,0x100000000000000000000,0x400000000000000000000,0x1000000000000000000000,0x4000000000000000000000,0x10000000000000000000000,0x40000000000000000000000,0x100000000000000000000000,0x400000000000000000000000,0x1000000000000000000000000,0x4000000000000000000000000,0x10000000000000000000000000,0x40000000000000000000000000,0x100000000000000000000000000,0x400000000000000000000000000,0x1000000000000000000000000000,0x4000000000000000000000000000,0x10000000000000000000000000000,0x40000000000000000000000000000,0x100000000000000000000000000000,0x400000000000000000000000000000,0x1000000000000000000000000000000,0x4000000000000000000000000000000,0x10000000000000000000000000000000,0x40000000000000000000000000000000 ./myscript_wrapper.sh\n</code></pre> <p>Submitting this script in a directory with the nemo and xios_server.exe executables will run the desired MPMD job. The exec_map array shows the position of each executable in the rank list (0 = xios_server.exe, 1 = nemo). For larger core counts the cpu_map can be limited to a single node map which will be cycled through as many times as necessary.</p>"},{"location":"research-software/nemo/#how-to-optimise-the-performance-of-nemo","title":"How to optimise the performance of NEMO","text":"<p>Note</p> <p>Our optimisation advice is based on the ARCHER2 4-cabinet preview system with the same node architecture as the current ARCHER2 service but a total of 1,024 compute nodes. During these investigations we used NEMO-4.0.6 and XIOS-2.5.  </p> <p>Through testing with idealised test cases to optimise the computational performance (i.e. without the demanding I/O management that is typical of NEMO production runs), we have found that drastically under-populating the nodes does not affect the performance of the computation. This indicates that users can reserve large portions of the nodes without a performance detriment. Users can run larger simulations by reserving up to 75% of the node can be reserved for I/O management (i.e. XIOS I/O-servers).</p> <p>XIOS I/O-servers can be more lightly packed than ocean clients and should be evenly distributed amongst the nodes i.e. not concentrated on a specific node. We found that placing 1 XIOS I/O-server per node with 4, 8, and 16 dedicated cores did not affect the performance. However, the performance was affected when allocating dedicated I/O-server cores outside of a 16-core NUMA region. Thus, users should confine XIOS I/O-servers to NUMA regions to improve performance and benefit from the memory hierarchy.</p>"},{"location":"research-software/nemo/#a-performance-investigation","title":"A performance investigation","text":"<p>Note</p> <p>These results were collated during early user testing of the ARCHER2 service by Andrew Coward and is subject to change.</p> <p>This table shows some preliminary results of a repeated 60 day simulation of the ORCA2_ICE_PISCES, SETTE configuration using various core counts and packing strategies:</p> <p></p> <p>Note</p> <p>These results used the mkslurm script, now hosted in <code>/work/n01/shared/nemo/old_scripts/mkslurm</code></p> <p>It is clear from the previous results that fully populating an ARCHER2 node is unlikely to provide the optimal performance for any codes with moderate memory bandwidth requirements. The explored regular packing strategy does not allow experimentation with less wasteful packing strategies than half-population though.</p> <p>There may be a case, for example, for just leaving every 1 in 4 cores idle, or every 1 in 8, or even fewer idle cores per node.  The mkslurm_alt script (/work/n01/shared/nemo/old_scripts/mkslurm_alt) provided a method of generating cpu-bind maps for exploring these strategies. The script assumed no change in the packing strategy for the servers but the core spacing argument (-c) for the ocean cores is replaced by a -g option representing the frequency of a gap in the, otherwise tightly-packed, ocean cores.</p> <p></p> <p>Preliminary tests have been conducted with the ORCA2_ICE_PISCES SETTE test case. This is a relatively small test case that will fit onto a single node. It is also small enough to perform well in attached mode. First some baseline tests in attached mode.</p> <p></p> <p>Previous tests used 4 I/O servers each occupying a single NUMA. For this size model, 2 servers occupying half a NUMA each will suffice.  That leaves 112 cores with which to try different packing strategies. Is it possible to match or better this elapsed time on a single node including external I/O servers?  -Yes!  -but not with an obvious gap frequency:</p> <p></p> <p>And activating land suppression can reduce times further:</p> <p></p> <p>The optimal two-node solution is also shown (this is quicker but the one node solution is cheaper).</p> <p>This leads us to the current iteration of the mkslurm script - mkslurm_hetjob. Note a tightly-packed placement with no gaps amongst the ocean processes can be generated using a client gap interval greater than the number of clients. This script has been used to explore the different placement strategies with a larger configuration based on eORCA025. In all cases, 8 XIOS servers were used, each with sole occupancy of a 16-core NUMA and a maximum of 2 servers per node. The rest of the initial 4 nodes (and any subsequent ocean core-only nodes) were filled with ocean cores at various packing densities (from tightly packed to half-populated). A summary of the results are shown below.</p> <p></p> <p>The limit of scalability for this problem size lies around 1500 cores. One interesting aspect is that the cost, in terms of node hours, remains fairly flat up to a thousand processes and the choice of gap placement makes much less difference as the individual domains shrink. It looks as if, so long as you avoid inappropriately high numbers of processors, choosing the wrong placement won't waste your allocation but may waste your time.</p>"},{"location":"research-software/nwchem/","title":"NWChem","text":"<p>NWChem aims to provide its users with computational chemistry tools that are scalable both in their ability to treat large scientific computational chemistry problems efficiently, and in their use of available parallel computing resources from high-performance parallel supercomputers to conventional workstation clusters. The NWChem software can handle: biomolecules, nanostructures, and solid-state system; from quantum to classical, and all combinations; Gaussian basis functions or plane-waves; scaling from one to thousands of processors; properties and relativity.</p>"},{"location":"research-software/nwchem/#useful-links","title":"Useful Links","text":"<ul> <li>NWChem home page</li> <li>NWChem documentation</li> <li>NWChem forum</li> </ul>"},{"location":"research-software/nwchem/#using-nwchem-on-archer2","title":"Using NWChem on ARCHER2","text":"<p>NWChem is released under an Educational Community License (ECL 2.0) and is freely available to all users on ARCHER2.</p>"},{"location":"research-software/nwchem/#where-can-i-get-help","title":"Where can I get help?","text":"<p>If you have problems accessing or running NWChem on ARCHER2, please contact the Service Desk. General questions on the use of NWChem might also be directed to the [NWChem forum][1]. More experienced users with detailed technical issues on NWChem should consider submitting them to the NWChem GitHub issue tracker.</p>"},{"location":"research-software/nwchem/#running-nwchem-jobs","title":"Running NWChem jobs","text":"<p>The following script will run a NWChem job using 2 nodes (256 cores) in the standard partition. It assumes that the input file is called <code>test_calc.nw</code>.</p> <pre><code>#!/bin/bash\n\n# Request 2 nodes with 128 MPI tasks per node for 20 minutes\n\n#SBATCH --job-name=NWChem_test\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code] \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the NWChem module, avoid any unintentional OpenMP threading by\n# setting OMP_NUM_THREADS, and launch the code.\nmodule load nwchem\nexport OMP_NUM_THREADS=1\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nsrun --distribution=block:block --hint=nomultithread nwchem test_calc\n</code></pre>"},{"location":"research-software/nwchem/#compiling-nwchem","title":"Compiling NWChem","text":"<p>The latest instructions for building NWChem on ARCHER2 may be found in the GitHub repository of build instructions:</p> <ul> <li>Build instructions for NWChem on      GitHub</li> </ul>"},{"location":"research-software/onetep/","title":"ONETEP","text":"<p>ONETEP (Order-N Electronic Total Energy Package) is a linear-scaling code for quantum-mechanical calculations based on density-functional theory.</p>"},{"location":"research-software/onetep/#useful-links","title":"Useful Links","text":"<ul> <li>ONETEP home page</li> <li>ONETEP tutorials</li> <li>ONETEP documentation</li> </ul>"},{"location":"research-software/onetep/#using-onetep-on-archer2","title":"Using ONETEP on ARCHER2","text":"<p>ONETEP is only available to users who have a valid ONETEP licence.</p> <p>If you have a ONETEP licence and wish to have access to ONETEP on ARCHER2, please make a request via the SAFE, see:</p> <ul> <li>How to request access to package      groups</li> </ul> <p>Please have your license details to hand.</p>"},{"location":"research-software/onetep/#running-parallel-onetep-jobs","title":"Running parallel ONETEP jobs","text":"<p>The following script, supplied by the ONETEP developers, will run a ONETEP job using 2 nodes (256 cores) with 16 MPI processes per node and 8 OpenMP threads per MPI process. It assumes that there is a single calculation options file with the <code>.dat</code> extension in the working directory.</p> <pre><code>#!/bin/bash\n\n# --------------------------------------------------------------------------\n# A SLURM submission script for ONETEP on ARCHER2 (full 23-cabinet system).\n# Central install, Cray compiler version.\n# Supports hybrid (MPI/OMP) parallelism.\n#\n# 2022.06 Jacek Dziedzic, J.Dziedzic@soton.ac.uk\n#                         University of Southampton\n#         Lennart Gundelach, L.Gundelach@soton.ac.uk\n#                            University of Southampton\n#         Tom Demeyere, T.Demeyere@soton.ac.uk\n#                       University of Southampton\n# --------------------------------------------------------------------------\n\n# v1.00 (2022.06.04) jd: Adapted from the user-compiled Cray compiler version.\n\n# ==========================================================================================================\n# Edit the following lines to your liking.\n#\n#SBATCH --job-name=mine               # Name of the job.\n#SBATCH --nodes=2                     # Number of nodes in job.\n#SBATCH --ntasks-per-node=16          # Number of MPI processes per node.\n#SBATCH --cpus-per-task=8             # Number of OMP threads spawned from each MPI process.\n#SBATCH --time=5:00:00                # Max time for your job (hh:mm:ss).\n#SBATCH --partition=standard          # Partition: standard memory CPU nodes with AMD EPYC 7742 64-core processor\n#SBATCH --account=t01                 # Replace 't01' with your budget code.\n#SBATCH --qos=standard                # Requested Quality of Service (QoS), See ARCHER2 documentation\n\nexport OMP_NUM_THREADS=8              # Repeat the value from 'cpus-per-task' here.\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Set up the job environment, loading the ONETEP module.\n# The module automatically sets OMP_PLACES, OMP_PROC_BIND and FI_MR_CACHE_MAX_COUNT.\n# To use a different binary, replace this line with either (drop the leading '#')\n# module load onetep/6.1.9.0-GCC-LibSci\n# to use the GCC-libsci binary, or with\n# module load onetep/6.1.9.0-GCC-MKL\n# to use the GCC-MKL binary.\n\nmodule load onetep/6.1.9.0-CCE-LibSci\n\n# ==========================================================================================================\n# !!! You should not need to modify anything below this line.\n# ==========================================================================================================\n\nworkdir=`pwd`\necho \"--- This is the submission script, the time is `date`.\"\n\n# Figure out ONETEP executable\nonetep_exe=`which onetep.archer2`\necho \"--- ONETEP executable is $onetep_exe.\"\n\nonetep_launcher=`echo $onetep_exe | sed -r \"s/onetep.archer2/onetep_launcher/\"`\n\necho \"--- workdir is '$workdir'.\"\necho \"--- onetep_launcher is '$onetep_launcher'.\"\n\n# Ensure exactly 1 .dat file in there.\nndats=`ls -l *dat | wc -l`\n\nif [ \"$ndats\" == \"0\" ]; then\necho \"!!! There is no .dat file in the current directory. Aborting.\" &gt;&amp;2\ntouch \"%NO_DAT_FILE\"\nexit 2\nfi\n\nif [ \"$ndats\" == \"1\" ]; then\ntrue\nelse\necho \"!!! More than one .dat file in the current directory, that's too many. Aborting.\" &gt;&amp;2\ntouch \"%MORE_THAN_ONE_DAT_FILE\"\nexit 3\nfi\n\nrootname=`echo *.dat | sed -r \"s/\\.dat\\$//\"`\nrootname_dat=$rootname\".dat\"\nrootname_out=$rootname\".out\"\nrootname_err=$rootname\".err\"\n\necho \"--- The input file is $rootname_dat, the output goes to $rootname_out and errors go to $rootname_err.\"\n\n# Ensure ONETEP executable is there and is indeed executable.\nif [ ! -x \"$onetep_exe\" ]; then\necho \"!!! $onetep_exe does not exist or is not executable. Aborting!\" &gt;&amp;2\ntouch \"%ONETEP_EXE_MISSING\"\nexit 4\nfi\n\n# Ensure onetep_launcher is there and is indeed executable.\nif [ ! -x \"$onetep_launcher\" ]; then\necho \"!!! $onetep_launcher does not exist or is not executable. Aborting!\" &gt;&amp;2\ntouch \"%ONETEP_LAUNCHER_MISSING\"\nexit 5\nfi\n\n# Dump the module list to a file.\nmodule list &gt;\\$modules_loaded 2&gt;&amp;1\n\nldd $onetep_exe &gt;\\$ldd\n\n# Report details\necho \"--- Number of nodes as reported by SLURM: $SLURM_JOB_NUM_NODES.\"\necho \"--- Number of tasks as reported by SLURM: $SLURM_NTASKS.\"\necho \"--- Using this srun executable: \"`which srun`\necho \"--- Executing ONETEP via $onetep_launcher.\"\n\n\n# Actually run ONETEP\n# Additional srun options to pin one thread per physical core\n########################################################################################################################################################\nsrun --hint=nomultithread --distribution=block:block -N $SLURM_JOB_NUM_NODES -n $SLURM_NTASKS $onetep_launcher -e $onetep_exe -t $OMP_NUM_THREADS $rootname_dat &gt;$rootname_out 2&gt;$rootname_err\n########################################################################################################################################################\n\necho \"--- srun finished at `date`.\"\n\n# Check for error conditions\nresult=$?\nif [ $result -ne 0 ]; then\necho \"!!! srun reported a non-zero exit code $result. Aborting!\" &gt;&amp;2\ntouch \"%SRUN_ERROR\"\nexit 6\nfi\n\nif [ -r $rootname.error_message ]; then\necho \"!!! ONETEP left an error message file. Aborting!\" &gt;&amp;2\ntouch \"%ONETEP_ERROR_DETECTED\"\nexit 7\nfi\n\ntail $rootname.out | grep completed &gt;/dev/null 2&gt;/dev/null\nresult=$?\nif [ $result -ne 0 ]; then\necho \"!!! ONETEP calculation likely did not complete. Aborting!\" &gt;&amp;2\ntouch \"%ONETEP_DID_NOT_COMPLETE\"\nexit 8\nfi\n\necho \"--- Looks like everything went fine. Praise be.\"\ntouch \"%DONE\"\n\necho \"--- Finished successfully at `date`.\"\n</code></pre>"},{"location":"research-software/onetep/#hints-and-tips","title":"Hints and Tips","text":"<p>See the information in the ONETEP documentation.</p>"},{"location":"research-software/onetep/#compiling-onetep","title":"Compiling ONETEP","text":"<p>The latest instructions for building ONETEP on ARCHER2 may be found in the GitHub repository of build instructions:</p> <ul> <li>Build instructions for ONETEP on      GitHub</li> </ul>"},{"location":"research-software/openfoam/","title":"OpenFOAM","text":"<p>OpenFOAM is an open-source toolbox for computational fluid dynamics. OpenFOAM consists of generic tools to simulate complex physics for a variety of fields of interest, from fluid flows involving chemical reactions, turbulence and heat transfer, to solid dynamics, electromagnetism and the pricing of financial options.</p> <p>The core technology of OpenFOAM is a flexible set of modules written in C++. These are used to build solvers and utilities to perform pre-processing and post-processing tasks ranging from simple data manipulation to visualisation and mesh processing.</p> <p>There are a number of different flavours of the OpenFOAM package with slightly different histories, and slightly different features. The two most common are distributed by openfoam.org and openfoam.com.</p>"},{"location":"research-software/openfoam/#useful-links","title":"Useful Links","text":"<ul> <li>OpenFOAM website (.org)</li> <li>OpenFOAM documentation (.org)</li> <li>OpenFOAM website (.com)</li> <li>OpenFOAM documentation (.com)</li> </ul>"},{"location":"research-software/openfoam/#using-openfoam-on-archer2","title":"Using OpenFOAM on ARCHER2","text":"<p>OpenFOAM is released under a GPL v3 license and is freely available to all users on ARCHER2.</p> Upgrade 2023Full system <pre><code>auser@ln01&gt; module avail openfoam\n--------------- /work/y07/shared/archer2-lmod/apps/core -----------------\nopenfoam/com/v2106        openfoam/org/v9.20210903\nopenfoam/com/v2212 (D)    openfoam/org/v10.20230119 (D)\n</code></pre> <p>Note: the older versions were recompiled under PE22.12 in April 2023.</p> <pre><code>auser@ln01&gt; module avail openfoam\n--------------- /work/y07/shared/archer2-lmod/apps/core -----------------\nopenfoam/com/v2106          openfoam/org/v9.20210903 (D)\nopenfoam/org/v8.20200901\n</code></pre> <p>Versions from openfoam.org are typically v8.0 etc and there is typically one release per year (in June; with a patch release in September). Versions from openfoam.com are e.g., v2106 (to be read as 2021 June) and there are typically two releases a year (one in June, and one in December).</p> <p>To use OpenFOAM on ARCHER2 you should first load an OpenFOAM module, e.g.</p> <pre><code>user@ln01:&gt; module load PrgEnv-gnu\nuser@ln01:&gt; module load openfoam/com/v2106\n</code></pre> <p>(Note that the <code>openfoam</code> module will automatically load <code>PrgEnv-gnu</code> if it is not already active.) The module defines only the base installation directory via the environment variable <code>FOAM_INSTALL_DIR</code>. After loading the module you need to source the <code>etc/bashrc</code> file provided by OpenFOAM, e.g.</p> <pre><code>source ${FOAM_INSTALL_DIR}/etc/bashrc\n</code></pre> <p>You should then be able to use OpenFOAM. The above commands will also need to be added to any job/batch submission scripts you want to use to run OpenFOAM. Note that all the centrally installed versions of OpenFOAM are compiled under <code>PrgEnv-gnu</code>.</p> <p>Note there are no default module versions specified. It is recommended to use a fully qualified module name (with the exact version, as in the example above).</p>"},{"location":"research-software/openfoam/#running-parallel-openfoam-jobs","title":"Running parallel OpenFOAM jobs","text":"<p>While it is possible to run limited OpenFOAM pre-processing and post-processing activities on the front end, we request all significant work is submitted to the queue system. Please remember that the front end is a shared resource.</p> <p>A typical SLURM job submission script for OpenFOAM is given here. This would request 4 nodes to run with 128 MPI tasks per node (a total of 512 MPI tasks). Each MPI task is allocated one core (<code>--cpus-per-task=1</code>).</p> Upgrade 2023Full system <pre><code>#!/bin/bash\n\n#SBATCH --nodes=4\n#SBATCH --tasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --distribution=block:block\n#SBATCH --hint=nomultithread\n#SBATCH --time=00:10:00\n\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Load the appropriate module and source the OpenFOAM bashrc file\n\nmodule load openfoam/org/v10.20230119\n\nsource ${FOAM_INSTALL_DIR}/etc/bashrc\n\n# Run OpenFOAM work, e.g.,\n\nsrun interFoam -parallel\n</code></pre> <pre><code>#!/bin/bash\n\n#SBATCH --nodes=4\n#SBATCH --tasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --distribution=block:block\n#SBATCH --hint=nomultithread\n#SBATCH --time=00:10:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the appropriate module and source the OpenFOAM bashrc file\n\nmodule load openfoam/org/v8.20210901\n\nsource ${FOAM_INSTALL_DIR}/etc/bashrc\n\n# Run OpenFOAM work, e.g.,\n\nsrun interFoam -parallel\n</code></pre>"},{"location":"research-software/openfoam/#compiling-openfoam","title":"Compiling OpenFOAM","text":"<p>If you want to compile your own version of OpenFOAM, instructions are available for ARCHER2 at:</p> <ul> <li>Build instructions for OpenFOAM on GitHub</li> </ul>"},{"location":"research-software/openfoam/#extensions-to-openfoam","title":"Extensions to OpenFOAM","text":"<p>Many packages extend the central OpenFOAM functionality in some way. However, there is no completely standardised way in which this works. Some packages assume they have write access to the main OpenFOAM installation. If this is the case, you must install your own version before continuing. This can be done on an individual basis, or a per-project basis using the project shared directories.</p>"},{"location":"research-software/openfoam/#module-version-history","title":"Module version history","text":"<p>The following centrally installed versions are available.</p>"},{"location":"research-software/openfoam/#upgrade-2023","title":"Upgrade 2023","text":"<ul> <li> <p>Module <code>openfoam/com/v2212</code> installed as default April 2023 (PE 22.12).   This is version v2212 (December 2022).   See the OpenFOAM.com v2212 release announcement</p> </li> <li> <p>Module <code>openfoam/com/v2106</code> was recompiled April 2023 (PE 22.12).   This is version v2106 (June 2021).   See the OpenFOAM.com v2106 release announcement</p> </li> <li> <p>Module <code>openfoam/org/v10.20230119</code> installed as default April 2023 (PE 22.12)   This is version 10 patch release 19th January 2023.   See version 10 patch news</p> </li> <li> <p>Module <code>openfoam/org/v9.20210903</code> was recompiled April 2023 (PE 22.12).   This is version 9 patch release 3rd September 2021.   See version 9 patch release news.</p> </li> </ul>"},{"location":"research-software/openfoam/#full-system","title":"Full system","text":"<ul> <li> <p>Module <code>openfoam/com/v2106</code> installed October 2021 (Cray PE 21.04).   Version v2106 (June 2021).   See OpenFOAM.com website</p> </li> <li> <p>Module <code>openfoam/org/v9.20200903</code> installed October 2021 (Cray PE 21.09).   Version 9 patch release 3rd September 2021.   See OpenFOAM.org website</p> </li> <li> <p>Module <code>openfoam/org/v8.20200901</code> installed October 2021 (Cray PE 21.09).   Version 8 patch release 1st September 2020.   See OpenFOAM.org website</p> </li> </ul>"},{"location":"research-software/orca/","title":"ORCA","text":"<p>ORCA is an ab initio quantum chemistry program package that contains modern electronic structure methods including density functional theory, many-body perturbation, coupled cluster, multireference methods, and semi-empirical quantum chemistry methods. Its main field of application is larger molecules, transition metal complexes, and their spectroscopic properties. ORCA is developed in the research group of Frank Neese. The free version is available only for academic use at academic institutions.</p> <p>Important</p> <p>ORCA is not part of the officially supported software on ARCHER2. While the ARCHER2 service desk is able to provide support for basic use of this software (e.g. access to software, writing job submission scripts) it does not generally provide detailed technical support for the software and you may be directed to seek support from other places if the service desk cannot answer the questions.</p>"},{"location":"research-software/orca/#useful-links","title":"Useful Links","text":"<ul> <li>ORCA Forum</li> </ul>"},{"location":"research-software/orca/#using-orca-on-archer2","title":"Using ORCA on ARCHER2","text":"<p>ORCA is available for academic use on ARCHER2 only. If you wish to use ORCA for commercial applications, you must contact the ORCA developers.</p>"},{"location":"research-software/orca/#running-parallel-orca-jobs","title":"Running parallel ORCA jobs","text":"<p>The following script will run an ORCA job on the ARCHER2 system using 256 MPI processes across 2 nodes, each MPI process will be placed on a separate physical core. It assumes that the input file is <code>my_calc.inp</code></p> <pre><code>#!/bin/bash\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=0:20:00\n\n# Replace [budget code] below with your project code (e.g. e05)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\nmodule load other-software\nmodule load orca\n\n# Launch the ORCA calculation\n#   * You must use \"$ORCADIR/orca\" so the application has the full executable path\n#   * Do not use \"srun\" to launch parallel ORCA jobs as they use OpenMPI rather than Cray MPICH\n#   * Remember to change the name of the input file to match your file name\n$ORCADIR/orca my_calc.inp\n</code></pre>"},{"location":"research-software/qe/","title":"Quantum Espresso","text":"<p>Quantum Espresso (QE) is an integrated suite of open-source computer codes for electronic-structure calculations and materials modeling at the nanoscale. It is based on density-functional theory, plane waves, and pseudopotentials.</p>"},{"location":"research-software/qe/#useful-links","title":"Useful Links","text":"<ul> <li>Quantum Espresso home page</li> <li>Quantum Espresso User Guides</li> <li>Quantum Espresso Tutorials</li> </ul>"},{"location":"research-software/qe/#using-qe-on-archer2","title":"Using QE on ARCHER2","text":"<p>QE is released under a GPL v2 license and is freely available to all ARCHER2 users.</p>"},{"location":"research-software/qe/#running-parallel-qe-jobs","title":"Running parallel QE jobs","text":"<p>For example, the following script will run a QE <code>pw.x</code> job using 4 nodes (128x4 cores).</p> <pre><code>#!/bin/bash\n\n# Request 4 nodes to run a 512 MPI task job with 128 MPI tasks per node.\n# The maximum walltime limit is set to be 20 minutes.\n\n#SBATCH --job-name=qe_test\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code] \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the relevant Quantum Espresso module\nmodule load quantum_espresso\n\n#\u00a0Set number of OpenMP threads to 1 to prevent multithreading by libraries\nexport OMP_NUM_THREADS=1\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nsrun --hint=nomultithread --distribution=block:block pw.x &lt; test_calc.in\n</code></pre>"},{"location":"research-software/qe/#hints-and-tips","title":"Hints and tips","text":"<p>The QE module is set to load up the default QE-provided pseudo-potentials. If you wish to use non-default pseudo-potentials, you will need to change the <code>ESPRESSO_PSEUDO</code> variable to point to the directory you wish. This can be done by adding the following line after the module is loaded</p> <pre><code>export ESPRESSO_PSEUDO /path/to/pseudo_potentials\n</code></pre>"},{"location":"research-software/qe/#compiling-qe","title":"Compiling QE","text":"<p>The latest instructions for building QE on ARCHER2 can be found in the GitHub repository of build instructions:</p> <ul> <li>Build instructions for Quantum Espresso</li> </ul>"},{"location":"research-software/vasp/","title":"VASP","text":"<p>The Vienna Ab initio Simulation Package (VASP) is a computer program for atomic scale materials modelling, e.g. electronic structure calculations and quantum-mechanical molecular dynamics, from first principles.</p> <p>VASP computes an approximate solution to the many-body Schr\u00f6dinger equation, either within density functional theory (DFT), solving the Kohn-Sham equations, or within the Hartree-Fock (HF) approximation, solving the Roothaan equations. Hybrid functionals that mix the Hartree-Fock approach with density functional theory are implemented as well. Furthermore, Green's functions methods (GW quasiparticles, and ACFDT-RPA) and many-body perturbation theory (2nd-order M\u00f8ller-Plesset) are available in VASP.</p> <p>In VASP, central quantities, like the one-electron orbitals, the electronic charge density, and the local potential are expressed in plane wave basis sets. The interactions between the electrons and ions are described using norm-conserving or ultrasoft pseudopotentials, or the projector-augmented-wave method.</p> <p>To determine the electronic ground state, VASP makes use of efficient iterative matrix diagonalisation techniques, like the residual minimisation method with direct inversion of the iterative subspace (RMM-DIIS) or blocked Davidson algorithms. These are coupled to highly efficient Broyden and Pulay density mixing schemes to speed up the self-consistency cycle.</p>"},{"location":"research-software/vasp/#useful-links","title":"Useful Links","text":"<ul> <li>VASP Manual</li> <li>VASP wiki</li> <li>VASP FAQs</li> </ul>"},{"location":"research-software/vasp/#using-vasp-on-archer2","title":"Using VASP on ARCHER2","text":"<p>VASP is only available to users who have a valid VASP licence.</p> <p>If you have a VASP 5 or 6 licence and wish to have access to VASP on ARCHER2, please make a request via the SAFE, see:</p> <ul> <li>How to request access to package groups</li> </ul> <p>Please have your license details to hand.</p> <p>Note</p> <p>Both VASP 5 and VASP 6 are available on ARCHER2. You generally need a different licence for each of these versions.</p>"},{"location":"research-software/vasp/#running-parallel-vasp-jobs","title":"Running parallel VASP jobs","text":"<p>To access VASP you should load the appropriate <code>vasp</code> module in your job submission scripts.</p> <p>To load the default version of VASP, you would use:</p> <pre><code>module load vasp\n</code></pre> <p>Once loaded, the executables are called:</p> <ul> <li><code>vasp_std</code> - Multiple k-point version</li> <li><code>vasp_gam</code> - GAMMA-point only version</li> <li><code>vasp_ncl</code> - Non-collinear version</li> </ul> <p>Once the module has been loaded, you can access the LDA and PBE pseudopotentials for VASP on ARCHER2 at:</p> <pre><code>$VASP_PSPOT_DIR\n</code></pre> <p>Tip</p> <p>VASP 6 can make use of OpenMP threads in addition to running with pure MPI. We will add notes on performance and use of threading in VASP as information becomes available.</p> <p>Example VASP submission script</p> <pre><code>#!/bin/bash\n\n# Request 16 nodes (2048 MPI tasks at 128 tasks per node) for 20 minutes.   \n\n#SBATCH --job-name=VASP_test\n#SBATCH --nodes=16\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:20:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code] \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the VASP module\nmodule load vasp/6\n\n# Avoid any unintentional OpenMP threading by setting OMP_NUM_THREADS\nexport OMP_NUM_THREADS=1\n\n# Ensure the cpus-per-task option is propagated to srun commands\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Launch the code - the distribution and hint options are important for performance\nsrun --distribution=block:block --hint=nomultithread vasp_std\n</code></pre>"},{"location":"research-software/vasp/#vasp-transition-state-tools-vtst","title":"VASP Transition State Tools (VTST)","text":"<p>As well as the standard VASP 5 modules, we provide versions of VASP 5 with the VASP Transition State Tools (VTST) from the University of Texas added. The VTST version adds various functionality to VASP and provides additional scripts to use with VASP. Additional functionality includes:</p> <ul> <li>Climbing Image NEB: method for finding reaction pathways between two stable states.</li> <li>Dimer: method for finding reaction pathways when only one state is known.</li> <li>Lanczos: provides an alternative way to find the lowest mode and find saddle points.</li> <li>Optimisers: provides an alternative way to find the lowest mode and find saddle points.</li> <li>Dynamical Matrix: uses finite difference to find normal modes and reaction prefactors.</li> </ul> <p>Full details of these methods and the provided scripts can be found on the VTST website.</p> <p>On ARCHER2, the VTST version of VASP 5 can be accessed by loading the modules with <code>VTST</code> in the module name, for example:</p> <pre><code>module load vasp/6/6.4.1-vtst\n</code></pre>"},{"location":"research-software/vasp/#compiling-vasp-on-archer2","title":"Compiling VASP on ARCHER2","text":"<p>If you wish to compile your own version of VASP on ARCHER2 (either VASP 5 or VASP 6) you can find information on how we compiled the central versions in the build instructions GitHub repository. See:</p> <ul> <li>Build instructions for VASP on GitHub</li> </ul>"},{"location":"research-software/vasp/#tips-for-using-vasp-on-archer2","title":"Tips for using VASP on ARCHER2","text":""},{"location":"research-software/vasp/#switching-mpi-transport-protocol-from-openfabrics-to-ucx","title":"Switching MPI transport protocol from OpenFabrics to UCX","text":"<p>The VASP modules are setup to use the OpenFabrics MPI transport protocol as testing has shown that this passes all the regression tests and gives the most reliable operation on ARCHER2. However, there may be cases where using UCX can give better performance than OpenFabrics.</p> <p>If you want to try the UCX transport protocol then you can do this  using by loading additional modules after you have loaded the VASP modules. For example, for VASP 6, you would use:</p> <pre><code>module load vasp/6\nmodule load craype-network-ucx\nmodule load cray-mpich-ucx\n</code></pre>"},{"location":"research-software/castep/castep/","title":"Castep","text":"<p>This page has moved</p>"},{"location":"research-software/chemshell/chemshell/","title":"Chemshell","text":"<p>This page has moved</p>"},{"location":"research-software/code-saturne/code-saturne/","title":"Code saturne","text":"<p>This page has moved</p>"},{"location":"research-software/cp2k/cp2k/","title":"Cp2k","text":"<p>This page has moved</p>"},{"location":"research-software/fhi-aims/fhi-aims/","title":"Fhi aims","text":"<p>This page has moved</p>"},{"location":"research-software/gromacs/gromacs/","title":"Gromacs","text":"<p>This page has moved</p>"},{"location":"research-software/lammps/lammps/","title":"Lammps","text":"<p>This page has moved</p>"},{"location":"research-software/mitgcm/mitgcm/","title":"Mitgcm","text":"<p>This page has moved</p>"},{"location":"research-software/mo-unified-model/mo-unified-model/","title":"Mo unified model","text":"<p>This page has moved</p>"},{"location":"research-software/namd/namd/","title":"Namd","text":"<p>This page has moved</p>"},{"location":"research-software/nektarplusplus/nektarplusplus/","title":"Nektarplusplus","text":"<p>This page has moved</p>"},{"location":"research-software/nemo/nemo/","title":"Nemo","text":"<p>This page has moved</p>"},{"location":"research-software/nwchem/nwchem/","title":"Nwchem","text":"<p>This page has moved</p>"},{"location":"research-software/onetep/onetep/","title":"Onetep","text":"<p>This page has moved</p>"},{"location":"research-software/openfoam/openfoam/","title":"Openfoam","text":"<p>This page has moved</p>"},{"location":"research-software/qe/qe/","title":"Qe","text":"<p>This page has moved</p>"},{"location":"research-software/vasp/vasp/","title":"Vasp","text":"<p>This page has moved</p>"},{"location":"software-libraries/","title":"Software Libraries","text":"<p>This section provides information on centrally-installed software libraries and library-based packages. These provide significant functionality that is of interest to both users and developers of applications.</p> <p>Libraries are made available via the module system, and fall into a number of distinct groups.</p>"},{"location":"software-libraries/#libraries-via-modules-cray-","title":"Libraries via modules <code>cray-*</code>","text":"<p>The following libraries are available as modules prefixed by <code>cray-</code> and may be of direct interest to developers and users. The modules are provided by HPE Cray to be optimised for performance on the ARCHER2 hardware, and should be used where possible. The relevant modules are:</p> <ul> <li> <p>cray-fftw ...details for module load cray-fttw...</p> <p>FFTW (Fastest Fourier Transform in the West) is a standard package for discrete Fourier transforms. See the FFTW home page</p> </li> <li> <p>cray-hdf5 and cray-hdf5-parallel ...details for hdf5...</p> <p>Hierarchical Data Format (HDF5) is a high-performance and portable data format and data model. These modules provide serial and parallel variants of HDF5. See the HDF5 home page</p> </li> <li> <p>cray-libsci ...details for cray-libsci...</p> <p>BLAS, LAPACK, BLACS, and SCALAPACK provide basic linear algebra  functionality such as vector-vector, matrix-vector, and  matrix-matrix multiplication.  Module <code>cray-libsci</code> is loaded by default in all programming  environments.</p> </li> <li> <p>cray-netcdf ...details for cray-netcdf...</p> <p>Serial version of Network Common Data Form (NetCDF), a widely used and portable data format. See the NETCDF website</p> </li> <li> <p>cray-netcdf-hdf5parallel</p> <p>A serial NetCDF built against parallel HDF5. Load module <code>cray-hdf5-parallel</code> first.</p> </li> <li> <p>cray-parallel-netcdf ...deatils for Parallel NetCDF...</p> <p>A parallel NetCDF implementation (sometimes referred to as \"Pnetcdf\").</p> </li> </ul>"},{"location":"software-libraries/#integration-with-compiler-environment","title":"Integration with compiler environment","text":"<p>All libraries provided by  modules prefixed <code>cray-</code> integrate with the compiler environment, and so appropriate compiler and link stage options are injected when using the standard compiler wrappers <code>cc</code>, <code>CC</code> and <code>ftn</code>.</p>"},{"location":"software-libraries/#libraries-supported-by-archer2-cse-team","title":"Libraries supported by ARCHER2 CSE team","text":"<p>The following libraries will also made available by the ARCHER2 CSE team:</p> <ul> <li> <p>ADIOS ...details for ADIOS on ARCHER2...</p> <p>ADIOS (Adaptable I/O System) provides library services for parallel I/O.</p> </li> <li> <p>AOCL ...details for AOCL on ARCHER2...</p> <p>AOCL (AMD Optimizing CPU Libraries) provides a set of numerical libraries optimised for AMD \"Zen\"-based processors. </p> </li> <li> <p>ARPACK-NG ...details for ARPACK-NG on ARCHER2...</p> <p>ARPACK-NG (Arnodli Package) computes eigenvalues and eigenvectors of large sparse matrics.</p> </li> <li> <p>Boost ...details for Boost on ARCHER2...</p> <p>Boost is a portable C++ library providing reference implementations of many common containers, operations and algorithms.</p> </li> <li> <p>Eigen ...details for Eigen on ARCHER2...</p> <p>Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms.</p> </li> <li> <p>GLM ...details for GLM on ARCHER2...</p> <p>GLM (GL Math library) is a C++ header-only library for performing operations commonly encountered in graphics applications.</p> </li> <li> <p>Hypre ...details for HYPRE on ARCHER2...</p> <p>HYPRE provides pre-conditioners and solvers for sparse linear algebra problems.</p> </li> <li> <p>Metis and Parmetis ...details for Metis and Parmetis...</p> <p>METIS is a set of (serial) routines for partitioning graphs and meshes, and computing reduced-fill orderings of sparse matrices. It is commonly used e.g., to compute decompositions for finite element problems. Parmetis is the distributed memory counterpart.</p> </li> <li> <p>Mumps ...details for MUMPS on ARCHER2...</p> <p>MUMPS provides parallel direct solution of large sparse matrix problems.</p> </li> <li> <p>PETSc ...details for PETSc on ARCHER2...</p> <p>PETSc is a general package with functionality related to the solution of a wide range of problems described by partial differential equations.</p> </li> <li> <p>Scotch ...details for Scotch and PT-Scotch on ARCHER2...</p> <p>Scotch (and its parallel partner PT-Scotch) is a graph partitioning library.</p> </li> <li> <p>SLEPc ...details for SLEPc on ARCHER2...</p> <p>SLEPc is a package for large eigenvalue problems based on PETSc.</p> </li> <li> <p>SuperLU and SuperLU_DIST ...details for SuperLU on ARCHER2...</p> <p>SuperLU provides solutions to large non-symmetric sparse systems. SuperLU_DIST is the distributed memory version.</p> </li> <li> <p>Trilinos ...details for Trilinos on ARCHER2...</p> <p>Trilinos is a large collection of packages for the solution of complex scientific and engineering problems.</p> </li> </ul>"},{"location":"software-libraries/#integration-with-compiler-environment_1","title":"Integration with compiler environment","text":"<p>Again, all the libraries listed above are supported by all programming environments via the module system. Additional compile and link time flags should not be required.</p>"},{"location":"software-libraries/#building-your-own-library-versions","title":"Building your own library versions","text":"<p>For the libraries listed in this section, a set of build and installation scripts are available at the ARCHER2 Github repository.</p> <p>Follow the instructions to build the relevant package (note this is the <code>cse-develop</code> branch of the repository). See also individual libraries pages in the list above for further details.</p> <p>The scripts available from this repository should work in all three programming environments.</p>"},{"location":"software-libraries/adios/","title":"ADIOS","text":"<p>The Adaptable I/O System (ADIOS) is developed at Oak Ridge National Laboratory and is freely available under a BSD license.</p>"},{"location":"software-libraries/adios/#version-history","title":"Version history","text":"Upgrade 2023 <p>The central installation of ADIOS (version 1) has been removed as it is no longer actively developed. A central installation of ADIOS (version 2) will be considered as a replacement.</p> Full system4-cabinet system <ul> <li>Module <code>adios/1.13.1</code> installed October 2021 (PE 21.04)</li> </ul> <ul> <li>Module <code>adios/1.13.1</code> installed January 2021</li> </ul>"},{"location":"software-libraries/adios/#compile-your-own-version","title":"Compile your own version","text":"<p>The Archer2 github repository provides a script which can be used to build ADIOS (version 1), e.g.,: <pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout modules-2022-12\n$ module load cray-hdf5-parallel\n$ ./sh/adios.sh --prefix=/path/to/install/location\n</code></pre> where the <code>--prefix</code> option determines the install location. See the Archer2 github repository for further details and options.</p>"},{"location":"software-libraries/adios/#using-adios","title":"Using ADIOS","text":"<p>Configuration details for ADIOS are obtained via the utility <code>adios_config</code> which should be available in the <code>PATH</code> once ADIOS is installed. For example, to recover the compiler options required to provide serial C include files, issue: <pre><code>$ adios_config -s -c\n</code></pre> Use <code>adios_config --help</code> for a summary of options.</p> <p>To compile and link application, such statements can be embedded in a Makefile via, e.g., <pre><code>ADIOS_INC := $(shell adios_config -s -c)\nADIOS_CLIB := $(shell adios_config -s -l)\n</code></pre> See the ADIOS user manual for further details and examples.</p>"},{"location":"software-libraries/adios/#resources","title":"Resources","text":"<p>The ADIOS home page</p> <p>ADIOS user manual (v1.10 pdf version)</p> <p>ADIOS 1.x github repository</p>"},{"location":"software-libraries/aocl/","title":"AMD Optimizing CPU Libraries (AOCL)","text":"<p>AMD Optimizing CPU Libraries (AOCL) are a set of numerical libraries optimized for AMD \u201cZen\u201d-based processors, including EPYC, Ryzen Threadripper PRO, and Ryzen.</p> <p>AOCL is comprised of eight libraries: - BLIS (BLAS Library) - libFLAME (LAPACK) - AMD-FFTW - LibM (AMD Core Math Library) - ScaLAPACK - AMD Random Number Generator (RNG) - AMD Secure RNG - AOCL-Sparse</p> <p>Tip</p> <p>AOCL <code>3.1</code> and <code>4.0</code> are available. <code>3.1</code> is default. </p>"},{"location":"software-libraries/aocl/#compiling-with-aocl","title":"Compiling with AOCL","text":"<p>Important</p> <p>AOCL does not currently support the Cray programming environment and is currently unavailable with <code>PrgEnv-cray</code> loaded.</p> <p>Important</p> <p>The <code>cray-libsci</code> module is loaded by default for all users and this module also contains definitions of BLAS, LAPACK and ScaLAPACK routines that conflict with those in AOCL. The <code>aocl</code> module automatically unloads <code>cray-libsci</code>.</p>"},{"location":"software-libraries/aocl/#gnu-programming-environment","title":"GNU Programming Environment","text":"<p>AOCL <code>3.1</code> and <code>4.0</code> is available for all versions of the GCC compilers: <code>gcc/11.2.0</code> and <code>gcc/10.3.0</code></p> <pre><code>module load PrgEnv-gnu\nmodule load aocl\n</code></pre>"},{"location":"software-libraries/aocl/#aocc-programming-environment","title":"AOCC Programming Environment","text":"<p>AOCL <code>3.1</code> and <code>4.0</code> is available for all versions of the AOCC compilers: <code>aocc/3.2.0</code>.</p> <pre><code>module load PrgEnv-aocc\nmodule load aocl\n</code></pre>"},{"location":"software-libraries/aocl/#resources","title":"Resources","text":"<p>For more information on AOCL, please see: https://developer.amd.com/amd-aocl/#documentation</p>"},{"location":"software-libraries/aocl/#version-history","title":"Version history","text":"<p>Current modules:</p> <ul> <li><code>aocl/3.1</code> installed June 2023</li> <li><code>aocl/4.0</code> installed June 2023</li> </ul>"},{"location":"software-libraries/arpack/","title":"ARPACK-NG","text":"<p>The Arnoldi Package (ARPACK) was designed to compute eigenvalues and eigenvectors of large sparse matrices. Originally from Rice University, an open source version (ARPACK-NG) is available under a BSD license and is made available here.</p>"},{"location":"software-libraries/arpack/#compiling-and-linking-with-arpack","title":"Compiling and linking with ARPACK","text":"<ul> <li><code>module load arpack-ng</code></li> </ul> <p>To compile an application against the ARPACK-NG libraries, load the <code>arpack-ng</code> module and use the compiler wrappers <code>cc</code>, <code>CC</code>, and <code>ftn</code> in the usual way.</p> <p>The <code>arpack-ng</code> module defines <code>ARPACK_NG_DIR</code> which locates the root of the installation for the current programming environment.</p>"},{"location":"software-libraries/arpack/#version-history","title":"Version history","text":"Full system4-cabinet system <ul> <li>Module <code>arpack-ng/3.8.0</code> installed October 2021 (PE 21.04)</li> </ul> <ul> <li>Not available</li> </ul>"},{"location":"software-libraries/arpack/#compiling-your-own-version","title":"Compiling your own version","text":"<p>The current supported version of MUMPS on Archer2 can be compiled using a script available from the Archer githug repository. <pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout modules-2021-10\n$ ./sh/arpack-ng.sh --prefix=/path/to/install/location\n</code></pre> where the <code>--prefix</code> specifies a suitable location. See the Archer2 github repository for further options and details.</p>"},{"location":"software-libraries/arpack/#resources","title":"Resources","text":"<p>Original ARPACK page</p> <p>ARPACK-NG github site</p>"},{"location":"software-libraries/boost/","title":"Boost","text":"<p>Boost provide portable C++ libraries useful in a broad range of contexts. The libraries are freely available under the terms of the Boost Software license.</p>"},{"location":"software-libraries/boost/#compiling-and-linking","title":"Compiling and linking","text":"<ul> <li><code>module load boost</code></li> </ul> <p>The C++ compiler wrapper <code>CC</code> will introduce the appropriate options to compile an application against the Boost libraries. The other compiler wrappers (<code>cc</code> and <code>ftn</code>) do not introduce these options.</p> <p>To check exactly what options are introduced type, e.g., <pre><code>$ CC --cray-print-opts\n</code></pre></p> <p>The <code>boost</code> module also defines the environment variable <code>BOOST_DIR</code> as the root of the installation for the current programming environment if this information is needed.</p>"},{"location":"software-libraries/boost/#version-history","title":"Version history","text":"Upgrade 2023Full system4-cabinet system <ul> <li>Module <code>boost/1.81.0</code> installed May 2023 (PE 22.12)</li> <li>Module <code>boost/1.72.0</code> recompiled May 2023 (PE 22.12)</li> </ul> <ul> <li>Module <code>boost/1.72</code> installed October 2021 (PE 21.04)</li> </ul> <ul> <li>Module <code>boost/1.72.0</code> installed January 2021</li> </ul> <p>The following libraries are installed: <code>atomic chrono container context contract coroutine date_time exception fiber filesystem graph_parallel graph iostreams locale log math mpi program_options random regex serialization stacktrace system test thread timer type_erasure wave</code></p>"},{"location":"software-libraries/boost/#compiling-boost","title":"Compiling Boost","text":"<p>The ARCHER2 Github repository contains a recipe for compiling Boost for the different programming environments. <pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout cse-develop\n$ ./sh/boost.sh --prefix=/path/to/install/location\n</code></pre> where the <code>--prefix</code> determines the install location. The list of libraries compiled is specified in the <code>boost.sh</code> script. See the ARCHER2 Github repository for further information.</p>"},{"location":"software-libraries/boost/#resources","title":"Resources","text":"<ul> <li> <p>Boost home page.</p> </li> <li> <p>Documentation (HTML) for the current version.</p> </li> <li> <p>Boost GitHub repository.</p> </li> </ul>"},{"location":"software-libraries/eigen/","title":"Eigen","text":"<p>Eigen is a C++ template library for linear algebra: matrices, vectors, numerical solvers, and related algorithms.</p>"},{"location":"software-libraries/eigen/#compiling-with-eigen","title":"Compiling with Eigen","text":"<ul> <li><code>module load eigen</code></li> </ul> <p>To compile an application with the Eigen header files, load the <code>eigen</code> module and use the compiler wrappers <code>cc</code>, <code>CC</code>, or <code>ftn</code> in the usual way. The relevant header files will be introduced automatically.</p> <p>The header files are located in <code>/work/y07/shared/libs/core/eigen/3.4.0/</code>, and can be included manually at compilation without loading the module if required.</p>"},{"location":"software-libraries/eigen/#version-history","title":"Version history","text":"<ul> <li>Module <code>eigen/3.4.0</code> installed October 2021</li> </ul>"},{"location":"software-libraries/eigen/#compiling-your-own-version","title":"Compiling your own version","text":"<p>The current supported version on Archer2 can be built using the following script <pre><code>$ wget https://gitlab.com/libeigen/eigen/-/archive/3.4.0/eigen-3.4.0.tar.gz\n$ tar xvf eigen-3.4.0.tar.gz\n$ cmake eigen-3.4.0/ -DCMAKE_INSTALL_PREFIX=/path/to/install/location\n$ make install\n</code></pre> where the <code>-DCMAKE_INSTALL_PREFIX</code> option determines the install directory. Installing in this way will also build the Eigen documentation and unit-tests.</p>"},{"location":"software-libraries/eigen/#resources","title":"Resources","text":"<p>Eigen home page</p> <p>Getting Started guide</p>"},{"location":"software-libraries/fftw/","title":"FFTW","text":"<ul> <li>Provides: FFTW v3</li> <li>Access: <code>module load cray-fftw</code></li> </ul> <p>FFTW is a C subroutine library (which includes a Fortran interface) for computing the discrete Fourier transform (DFT) in one or more dimensions, of arbitrary input size, and of both real and complex data (as well as of even/odd data, i.e. the discrete cosine/sine transforms or DCT/DST).</p> <p>Only the version 3 interface is available on ARCHER2.</p>"},{"location":"software-libraries/glm/","title":"GLM","text":"<p>OpenGL Mathemetics (GLM) is a header-only C++ library which performs operations typically encountered in graphics applications, but can also be relevant to scientific applications. GLM is freely available under an MIT license.</p>"},{"location":"software-libraries/glm/#compiling-with-glm","title":"Compiling with GLM","text":"<ul> <li><code>module load glm</code></li> </ul> <p>The compiler wrapper <code>CC</code> will automatically location the required include directory when the module is loaded.</p> <p>The <code>glm</code> module also defines the environment variable <code>GLM_DIR</code> which carries the root of the installation, if needed.</p>"},{"location":"software-libraries/glm/#version-history","title":"Version history","text":"Full system4-cabinet system <ul> <li>Module <code>glm/0.9.9.6</code> installed October 2021 (PE 21.04)</li> </ul> <ul> <li>Module <code>glm/0.9.9.6</code> installed January 2021</li> </ul>"},{"location":"software-libraries/glm/#install-your-own-version","title":"Install your own version","text":"<p>One can follow the instructions used to install the current version on ARCHER2 via the ARCHER2 Github repository: <pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout modules-2021-10\n$ ./sh/glm.sh --prefix=/path/to/install/location\n</code></pre> where the <code>--prefix</code> option sets the install location. See the ARCHER2 Github repository for further details.</p>"},{"location":"software-libraries/glm/#resources","title":"Resources","text":"<p>The GLM Github repository.</p>"},{"location":"software-libraries/hdf5/","title":"HDF5","text":"<p>The Hierarchical Data Format HDF5 (and its parallel manifestation HDF5 parallel) is a standard library and data format developed and supported by The HDF Group, and is released under a BSD-like license. </p> <p>Both serial and parallel versions are available on ARCHER2 as standard modules:</p> <ul> <li><code>module load cray-hdf5</code> (serial version)</li> <li><code>module load cray-hdf5-parallel</code> (MPI parallel version)</li> </ul> <p>Use <code>module help</code> to locate <code>cray-</code>specific release notes on a particular version.</p> <p>Known issues:</p> Upgrade 2023Full system4-cabinet system <ul> <li>There are no currently known issues.</li> </ul> <ul> <li>There is currently a problem with the module file which means   <code>cray-hdf5-parallel</code> will not operate correctly in <code>PrgEnv-aocc</code>.   One can load module <code>epcc-cray-hdf5-parallel</code> instead as a work-around   if <code>PrgEnv-aocc</code> is required.</li> </ul> <ul> <li>There are no currently known issues. </li> </ul> <p>Some general comments and information on serial and parallel I/O  to ARCHER2 are given in the section on I/O and file systems.</p>"},{"location":"software-libraries/hdf5/#resources","title":"Resources","text":"<p>Tutorials and introduction to HDF5 at the HDF5 Group pages.</p> <p>General information for developers of HDF5.</p>"},{"location":"software-libraries/hypre/","title":"HYPRE","text":"<p>HYPRE is a library of linear solvers for structured and unstructured problems with a particular emphasis on multigrid. It is a product of the Lawrence Livermore National Laboratory and is distributed under either the MIT license or the Apache license.</p>"},{"location":"software-libraries/hypre/#compiling-and-linking-with-hypre","title":"Compiling and linking with HYPRE","text":"<ul> <li><code>module load hypre</code></li> </ul> <p>To compile and link an application with the HYPRE libraries, load the <code>hypre</code> module and use the compiler wrappers <code>cc</code>, <code>CC</code>, or <code>ftn</code> in the usual way. The relevant include files and libraries will be introduced automatically.</p> <p>Two versions of HYPRE are included: one with, and one without, OpenMP. The relevant version will be selected if e.g., <code>-fopenmp</code> is included in the compile or link stage.</p> <p>The <code>hypre</code> module defines the environment variable <code>HYPRE_DIR</code> which will show the root of the installation for the current programming environment if required.</p>"},{"location":"software-libraries/hypre/#version-history","title":"Version history","text":"Upgrade 2023Full system4-cabinet system <ul> <li>module <code>hypre/2.25.0</code> installed as default May 2023 (PE 22.12)</li> <li>module <code>hypre/2.18.0</code> recompiled and installed May 2023 (PE 22.12)</li> </ul> <ul> <li>Module <code>hypre/2.18.0</code> installed October 2021 (PE 21.04)</li> </ul> <ul> <li>Module <code>hypre/2.18.0</code> installed January 2021</li> </ul>"},{"location":"software-libraries/hypre/#compiling-your-own-version","title":"Compiling your own version","text":"<p>The current supported version on Archer2 can be built using the script from the Archer2 repository: <pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout modules-2022-12\n$ ./sh/tpsl/hypre.sh --prefix=/path/to/install/location\n</code></pre> where the <code>--prefix</code> option determines the install directory. See the Archer2 github repository for more information.</p>"},{"location":"software-libraries/hypre/#resources","title":"Resources","text":"<p>HYPRE home page</p> <p>The latest HYPRE user manual (HTML)</p> <p>An older pdf version</p> <p>HYPRE github repository</p>"},{"location":"software-libraries/libsci/","title":"HPE Cray LibSci","text":"<ul> <li>Provides: BLAS, LAPACK, CBLAS, LAPACKE, BLACS, ScaLAPACK</li> <li>Access: <code>module load cray-libsci</code> (note: loaded by default for all users)</li> </ul> <p>Cray scientific libraries, available for all compiler choices provides access to the Fortran BLAS and LAPACK interface for basic linear algebra, the corresponding C interfaces CBLAS and LAPACKE, and BLACS and ScaLAPACK for parallel linear algebra. Type <code>man intro_libsci</code> for further details.</p>"},{"location":"software-libraries/matio/","title":"Matio","text":"<p>Matio is a library which allows reading and writing matrices in MATLAB MAT format. It is an open source development released under a BSD license.</p>"},{"location":"software-libraries/matio/#compiling-and-linking-against-matio","title":"Compiling and linking against Matio","text":"<ul> <li><code>module load matio</code></li> </ul> <p>Load the <code>matio</code> module and use the standard compiler wrappers <code>cc</code>, <code>CC</code>, or <code>ftn</code> in the usual way. The appropriate header files and libraries will be included automatically via the compiler wrappers.</p> <p>The <code>matio</code> module set the <code>PATH</code> variable so that the stand-alone utility <code>matdump</code> can be used. The module also defines <code>MATIO_PATH</code> which gives the root of the installation if this is needed.</p>"},{"location":"software-libraries/matio/#version-history","title":"Version history","text":"Upgrade 2023Full system4-cabinet system <ul> <li>Module <code>matio/1.5.23</code> installed May 2023 (PE 22.12)</li> <li>Module <code>matio/1.5.18</code> is removed.</li> </ul> <ul> <li>Module <code>matio/1.5.18</code> installed October 2021 (PE 21.04)</li> </ul> <ul> <li>Module <code>matio/1.5.18</code> installed January 2021</li> </ul>"},{"location":"software-libraries/matio/#compiling-your-own-version","title":"Compiling your own version","text":"<p>A version of Matio as currently installed on Archer2 can be compiled using the script avaailable from the Archer2 github repository:</p> <p><pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout modules-2022-12\n$ ./sh/tpsl/matio.sh --prefix=/path/to/install/location\n</code></pre> where <code>--prefix</code> defines the location of the installation.</p>"},{"location":"software-libraries/matio/#resources","title":"Resources","text":"<p>Matio github repository</p>"},{"location":"software-libraries/mesa/","title":"Mesa","text":"<p>Mesa is an open-source implementation of OpenGL, Vulkan, and other graphics API to vendor-specific hardware drivers.</p>"},{"location":"software-libraries/mesa/#compiling-with-mesa","title":"Compiling with Mesa","text":"<ul> <li><code>module load mesa</code></li> </ul> <p>To compile an application with the mesa header files, load the <code>mesa</code> module and use the compiler wrappers in the usual way. The relevant header files will be introduced automatically.</p> <p>The header files are located in <code>/work/y07/shared/libs/core/mesa/21.0.1/</code>, and can be included manually at compilation without loading the module if required.</p>"},{"location":"software-libraries/mesa/#version-history","title":"Version history","text":"<ul> <li>Module <code>mesa/21.0.1</code> installed June 2023</li> </ul>"},{"location":"software-libraries/mesa/#compiling-your-own-version","title":"Compiling your own version","text":"<p>Build recipe for this module can be found at the HPC-UK github repo</p>"},{"location":"software-libraries/mesa/#resources","title":"Resources","text":"<p>Mesa home page</p>"},{"location":"software-libraries/metis/","title":"Metis and Parmetis","text":"<p>The University of Minnesota provide a family of libraries for partitioning graphs and meshes, and computing fill-reducing ordering of sparse matrices. These libraries coming broadly under the label of \"Metis\". They are free to use for educational and research purposes.</p>"},{"location":"software-libraries/metis/#metis","title":"Metis","text":"<ul> <li><code>module load metis</code></li> </ul> <p>Metis is the sequential library for partitioning problems; it also supplies a number of simple stand-alone utility programs to access the Metis API for graph and mesh partitioning, and graph and mesh manipulation. The stand alone programs typically read a graph or mesh from file which must be in \"metis\" format.</p>"},{"location":"software-libraries/metis/#compiling-and-linking-with-metis","title":"Compiling and linking with Metis","text":"<p>The Metis library available via <code>module load metis</code> comes both with and without support for OpenMP. When using the compiler wrappers <code>cc</code>, <code>CC</code>, and <code>ftn</code>, the appropriate version will be selected based on the presence or absence of, e.g., <code>-fopenmp</code> in the compile or link invocation.</p> <p>Use, e.g., <pre><code>$ cc --cray-print-opts\n</code></pre> or <pre><code>$ cc -fopenmp --cray-print-opts\n</code></pre> to see exactly what options are being issued by the compiler wrapper when the <code>metis</code> module is loaded.</p> <p>Metis is currently provided as static libraries, so it should not be necessary to re-load the <code>metis</code> module at run time.</p> <p>The serial utilities (e.g. <code>gpmetis</code> for graph partitioning) are supplied without OpenMP. These may then be run on the front end for small problems if the <code>metis</code> module is loaded.</p> <p>The <code>metis</code> module defines the environment variable <code>METIS_DIR</code> which indicates the current location of the Metis installation.</p> <p>Note the <code>metis</code> and <code>parmetis</code> libraries (and dependent modules) have been compiled with the default 32-bit integer indexing, and 4-byte floating point options.</p>"},{"location":"software-libraries/metis/#parmetis","title":"Parmetis","text":"<ul> <li><code>module load parmetis</code></li> </ul> <p>Parmetis is the distributed memory incarnation of the Metis functionality. As for the <code>metis</code> module, Parmetis is integrated with use of the compiler wrappers <code>cc</code>, <code>CC</code>, and <code>ftn</code>.</p> <p>Parmetis depends on the <code>metis</code> module, which is loaded automatically by the <code>parmetis</code> module.</p> <p>The <code>parmetis</code> module defines the environment variable <code>PARMETIS_DIR</code> which holds the current location of the Parmetis installation. This variable may not respond to a change of compiler version within a given programming environment. If you wish to use <code>PARMETIS_DIR</code> in such a context, you may need to (re-)load the <code>parmetis</code> module after the change of compiler version.</p>"},{"location":"software-libraries/metis/#module-version-history","title":"Module version history","text":"Upgrade 2023Full system4-cabinet system <ul> <li>module <code>metis/5.1.0</code> recompiled and installed May 2023 (PE22.12)</li> <li>module <code>partmetis/4.0.3</code> recompiled and installed May 2023 (PE22.12)</li> </ul> <ul> <li>module <code>metis/5.1.0</code> installed October 2021 (PE21.04)</li> <li>module <code>parmetis/4.0.3</code> installed January 2021 (PE21.04)</li> </ul> <ul> <li>module <code>metis/5.1.0</code> installed January 2021</li> <li>module <code>parmetis/4.0.3</code> installed January 2021</li> </ul>"},{"location":"software-libraries/metis/#compile-your-own-version","title":"Compile your own version","text":"<p>The build procedure used for the Metis and Parmetis libraries on Archer2 is available via github.</p>"},{"location":"software-libraries/metis/#metis_1","title":"Metis","text":"<p>The latest Archer2 version of Metis can be installed</p> <pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout modules-2022-12\n$ ./sh/tpsl/metis.sh --prefix=/path/to/install/location\n</code></pre> <p>where <code>--prefix</code> determines the install location. This will download and install the default version for the current programming environment.</p>"},{"location":"software-libraries/metis/#parmetis_1","title":"Parmetis","text":"<p>Parmetis can be installed in via the same mechanism as Metis: <pre><code>$ ./sh/tpsl/parmetis.sh --prefix=/path/to/install/location\n</code></pre> The Metis package should be installed first (as above) using the same location. See the Archer2 repository for further details and options.</p>"},{"location":"software-libraries/metis/#resources","title":"Resources","text":"<p>-- Metis and Parmetis at github</p>"},{"location":"software-libraries/mkl/","title":"Intel Math Kernel Library (MKL)","text":"<p>The Intel Maths Kernel Libraries (MKL) contain a variety of optimised numerical libraries including BLAS, LAPACK, ScaLAPACK and FFTW. In general, the exact commands required to build against MKL depend on the details of compiler, environment, requirements for parallelism, and so on. The Intel MKL link line advisor should be consulted.</p> <p>Some examples are given below. Note that loading the <code>mkl</code> module will provide  the environment variable <code>MKLROOT</code> which holds the location of the various MKL components.</p> <p>Warning</p> <p>The ARCHER2 CSE team have seen that using MKL on ARCHER2 for some software  leads to failed regression tests due to numerical differences between refernece results and those produced with software using MKL. </p> <p>We strongly recommend that you use the HPE Cray LibSci and HPE Cray FFTW libraries for software if at all possible rather than MKL. If you do decide to use MKL on ARCHER2, then you should carefully validate results from your software to ensure that it is giving the expected results.</p> <p>Important</p> <p>The <code>cray-libsci</code> module is loaded by default for all users and this module  also contains definitions of BLAS, LAPACK and ScaLAPACK routines that conflict with those in MKL. The <code>mkl</code> module automatically unloads <code>cray-libsci</code>.</p> <p>Important</p> <p>The <code>mkl</code> module needs to be loaded both at compile time and at runtime (usually in your job submission script).</p> <p>Tip</p> <p>MKL only supports the GCC programming environment (<code>PrgEnv-gnu</code>). Other programming environments may work but this is untested and unsupported on ARCHER2.</p>"},{"location":"software-libraries/mkl/#serial-mkl-with-gcc","title":"Serial MKL with GCC","text":"<p>Swap modules:</p> <pre><code>module load PrgEnv-gnu\nmodule load mkl\n</code></pre> Language Compile options Link options Fortran <code>-m64  -I\"${MKLROOT}/include\"</code> <code>-L${MKLROOT}/lib/intel64 -Wl,--no-as-needed -lmkl_gf_lp64 -lmkl_sequential -lmkl_core -lpthread -lm -ldl</code> C/C++ <code>-m64  -I\"${MKLROOT}/include\"</code> <code>-L${MKLROOT}/lib/intel64 -Wl,--no-as-needed -lmkl_intel_lp64 -lmkl_sequential -lmkl_core -lpthread -lm -ldl</code>"},{"location":"software-libraries/mkl/#threaded-mkl-with-gcc","title":"Threaded MKL with GCC","text":"<p>Swap modules:</p> <pre><code>module load PrgEnv-gnu\nmodule load mkl\n</code></pre> Language Compile options Link options Fortran <code>-m64  -I\"${MKLROOT}/include\"</code> <code>-L${MKLROOT}/lib/intel64 -Wl,--no-as-needed -lmkl_gf_lp64 -lmkl_gnu_thread -lmkl_core -lgomp -lpthread -lm -ldl</code> C/C++ <code>-m64  -I\"${MKLROOT}/include\"</code> <code>-L${MKLROOT}/lib/intel64 -Wl,--no-as-needed -lmkl_intel_lp64 -lmkl_gnu_thread -lmkl_core -lgomp -lpthread -lm -ldl</code>"},{"location":"software-libraries/mkl/#mkl-parallel-scalapack-with-gcc","title":"MKL parallel ScaLAPACK with GCC","text":"<p>Swap modules:</p> <pre><code>module load PrgEnv-gnu\nmodule load mkl\n</code></pre> Language Compile options Link options Fortran <code>-m64  -I\"${MKLROOT}/include\"</code> <code>-L${MKLROOT}/lib/intel64 -lmkl_scalapack_lp64 -Wl,--no-as-needed -lmkl_gf_lp64 -lmkl_gnu_thread -lmkl_core -lmkl_blacs_intelmpi_lp64 -lgomp -lpthread -lm -ldl</code> C/C++ <code>-m64  -I\"${MKLROOT}/include\"</code> <code>-L${MKLROOT}/lib/intel64 -lmkl_scalapack_lp64 -Wl,--no-as-needed -lmkl_intel_lp64 -lmkl_gnu_thread -lmkl_core -lmkl_blacs_intelmpi_lp64 -lgomp -lpthread -lm -ldl</code>"},{"location":"software-libraries/mumps/","title":"MUMPS","text":"<p>MUMPS is a parallel solver for large sparse systems and features a 'multifrontal' method and is developed largely at CERFCAS, ENS Lyon, IRIT Toulouse, INRIA, and the University of Bordeaux. It is provided free of charge and is largely under a CeCILL-C license.</p>"},{"location":"software-libraries/mumps/#compiling-and-linking-with-mumps","title":"Compiling and linking with MUMPS","text":"<ul> <li><code>module load mumps</code></li> </ul> <p>To compile an application against the MUMPS libraries, load the <code>mumps</code> module and use the compiler wrappers <code>cc</code>, <code>CC</code>, and <code>ftn</code> in the usual way.</p> <p>MUMPS is configured to allow Pord, Metis, Parmetis, and Scotch orderings.</p> <p>Two versions of MUMPS are provided: one with, and one without, OpenMP. The relevant version will be selected if the relevant option is included at the compile stage.</p> <p>The <code>mumps</code> module defines <code>MUMPS_DIR</code> which locates the root of the installation for the current programming environment.</p>"},{"location":"software-libraries/mumps/#version-history","title":"Version history","text":"Upgrade 2023Full system4-cabinet system <ul> <li>Module <code>mumps/5.5.1</code> installed as default May 2023 (PE 22.12)</li> <li>Module <code>mumps/5.3.5</code> recompiled May 2023 (PE 22.12)</li> </ul> <p>Note: <code>mumps/5.5.1</code> uses <code>scotch/7.0.3</code> while <code>mumps/5.3.5</code> uses <code>scotch/6.1.0</code>.</p> <ul> <li>Module <code>mumps/5.3.5</code> installed October 2021 (PE 21.04)</li> </ul> <ul> <li>Module <code>mumps/5.2.1</code> installed January 2021</li> </ul> <p>Known issues: The OpenMP version in <code>PrgEnv-aocc</code> is not available at the moment.</p>"},{"location":"software-libraries/mumps/#compiling-your-own-version","title":"Compiling your own version","text":"<p>The current supported version of MUMPS on Archer2 can be compiled using a script available from the Archer githug repository. <pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout modules-2022-12\n$ ./sh/tpsl/metis.sh --prefix=/path/to/install/location\n$ ./sh/tpsl/parmetis.sh --prefix=/path/to/install/location\n$ ./sh/tpsl/scotchv7.sh --prefix=/path/to/install/location\n$ ./sh/tpsl/mumps.sh --prefix=/path/to/install/location\n</code></pre> where the <code>--prefix</code> option should be the same for MUMPS at the three dependencies (Metis, Parmetis, and Scotch Version 7). See the Archer2 github repository for further options and details.</p>"},{"location":"software-libraries/mumps/#resources","title":"Resources","text":"<p>The MUMPS home page</p> <p>MUMPS user manual (Version 5.6, pdf)</p>"},{"location":"software-libraries/netcdf/","title":"NetCDF","text":"<p>The Network Common Data Form NetCDF (and its parallel manifestation NetCDF parallel) is a standard library and data format developed and supported by UCAR is released under a BSD-like license.</p> <p>Both serial and parallel versions are available on ARCHER2 as standard modules:</p> <ul> <li><code>module load cray-netcdf</code> (serial version)</li> <li><code>module load cray-netcdf-hdf5parallel</code> (MPI parallel version)</li> </ul> <p>Note that one should first load the relevant HDF module file, e.g., <pre><code>$ module load cray-hdf5\n$ module load cray-netcdf\n</code></pre> for the serial version.</p> <p>Use <code>module spider</code> to locate available versions, and use <code>module help</code> to locate <code>cray-</code>specific release notes on a particular version.</p> <p>Known issues:</p> Upgrade 2023Full system4-cabinet system <ul> <li>There are no currently known issues.</li> </ul> <ul> <li>There is currently a problem with the module file which means   <code>cray-netcdf-hdf5parallel</code> will not operate correctly in <code>PrgEnv-aocc</code>.   One can load module <code>epcc-netcdf-hdf5parallel</code> instead as a work-around   if <code>PrgEnv-aocc</code> is required.</li> </ul> <ul> <li>There are no currently known issues.</li> </ul> <p>Some general comments and information on serial and parallel I/O to ARCHER2 are given in the section on I/O and file systems.</p>"},{"location":"software-libraries/netcdf/#resources","title":"Resources","text":"<p>The NetCDF home page.</p>"},{"location":"software-libraries/petsc/","title":"PETSc","text":"<p>PETSc is a suite of parallel tools for solution of partial differential equations. PETSc is developed at Argonne National Laboratory and is freely available under a BSD 2-clause license.</p>"},{"location":"software-libraries/petsc/#build","title":"Build","text":"<ul> <li><code>module load petsc</code></li> </ul> <p>Applications may be linked against PETSc by loading the <code>petsc</code> module and using the compiler wrappers <code>cc</code>, <code>CC</code>, and <code>ftn</code> in the usual way. Details of options introduced by the compiler wrappers can be examined via, e.g., <pre><code>$ cc --cray-print-opts\n</code></pre></p> <p>PETSC is configured with Metis, Parmetis, and Scotch orderings, and to support HYPRE, MUMPS, SuperLU, and SuperLU-DIST. PETSc is compiled without OpenMP.</p> <p>The <code>petsc</code> module defines the environment variable <code>PETSC_DIR</code> as the root of the installation if this is required.</p>"},{"location":"software-libraries/petsc/#version-history","title":"Version history","text":"Upgrade 2023Full system4-cabinet system <ul> <li>Module <code>petsc/3.18.5</code> installed as default May 2023 (PE 22.12)</li> <li>Module <code>petsc/3.14.2</code> recompiled May 2023 (PE 22.12)</li> </ul> <p>Note: PETSc has a number of dependencies; where applicable, the newer version of PETSc depends on the newer module version of each relevant dependency. Check <code>module list</code> to be sure.</p> <ul> <li>Module <code>petsc/3.14.2</code> installed October 2021 (PE 21.04)</li> </ul> <ul> <li>Module <code>petsc/3.13.3</code> installed January 2021</li> </ul> <p>Known issues: PETSc is not currently available for <code>PrgEnv-aocc</code>. There is no HYPRE support in this version.</p>"},{"location":"software-libraries/petsc/#compile-your-own-version","title":"Compile your own version","text":"<p>It is possible to follow the steps used to build the current version on Archer2. These steps are codified at the Archer2 github repository and include a number of dependencies to be built in the correct order: <pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout modules-2012-12\n$ ./sh/tpsl/metis.sh --prefix=/path/to/install/location\n$ ./sh/tpsl/parmetis.sh --prefix=/path/to/install/location\n$ ./sh/tpsl/hypre.sh --prefix=/path/to/install/location\n$ ./sh/tpsl/scotchv7.sh --prefix=/path/to/install/location\n$ ./sh/tpsl/mumps.sh --prefix=/path/to/install/location\n$ ./sh/tpsl/superlu.sh --prefix=/path/to/install/location\n$ ./sh/tpsl/superlu-dist.sh --prefix=/path/to/install/location\n\n$ module load cray-hdf5\n$ ./sh/petsc.sh --prefix=/path/to/install/location\n</code></pre> The <code>--prefix</code> option indicating the install directory should be the same in all cases. See the Archer2 github repository for further details (and options). This will compile version 3.18.5 against the latest module versions of each dependency.</p>"},{"location":"software-libraries/petsc/#resources","title":"Resources","text":"<p>PETSc home page</p> <p>Current PETSc documentation (HTML)</p>"},{"location":"software-libraries/scotch/","title":"Scotch and PT-Scotch","text":"<p>Scotch and its parallel version PT-Scotch are provided by Labri at the University of Bordeaux and INRIA Bordeaux South-West. They are used for graph partitioning and ordering problems. The libraries are freely available for scientific use under a license similar to the LGPL license.</p>"},{"location":"software-libraries/scotch/#scotch-and-pt-scotch_1","title":"Scotch and PT-Scotch","text":"<ul> <li><code>module load scotch</code></li> </ul> <p>The <code>scotch</code> module provides access to both the Scotch and PT-Scotch libraries via the compiler system. A number of stand-alone utilities are also provided as part of the package.</p>"},{"location":"software-libraries/scotch/#compiling-and-linking","title":"Compiling and linking","text":"<p>If the <code>scotch</code> module is loaded, then applications may be automatically compiled and linked against the libraries for the current programming environment. Check, e.g., <pre><code>$ cc --cray-print-opts\n</code></pre> if you wish to see exactly what options are generated by the compiler wrappers.</p> <p>Scotch and PT-Scotch libraries are provides as static archives only. The compiler wrappers do not give access to the libraries <code>libscotcherrexit.a</code> or <code>libptscotcherrexit.a</code>. If you wish to perform your own error handling these libraries must be linked manually.</p> <p>The <code>scotch</code> module defines the environment <code>SCOTCH_DIR</code> which holds the root of the installation for a given programming environment. Libraries are present in <code>${SCOTCH_DIR}/lib</code>.</p> <p>Stand-alone applications are also available. See the Scotch and PT-Scotch user manuals for further details.</p>"},{"location":"software-libraries/scotch/#module-version-history","title":"Module version history","text":"Upgrade 2023Full system4-cabinet system <ul> <li>Module <code>scotch/7.0.3</code> installed May 2023 (PE 22.12)</li> <li>Module <code>scotch/6.1.0</code> recompiled May 2023 (PE 22.12)</li> </ul> <p>Note: <code>scotch/7.0.3</code> has disabled a number of features including   the Metis compatibility layer, and threads, to allow all tests   to pass.</p> <ul> <li> <p>Module `scotch/6.1.0 installed October 2021 (PE 21.04)</p> <p>Known issue: a small number of the standard PT-Scotch tests are failing (all programming environments). Symptoms include truncated <code>MPI_Recvs</code>. This is currently being investigated.</p> </li> </ul> <ul> <li> <p>Module <code>scotch/6.0.10</code> installed January 2021</p> <p>Known issue: a small number of the standard PT-Scotch tests are failing (all programming environments). Symptoms include truncated <code>MPI_Recvs</code>. This is currently being investigated.</p> </li> </ul>"},{"location":"software-libraries/scotch/#compiling-your-own-version","title":"Compiling your own version","text":"<p>The build procedure for the Scotch package on Archer2 is available via github.</p>"},{"location":"software-libraries/scotch/#scotch-and-pt-scotch_2","title":"Scotch and PT-Scotch","text":"<p>The latest Scotch and PT-Scotch libraries are installed on Archer using the following mechanism: <pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout modules-2022-12\n$ ./sh/tpsl/scotchv7.sh --prefix=/path/to/install/location\n</code></pre> where the <code>--prefix</code> option defines the destination for the install. This script will download, compile and install version 7.0.3. A separate script (<code>scotch.sh</code>) in the same location is used for version 6.</p>"},{"location":"software-libraries/scotch/#resources","title":"Resources","text":"<p>The Scotch home page</p> <p>Scotch user manual (pdf)</p> <p>PT-Scotch user manual (pdf)</p>"},{"location":"software-libraries/slepc/","title":"SLEPC","text":"<p>The Scalable Library for Eigenvalue Problem computations is an extension of PETSc developed at the Universitat Politecnica de Valencia.  SLEPc is freely available under a 2-clause BSD license.</p>"},{"location":"software-libraries/slepc/#compiling-and-linking-with-slepc","title":"Compiling and linking with SLEPc","text":"<ul> <li><code>module load slepc</code></li> </ul> <p>To compile an application against the SLEPc libraries, load the <code>slepc</code> module and use the compiler wrappers <code>cc</code>, <code>CC</code>, and <code>ftn</code> in the usual way. Static libraries are available so no module is required at run time.</p> <p>The SLEPc module defines <code>SLEPC_DIR</code> which locates the root of the installation.</p>"},{"location":"software-libraries/slepc/#version-history","title":"Version history","text":"Upgrade 2023Full system4-cabinet system <ul> <li>Module <code>slepc/3.18.3</code> installed as default May 2023 (PE 22.12)</li> <li>Module <code>slepc/3.14.1</code> recompiled May 2023 (PE 22.12)</li> </ul> <p>Note: each SLEPc module depends on a PETSc module with the same minor version number.</p> <ul> <li>Module <code>slepc/3.14.1</code> installed October 2021 (PE 21.04)</li> </ul> <ul> <li>Module <code>slepc/3.13.2</code> installed January 2021</li> </ul>"},{"location":"software-libraries/slepc/#compiling-your-own-version","title":"Compiling your own version","text":"<p>The version of SLEPc currently available on ARCHER2 can be compiled using a script available from the ARCHER2 github repository: <pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout modules-2022-12\n$ ./sh/slepc.sh --prefix=/path/to/install/location\n</code></pre> The dependencies (including PETSc) can be built in the same way, or taken from the existing modules. See the ARCHER2 github repository for further information.</p>"},{"location":"software-libraries/slepc/#resources","title":"Resources","text":"<p>SLEPc home page</p> <p>Latest release version of SLEPc user manual (PDF)</p> <p>SLEPc Gitlab repository</p>"},{"location":"software-libraries/superlu/","title":"SuperLU and SuperLU_DIST","text":"<p>SuperLU and SuperLU_DIST are libraries for the direct solution of large sparse non-symmetric systems of linear equations, typically by factorisation and back-substitution. The libraries are provided by Lawrence Berkeley National Laboratory and are freely available under a slightly modified BSD-style license.</p> <p>Two separate modules are provided for SuperLU and SuperLU_DIST.</p>"},{"location":"software-libraries/superlu/#superlu","title":"SuperLU","text":"<ul> <li><code>module load superlu</code></li> </ul> <p>This module provides the serial library SuperLU.</p>"},{"location":"software-libraries/superlu/#compiling-and-linking-with-superlu","title":"Compiling and linking with SuperLU","text":"<p>Compiling and linking SuperLU applications requires no special action beyond <code>module load superlu</code> and using the standard compiler wrappers <code>cc</code>, <code>CC</code>, or <code>ftn</code>. The exact options issued by the compiler wrapper can be examined via, e.g., <pre><code>$ cc --cray-print-opts\n</code></pre> while the module is loaded.</p> <p>The module defines the environment variable <code>SUPERLU_DIR</code> as the root location of the installation for a given programming environment.</p>"},{"location":"software-libraries/superlu/#version-history","title":"Version history","text":"Upgrade 2023Full system4-cabinet system <ul> <li>Module <code>superlu/5.2.2</code> recompiled May 2023 (PE 22.12)</li> </ul> <ul> <li>Module <code>superlu/5.2.2</code> installed October 2021 (PE 21.04)</li> </ul> <ul> <li>Module <code>superle/5.2.1</code> installed January 2021</li> </ul>"},{"location":"software-libraries/superlu/#superlu_dist","title":"SuperLU_DIST","text":"<ul> <li><code>module load superlu-dist</code></li> </ul> <p>This modules provides the distributed memory parallel library SuperLU_DIST both with and without OpenMP.</p>"},{"location":"software-libraries/superlu/#compiling-and-linking-superlu_dist","title":"Compiling and linking SuperLU_DIST","text":"<p>Use the standard compiler wrappers: <pre><code>$ cc my_superlu_dist_application.c\n</code></pre> or <pre><code>$ cc -fopenmp my_superlu_dist_application.c\n</code></pre> to compile the and link against the appropriate libraries.</p> <p>The <code>superlu-dist</code> module defines the environment variable <code>SUPERLU_DIST_DIR</code> as the root of the installation for the current programming environment.</p>"},{"location":"software-libraries/superlu/#version-history_1","title":"Version history","text":"Upgrade 2023Full system4-cabinet system <ul> <li>Module <code>superlu-dist/8.1.2</code> installed as default May 2023 (PE 22.12)</li> <li>Module <code>superlu-dist/6.4.0</code> recompiled May 2023 (PE 22.12)</li> </ul> <ul> <li>Module <code>superlu-dist/6.4.0</code> installed October 2021 (PE 21.04)</li> </ul> <ul> <li>Module <code>superlu-dist/6.1.1</code> installed January 2021</li> </ul>"},{"location":"software-libraries/superlu/#compiling-your-own-version","title":"Compiling your own version","text":"<p>The build used for Archer2 can be replicated by using the scripts provided at the Archer2 repository.</p>"},{"location":"software-libraries/superlu/#superlu_1","title":"SuperLU","text":"<p>The current Archer2 supported version may be built via <pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout modules-2022-12\n$ ./sh/tpsl/superlu.sh --prefix=/path/to/install/location\n</code></pre> where the <code>--prefix</code> option controls the install destination.</p>"},{"location":"software-libraries/superlu/#superlu_dist_1","title":"SuperLU_DIST","text":"<p>SuperLU_DIST is configured using Metis and Parmetis, so these should be installed first: <pre><code>$ ./sh/tpsl/metis.sh --prefix=/path/to/install/location\n$ ./sh/tpsl/parmetis.sh --prefix=/path/to/install/location\n$ ./sh/tpsl/superlu_dist.sh --prefix=/path/to/install/location\n</code></pre> will download, compile, and install the relevant libraries. The install location should be the same for all three packages. See the Archer2 github repository for further options and details.</p>"},{"location":"software-libraries/superlu/#resources","title":"Resources","text":"<p>The Supernodal LU project home page</p> <p>The SuperLU User guide (pdf). This describes both SuperLU and SuperLU_DIST.</p> <p>The SuperLU github repository</p> <p>The SuperLU_DIST github repository</p>"},{"location":"software-libraries/trilinos/","title":"Trilinos","text":"<p>Trilinos is a large collection of packages with software components that can be used for scientific and engineering problems. Most of the package are released under a BSD license (and some under LGPL).</p>"},{"location":"software-libraries/trilinos/#compiling-and-linking-against-trilinos","title":"Compiling and linking against Trilinos","text":"<ul> <li><code>module load trilinos</code></li> </ul> <p>Applications may be built against the module version of Trilinos by using the using the compiler wrappers <code>CC</code> or <code>ftn</code> in the normal way. The appropriate include files and library paths will be inserted automatically. Trilinos is build with OpenPM enabled.</p> <p>The <code>trilinos</code> module defines the environment variable <code>TRILINOS_DIR</code> as the root of the installation for the current programming environment.</p> <p>Trilinos also provides a small number of stand-alone executables which are available via the standard <code>PATH</code> mechanism while the module is loaded.</p>"},{"location":"software-libraries/trilinos/#version-history","title":"Version history","text":"Upgrade 2023Full system4-cabinet system <ul> <li>Module <code>trilinos/12.18.1</code> recompiled May 2023 (PE 22.12)</li> </ul> <p>Note that Trilinos is not currently available for <code>PrgEnv-aocc</code>.</p> <ul> <li>Module <code>trilinos/12.18.1</code> installed October 2021 (PE 21.04)</li> </ul> <p>If using AMD compilers, module version <code>aocc/3.0.0</code> is required.</p> <ul> <li><code>module trilinos/12.18.1</code> installed January 2021</li> </ul> <p>Known issue</p> <p>Trilinos is not available in <code>PrgEnv-aocc</code> at the moment.</p> <p>Known issue</p> <p>The <code>ForTrilinos</code> package is not available in this version.</p> <p>Packages enabled are: <code>Amesos, Amesos2, Anasazi, AztecOO Belos Epetra EpretExt FEI Galeri GlobiPack Ifpack Ifpack2 Intrepid Isorropia Kokkos Komplex Mesquite ML Moertel MueLu NOX OptiPack Pamgen Phalanx Piro Pliris ROL RTOp Rythmos Sacado Shards ShyLU STK STKSearch STKTopology STKUtil Stratimikos Teko Teuchos Thyra Tpetra TrilinosCouplings Triutils Xpetra Zoltan Zoltan2</code></p>"},{"location":"software-libraries/trilinos/#compiling-trilinos","title":"Compiling Trilinos","text":"<p>A script which has details of the relevant configuration options for Trilinos is available at the ARCHER2 Github repository. The script will build a static-only version of the libraries. <pre><code>$ git clone https://github.com/ARCHER2-HPC/pe-scripts.git\n$ cd pe-scripts\n$ git checkout modules-2022-12\n$ ...\n$ ./sh/trilinos.sh --prefix=/path/to/install/location\n</code></pre> where <code>--prefix</code> sets the installation location. The ellipsis <code>...</code> is standing for the dependencies used to build Trilinos, which here are: <code>metis, parmetis, superlu, superlu-dist, scotch, mumps, glm, boost</code>. These packages should be built as described in their corresponding pages linked in the menu on the left.</p> <p>See the ARCHER2 Github repository for further details.</p> <p>Note that Trilinos may take up to one hour to compile on its own, and so the compilation is best performed as a batch job.</p>"},{"location":"software-libraries/trilinos/#resources","title":"Resources","text":"<ul> <li> <p>Trilinos home page</p> </li> <li> <p>Trilinos Github repository</p> </li> </ul>"},{"location":"user-guide/","title":"User and Best Practice Guide","text":"<p>The ARCHER2 User and Best Practice Guide covers all aspects of use of the ARCHER2 service. This includes fundamentals (required by all users to use the system effectively), best practice for getting the most out of ARCHER2 and more technical topics.</p> <p>The User and Best Practice Guide contains the following sections:</p> <ul> <li>Connecting to ARCHER2</li> <li>Data management and transfer</li> <li>Software environment</li> <li>Running jobs on ARCHER2</li> <li>I/O and file systems</li> <li>Application development environment</li> <li>Containers</li> <li>Using Python</li> <li>Data analysis</li> <li>Debugging</li> <li>Profiling</li> <li>Performance tuning</li> <li>ARCHER2 hardware</li> <li>Energy use</li> </ul>"},{"location":"user-guide/analysis/","title":"Data analysis","text":"<p>As well as being used for scientific simulations, ARCHER2 can also be used for data pre-/post-processing and analysis. This page provides an overview of the different options for doing so.</p>"},{"location":"user-guide/analysis/#using-the-login-nodes","title":"Using the login nodes","text":"<p>The easiest way to run non-computationally intensive data analysis is to run directly on the login nodes. However, please remember that the login nodes are a shared resource and should not be used for long-running  tasks.</p>"},{"location":"user-guide/analysis/#example-running-an-r-script-on-a-login-node","title":"Example: Running an R script on a login node","text":"<pre><code>module load cray-R\nRscript example.R\n</code></pre>"},{"location":"user-guide/analysis/#using-the-compute-nodes","title":"Using the compute nodes","text":"<p>If running on the login nodes is not feasible (e.g. due to memory requirements or computationally intensive analysis), the compute nodes can also be used for data analysis.</p> <p>Important</p> <p>This is a more expensive option, as you will be charged for using the entire node, even though your analysis may only be using one core.</p>"},{"location":"user-guide/analysis/#example-running-an-r-script-on-a-compute-node","title":"Example: Running an R script on a compute node","text":"<pre><code>#!/bin/bash\n#SBATCH --job-name=data_analysis\n#SBATCH --time=0:10:0\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=1\n\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\nmodule load cray-R\n\nRscript example.R\n</code></pre> <p>An advantage of this method is that you can use Job chaining to automate the process of analysing your output data once your compute job has finished.</p>"},{"location":"user-guide/analysis/#using-interactive-jobs","title":"Using interactive jobs","text":"<p>For more interactive analysis, it may be useful to use <code>salloc</code> to reserve a compute node on which to do your analysis. This allows you to run jobs directly on the compute nodes from the command line without using a job submission script. More information on interactive jobs can be found here.</p>"},{"location":"user-guide/analysis/#example-reserving-a-single-node-for-20-minutes-for-interactive-analysis","title":"Example: Reserving a single node for 20 minutes for interactive analysis","text":"<pre><code>auser@ln01:&gt; salloc --nodes=1 --ntasks-per-node=1 --cpus-per-task=1 \\\n--time=00:20:00 --partition=standard --qos=short \\\n--account=[budget code]\n</code></pre> <p>Note</p> <p>If you want to run for longer than 20 minutes, you will need to use a different QoS as the maximum runtime for the <code>short</code> QoS is  20 mins.</p>"},{"location":"user-guide/analysis/#data-analysis-nodes","title":"Data analysis nodes","text":"<p>The data analysis nodes on the ARCHER2 system are designed for large compilations, post-calculation analysis and data manipulation. They should  be used for jobs which are too small to require a whole compute node, but  which would have an adverse impact on the operation of the login nodes if  they were run interactively.</p> <p>Unlike compute nodes, the data analysis nodes are able to access the home,  work, and the RDFaaS file systems. They can also  be used to transfer data from a remote system to ARCHER2 and vice versa  (using e.g. <code>scp</code> or <code>rsync</code>). This can be useful when transferring large  amounts of data that might take hours to complete.</p>"},{"location":"user-guide/analysis/#requesting-resources-on-the-data-analysis-nodes-using-slurm","title":"Requesting resources on the data analysis nodes using Slurm","text":"<p>The ARCHER2 data analysis nodes can be reached by using the <code>serial</code>  partition and the <code>serial</code> QoS. Unlike other nodes on ARCHER2, you may  only request part of a single node and you will likely be sharing the node  with other users.</p> <p>The data analysis nodes are set up such that you can specify the number of  cores you want to use (up to 32 physical cores) and the amount of memory you  want for your job (up to 125 GB). You can have multiple jobs running on the  data analysis nodes at the same time, but the total number of cores used by  those jobs cannot exceed 32, and the total memory used by jobs currently running from a single user cannot exceed 125 GB -- any jobs above this limit will remain pending until your previous jobs are finished.</p> <p>You do not need to specify both number of cores and memory for jobs on the data analysis nodes. By default, you will get 1984 MiB of memory per core (which is a little less than 2 GB), when specifying cores only, and 1 core when specifying the memory only.</p> <p>Note</p> <p>Each data analysis node is fitted with 512 GB of memory. However, a small amount of this memory is needed for system processes, which is why we set an upper limit of 125 GB per user (a user is limited to one quarter of the RAM on a node). This is also why the per-core default memory allocation is slightly less than 2 GB.</p> <p>Note</p> <p>When running on the data analysis nodes, you must always specify either  the number of cores you want, the amount of memory you want, or both.  The examples shown below specify the number of cores with the <code>--ntasks</code> flag and the memory with the <code>--mem</code> flag. If you are only wanting to  specify one of the two, please remember to delete the other one.</p>"},{"location":"user-guide/analysis/#example-running-a-serial-batch-script-on-the-data-analysis-nodes","title":"Example: Running a serial batch script on the data analysis nodes","text":"<p>A Slurm batch script for the data analysis nodes looks very similar to  one for the compute nodes. The main differences are that you need to use  <code>--partition=serial</code> and <code>--qos=serial</code>, specify the number of tasks (rather than the number of nodes) and/or specify the amount of memory you want. For example, to use a single core and 4 GB of memory, you  would use something like:</p> <pre><code>#!/bin/bash\n\n# Slurm job options (job-name, job time)\n#SBATCH --job-name=data_analysis\n#SBATCH --time=0:20:0\n#SBATCH --ntasks=1\n\n# Replace [budget code] below with your budget code (e.g. t01)\n#SBATCH --account=[budget code]             \n#SBATCH --partition=serial\n#SBATCH --qos=serial\n\n# Define memory required for this jobs. By default, you would \n# get just under 2 GB, but you can ask for up to 125 GB.\n#SBATCH --mem=4G\n\n# Set the number of threads to 1\n#   This prevents any threaded system libraries from automatically \n#   using threading.\nexport OMP_NUM_THREADS=1\n\nmodule load cray-python\n\npython my_analysis_script.py\n</code></pre>"},{"location":"user-guide/analysis/#interactive-session-on-the-data-analysis-nodes","title":"Interactive session on the data analysis nodes","text":"<p>There are two ways to start an interactive session on the data analysis nodes:  you can either use <code>salloc</code> to reserve a part of a data analysis node for interactive  jobs; or, you can use <code>srun</code> to open a terminal on the node and run things on the  node directly. You can find out more information on the advantages and disadvantages  of both of these methods in the Running jobs on ARCHER2  section of the User and Best Practice Guide.</p>"},{"location":"user-guide/analysis/#using-salloc-for-interactive-access","title":"Using <code>salloc</code> for interactive access","text":"<p>You can reserve resources on a data analysis node using <code>salloc</code>. For example, to request 1 core and 4 GB of memory for 20 minutes, you  would use:</p> <pre><code>auser@ln01:~&gt; salloc --time=00:20:00 --partition=serial --qos=serial \\\n--account=[budget code] --ntasks=1 \\\n--mem=4G\n</code></pre> <p>When you submit this job, your terminal will display something like:</p> <pre><code>salloc: Pending job allocation 523113\nsalloc: job 523113 queued and waiting for resources\nsalloc: job 523113 has been allocated resources\nsalloc: Granted job allocation 523113\nsalloc: Waiting for resource configuration\nsalloc: Nodes dvn01 are ready for job\n\nauser@ln01:~&gt;\n</code></pre> <p>It may take some time for your interactive job to start. Once it runs you will enter a standard interactive terminal session (a new shell). Note that this shell is still on the front end (the prompt has not changed). Whilst the interactive session lasts you will be able to run jobs on the data analysis nodes by issuing the <code>srun</code> command directly at  your command prompt. The maximum number of cores and memory you can use is limited by resources requested in the <code>salloc</code> command (or by the  defaults if you did not explicitly ask for particular amounts of resource).</p> <p>Your session will end when you hit the requested walltime. If you wish to finish before this you should use the <code>exit</code> command - this will return you to your prompt before you issued the <code>salloc</code> command.</p>"},{"location":"user-guide/analysis/#using-srun-for-interactive-access","title":"Using <code>srun</code> for interactive access","text":"<p>You can get a command prompt directly on the data analysis nodes by using the <code>srun</code> command directly. For example, to reserve 1 core and 8 GB of memory, you would use:</p> <pre><code>auser@ln01:~&gt; srun   --time=00:20:00 --partition=serial --qos=serial \\\n--account=[budget code]    \\\n--ntasks=1 --mem=8G \\\n--pty /bin/bash\n</code></pre> <p>The <code>--pty /bin/bash</code> will cause a new shell to be started on the data  analysis node. (This is perhaps closer to what many people consider an 'interactive' job than the method using the <code>salloc</code> method described above.)</p> <p>One can now issue shell commands in the usual way.</p> <p>When finished, type <code>exit</code> to relinquish the allocation and control will be returned to the front end.</p> <p>By default, the interactive shell will retain the environment of the parent. If you want a clean shell, remember to specify the <code>--export=none</code> option to the <code>srun</code> command.</p>"},{"location":"user-guide/analysis/#visualising-data-using-the-data-analysis-nodes-using-x","title":"Visualising data using the data analysis nodes using X","text":"<p>You can view data on the data analysis nodes by starting an interactive  <code>srun</code> session with the <code>--x11</code> flag to export the X display back to your local system. For 1 core with * GB of memory:</p> <pre><code>auser@ln01:~&gt; srun   --time=00:20:00 --partition=serial --qos=serial  \\\n--hint=nomultithread --account=[budget code]    \\\n--ntasks=1 --mem=8G --x11 --pty /bin/bash\n</code></pre> <p>Tip</p> <p>Data visualisation on ARCHER2 is only possible if you used the <code>-X</code>  or <code>-Y</code> flag to the <code>ssh</code> command when when logging in to the system.</p>"},{"location":"user-guide/analysis/#using-singularity","title":"Using Singularity","text":"<p>Singularity can be useful for data analysis, as sites such as DockerHub or SingularityHub contain many pre-built images of data analysis tools that can be simply downloaded and used on ARCHER2. More information about Singularity on ARCHER2 can be found in the Containers section section of the User and Best Practice Guide.</p>"},{"location":"user-guide/analysis/#data-analysis-tools","title":"Data analysis tools","text":"<p>Useful tools for data analysis can be found on the Data Analysis and Tools page.</p>"},{"location":"user-guide/connecting/","title":"Connecting to ARCHER2","text":"<p>This section covers the basic connection methods.</p> <p>On the ARCHER2 system, interactive access is achieved using SSH, either directly from a command-line terminal or using an SSH client. In addition, data can be transferred to and from the ARCHER2 system using <code>scp</code> from the command line or by using a file-transfer client.</p> <p>Before following the process below, we assume you have set up an account on ARCHER2 through the EPCC SAFE. Documentation on how to do this can be found at:</p> <ul> <li>SAFE Guide for Users</li> </ul>"},{"location":"user-guide/connecting/#command-line-terminal","title":"Command line terminal","text":""},{"location":"user-guide/connecting/#linux","title":"Linux","text":"<p>Linux distributions include a terminal application that can be used for SSH access to the ARCHER2 login nodes. Linux users will have different terminals depending on their distribution and window manager (e.g., GNOME Terminal in GNOME, Konsole in KDE). Consult your Linux distribution's documentation for details on how to load a terminal.</p>"},{"location":"user-guide/connecting/#macos","title":"MacOS","text":"<p>MacOS users can use the Terminal application, located in the Utilities folder within the Applications folder.</p>"},{"location":"user-guide/connecting/#windows","title":"Windows","text":"<p>A typical Windows installation will not include a terminal client, though there are various clients available. We recommend Windows users download and install MobaXterm to access ARCHER2. It is very easy to use and includes an integrated X Server, which allows you to run graphical applications on ARCHER2.</p> <p>You can download MobaXterm Home Edition (Installer Edition) from the following link:</p> <ul> <li>Install MobaXterm</li> </ul> <p>Double-click the downloaded Microsoft Installer file (.msi) and follow the instructions from the Windows Installation Wizard. Note, you might need to have administrator rights to install on some versions of Windows. Also, make sure to check whether Windows Firewall has blocked any features of this program after installation (Windows will warn you if the built-in firewall blocks an action, and gives you the opportunity to override the behaviour).</p> <p>Once installed, start MobaXterm and then click \"Start local terminal\".</p> <p>Tips</p> <ul> <li> <p>If you download the .zip file rather than the .msi, make sure you unzip it before attempting to run the installer.</p> </li> <li> <p>If you do not have administrator rights, you can use the Portable edition of MobaXterm.</p> </li> <li> <p>If this is your first time using MobaXterm, you should check that a permanent /home directory has been set up (otherwise, all saved info will be lost from session to session). Go to \"Settings\" -&gt; \"Configuration\" and check that a path is set in the field marked \"Persistent home directory\". If prompted, make sure path is set as \"private\".</p> </li> <li> <p>Any SSH key generated in MobaXterm will, by default, be stored in the permanent /home directory (see above). That is, if your /home directory is <code>_MyDocuments_\\MobaXterm\\home</code> then within that folder you will find a folder named <code>_MyDocuments_\\MobaXterm\\home\\.ssh</code> containing your keys.  This folder will be 'hidden' by default, so you may need to tick 'Hidden items' under 'View' in Windows Explorer to see it.</p> </li> <li> <p>MobaXterm also allows you to set up pre-configured SSH sessions with the username, login host and key details saved.  You are welcome to use this, rather than using the \"Local terminal\", but we are not able to assist with debugging connection issues if you choose this method.</p> </li> </ul>"},{"location":"user-guide/connecting/#access-credentials","title":"Access credentials","text":"<p>To access ARCHER2, you need to use two sets of credentials: a password and an SSH key pair protected by a passphrase. You can find more detailed instructions on how to set up your credentials to access ARCHER2 from Windows, MacOS and Linux below.</p>"},{"location":"user-guide/connecting/#ssh-key-pairs","title":"SSH Key Pairs","text":"<p>You will need to generate an SSH key pair protected by a passphrase to access ARCHER2.</p> <p>Using a terminal (the command line), set up a key pair that contains your e-mail address and enter a passphrase you will use to unlock the key:</p> <pre><code>$ ssh-keygen -t rsa -C \"your@email.com\"\n...\n-bash-4.1$ ssh-keygen -t rsa -C \"your@email.com\"\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/Home/user/.ssh/id_rsa): [Enter]\nEnter passphrase (empty for no passphrase): [Passphrase]\nEnter same passphrase again: [Passphrase]\nYour identification has been saved in /Home/user/.ssh/id_rsa.\nYour public key has been saved in /Home/user/.ssh/id_rsa.pub.\nThe key fingerprint is:\n03:d4:c4:6d:58:0a:e2:4a:f8:73:9a:e8:e3:07:16:c8 your@email.com\nThe key's randomart image is:\n+--[ RSA 2048]----+\n|    . ...+o++++. |\n| . . . =o..      |\n|+ . . .......o o |\n|oE .   .         |\n|o =     .   S    |\n|.    +.+     .   |\n|.  oo            |\n|.  .             |\n| ..              |\n+-----------------+\n</code></pre> <p>(remember to replace \"your@email.com\" with your e-mail address).</p>"},{"location":"user-guide/connecting/#upload-public-part-of-key-pair-to-safe","title":"Upload public part of key pair to SAFE","text":"<p>You should now upload the public part of your SSH key pair to the SAFE by following the instructions at:</p> <p>Login to SAFE.</p> <p>Then:</p> <ol> <li>Go to the Menu Login accounts and select the ARCHER2 account you      want to add the SSH key to.</li> <li>On the subsequent Login Account details page, click the Add      Credential button.</li> <li>Select SSH public key as the Credential Type and click Next</li> <li>Either copy and paste the public part of your SSH key into the      SSH Public key box or use the button to select the public key      file on your computer.</li> <li>Click Add to associate the public SSH key with your account.</li> </ol> <p>Once you have done this, your SSH key will be added to your ARCHER2 account.</p> <p>Remember, you need both an SSH key and a password to log in to ARCHER2. You will need to collect an initial password before you can log into ARCHER2. We cover this next.</p> <p>Note</p> <p>If you want to connect to ARCHER2 from more than one machine---for example, from your home laptop as well as your work laptop---you should generate an SSH key on each machine, and add each of the public keys into SAFE.</p>"},{"location":"user-guide/connecting/#initial-passwords","title":"Initial passwords","text":"<p>The SAFE web interface is used to provide your initial password for logging onto ARCHER2 (see the SAFE Documentation for more details on requesting accounts and picking up passwords).</p> <p>Note</p> <p>ARCHER2 account passwords are also sometimes referred to as LDAP passwords by the system.</p> <p>Note</p> <p>You will be prompted to change your password the first time that you log in to ARCHER2. You may also change your password, at any time, on ARCHER2, using the <code>passwd</code> command. This change is not be reflected in SAFE so, if you forget your password, you should use SAFE to request a new one-shot password.</p>"},{"location":"user-guide/connecting/#ssh-clients","title":"SSH Clients","text":"<p>As noted above, you interact with ARCHER2, over an encrypted communication channel (specifically, Secure Shell version 2 (SSH-2)). This allows command-line access to one of the login nodes of ARCHER2, from which you can run commands or use a command-line text editor to edit files.  SSH can also be used to run graphical programs such as GUI text editors and debuggers, when used in conjunction with an X Server.</p>"},{"location":"user-guide/connecting/#logging-in","title":"Logging in","text":"<p>The login addresses for ARCHER2 are:</p> <ul> <li>ARCHER2 full system: login.archer2.ac.uk</li> </ul> <p>You can use the following command from the terminal window to log in to ARCHER2:</p> Full system <pre><code>ssh username@login.archer2.ac.uk\n</code></pre> <p>The order in which you are asked for credentials depends on the system you are accessing:</p> Full system <p>You will first be prompted for the passphrase associated with your SSH key pair. Once you have entered this passphrase successfully, you will then be prompted for your machine account password. You need to enter both credentials correctly to be able to access ARCHER2.</p> <p>Tip</p> <p>If you logged into ARCHER2 with your account before the major upgrade in May/June 2023 you may see an error  from SSH that looks like</p> <pre><code>@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@       WARNING: POSSIBLE DNS SPOOFING DETECTED!          @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nThe ECDSA host key for login.archer2.ac.uk has changed,\nand the key for the corresponding IP address 193.62.216.43\nhas a different value. This could either mean that\nDNS SPOOFING is happening or the IP address for the host\nand its host key have changed at the same time.\nOffending key for IP in /Users/auser/.ssh/known_hosts:11\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\nIt is also possible that a host key has just been changed.\nThe fingerprint for the ECDSA key sent by the remote host is\nSHA256:UGS+LA8I46LqnD58WiWNlaUFY3uD1WFr+V8RCG09fUg.\nPlease contact your system administrator.\n</code></pre> <p>If you see this, you should delete the offending host key from your <code>~/.ssh/known_hosts</code> file (in the example above the offending line is line #11)</p> <p>Warning</p> <p>If your SSH key pair is not stored in the default location (usually <code>~/.ssh/id_rsa</code>) on your local system, you may need to specify the path to the private part of the key wih the <code>-i</code> option to <code>ssh</code>. For example, if your key is in a file called <code>keys/id_rsa_ARCHER2</code> you would use the command <code>ssh -i keys/id_rsa_ARCHER2 username@login.archer2.ac.uk</code> to log in (or the equivalent for the 4-cabinet system).</p> <p>Tip</p> <p>When you first log into ARCHER2, you will be prompted to change your initial password. This is a three-step process:</p> <ol> <li>When promoted to enter your ldap password: Re-enter the password     you retrieved from SAFE.</li> <li>When prompted to enter your new password: type in a new password.</li> <li>When prompted to re-enter the new password: re-enter the new     password.</li> </ol> <p>Your password will now have been changed</p> <p>To allow remote programs, especially graphical applications, to control your local display, such as for a debugger, use:</p> Full system <pre><code>ssh -X username@login.archer2.ac.uk\n</code></pre> <p>Some sites recommend using the <code>-Y</code> flag. While this can fix some compatibility issues, the <code>-X</code> flag is more secure.</p> <p>Current MacOS systems do not have an X window system. Users should install the XQuartz package to allow for SSH with X11 forwarding on MacOS systems:</p> <ul> <li>XQuartz website</li> </ul>"},{"location":"user-guide/connecting/#host-keys","title":"Host Keys","text":"<p>Adding the host keys to your SSH configuration file provides an extra level of security for your connections to ARCHER2. The host keys are checked against the login nodes when you login to ARCHER2 and if the remote server key does not match the one in the configuration file, the connection will be refused. This provides protection against potential malicious servers masquerading as the ARCHER2 login nodes.</p>"},{"location":"user-guide/connecting/#loginarcher2acuk","title":"login.archer2.ac.uk","text":"<pre><code>login.archer2.ac.uk ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBANu9BQJ1UFr4nwy8X5seIPgCnBl1TKc8XBq2YVY65qS53QcpzjZAH53/CtvyWkyGcmY8/PWsJo9sXHqzXVSkzk=\n\nlogin.archer2.ac.ukssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDFGGByIrskPayB5xRm3vkWoEc5bVtTCi0oTGslD8m+M1Sc/v2IV6FxaEVXGwO9ErQwrtFQRj0KameLS3Jn0LwQ13Tw+vTXV0bsKyGgEu2wW+BSDijGpbxRZXZrg30TltZXd4VkTuWiE6kyhJ6qiIIR0nwfDblijGy3u079gM5Om/Q2wydwh0iAASRzkqldL5bKDb14Vliy7tCT3TJXI49+qIagWUhNEzyN1j2oK/2n3JdflT4/anQ4jUywVG4D1Tor/evEeSa3h5++gbtgAXZaCtlQbBxwckmTetXqnlI+pvkF0AAuS18Bh+hdmvT1+xW0XLv7CMA64HfR93XgQIIuPqFAS1p+HuJkmk4xFAdwrzjnpYAiU5Apkq+vx3W957/LULzZkeiFQY2Y3CY9oPVR8WBmGKXOOBifhl2Hvd51fH1wd0Lw7Zph53NcVSQQhdDUVhgsPJA3M/+UlqoAMEB/V6ESE2z6yrXVfNjDNbbgA1K548EYpyNR8z4eRtZOoi0=\n\nlogin.archer2.ac.uk ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAINyptPmidGmIBYHPcTwzgXknVPrMyHptwBgSbMcoZgh5\n</code></pre> <p>Host key verification can fail if this key is out of date, a problem which can be fixed by removing the offending entry in <code>~/.ssh/known_hosts</code> and replacing it with the new key published here.  We recommend users should check this page for any key updates and not just accept a new key from the server without confirmation.</p>"},{"location":"user-guide/connecting/#making-access-more-convenient-using-the-ssh-configuration-file","title":"Making access more convenient using the SSH configuration file","text":"<p>Typing in the full command to log in or transfer data to ARCHER2 can become tedious as it often has to be repeated several times. You can use the SSH configuration file, usually located on your local machine at <code>.ssh/config</code> to make the process more convenient.</p> <p>Each remote site (or group of sites) can have an entry in this file, which may look something like:</p> Full system <pre><code>Host archer2\n    HostName login.archer2.ac.uk\n    User username\n</code></pre> <p>(remember to replace <code>username</code> with your actual username!).</p> <p>Taking the full-system example: the <code>Host</code> line defines a short name for the entry. In this case, instead of typing <code>ssh username@login.archer2.ac.uk</code> to access the ARCHER2 login nodes, you could use <code>ssh archer2</code> instead. The remaining lines define the options for the host.</p> <ul> <li><code>Hostname login.archer2.ac.uk</code> --- defines the full address of the      host</li> <li><code>User username</code> --- defines the username to use by default for this      host (replace <code>username</code> with your own username on the remote      host)</li> </ul> <p>Now you can use SSH to access ARCHER2 without needing to enter your username or the full hostname every time:</p> <pre><code>ssh archer2\n</code></pre> <p>You can set up as many of these entries as you need in your local configuration file. Other options are available. See the ssh_config manual page (or <code>man ssh_config</code> on any machine with SSH installed) for a description of the SSH configuration file. For example, you may find the <code>IdentityFile</code> option useful if you have to manage multiple SSH key pairs for different systems as this allows you to specify which SSH key to use for each system.</p> <p>Bug</p> <p>There is a known bug with Windows ssh-agent. If you get the error message: <code>Warning: agent returned different signature type ssh-rsa (expected rsa-sha2-512)</code>, you will need to either specify the path to your ssh key in the command line (using the <code>-i</code> option as described above) or add that path to your SSH config file by using the <code>IdentityFile</code> option.</p>"},{"location":"user-guide/connecting/#ssh-debugging-tips","title":"SSH debugging tips","text":"<p>If you find you are unable to connect to ARCHER2, there are some simple checks you may use to diagnose the issue, which are described below. If you are having difficulties connecting, we suggest trying these before contacting the ARCHER2 Service Desk.</p>"},{"location":"user-guide/connecting/#use-the-userloginarcher2acuk-syntax-rather-than-l-user-loginarcher2acuk","title":"Use the <code>user@login.archer2.ac.uk</code> syntax rather than <code>-l user login.archer2.ac.uk</code>","text":"<p>We have seen a number of instances where people using the syntax</p> <pre><code>ssh -l user login.archer2.ac.uk\n</code></pre> <p>have not been able to connect properly and get prompted for a password many times. We have found that using the alternative syntax:</p> <pre><code>ssh user@login.archer2.ac.uk\n</code></pre> <p>works more reliably.</p>"},{"location":"user-guide/connecting/#can-you-connect-to-the-login-node","title":"Can you connect to the login node?","text":"<p>Try the command <code>ping -c 3 login.archer2.ac.uk</code>, on Linux or MacOS, or <code>ping -n 3 login.archer2.ac.uk</code> on Windows. If you successfully connect to the login node, the output should include:</p> <pre><code>--- login.archer2.ac.uk ping statistics ---\n3 packets transmitted, 3 received, 0% packet loss, time 38ms\n</code></pre> <p>(the ping time '38ms' is not important). If not all packets are received there could be a problem with your Internet connection, or the login node could be unavailable.</p>"},{"location":"user-guide/connecting/#password","title":"Password","text":"<p>If you are having trouble entering your password, consider using a password manager, from which you can copy and paste it. If you need to reset your password, instructions for doing so can be found in the SAFE documentation</p> <p>Windows users should note that the <code>Ctrl+V</code> shortcut does not work to paste in to PuTTY, MobaXterm, or PowerShell. Instead use <code>Shift+Ins</code> to paste. Alternatively, right-click and select 'Paste' in PuTTY and MobaXterm, or simply right-click to paste in PowerShell.</p>"},{"location":"user-guide/connecting/#ssh-key","title":"SSH key","text":"<p>If you get the error message <code>Permission denied (publickey)</code>, this may indicate a problem with your SSH key. Some things to check:</p> <ul> <li> <p>Have you uploaded the key to SAFE? Please note that if the same      key is re-uploaded, SAFE will not map the \"new\" key to ARCHER2. If      for some reason this is required, please delete the key first,      then re-upload.</p> </li> <li> <p>Is SSH using the correct key? You can check which keys are      being found and offered by SSH using <code>ssh -vvv</code>. If your private      key has a non-default name, you should use the <code>-i</code> option to      provide it to ssh. For example, <code>ssh -i path/to/key      username@login.archer2.ac.uk</code>.</p> </li> <li> <p>Are you entering the passphrase correctly? You will be asked for      your private key's passphrase first. If you enter it incorrectly      you will usually be asked to enter it again (usually you will get      three chances, after which SSH will fail with <code>Permission denied      (publickey)</code>). If you would like to confirm your passphrase      without attempting to connect, you can use <code>ssh-keygen -y -f      /path/to/private/key</code>. If successful, this command will print the      corresponding public key. You can also use this to check that you      have uploaded the correct public key to SAFE.</p> </li> <li> <p>Are permissions correct on the SSH key? One common issue is that      the permissions are set incorrectly on either the key files or      the directory it is contained in. On Linux and MacOS, if      your private keys are held in <code>~/.ssh/</code> you can check this with      <code>ls -al ~/.ssh</code>. This should give something similar to the      following output:</p> <pre><code> $ ls -al ~/.ssh/\n drwx------.  2 user group    48 Jul 15 20:24 .\n drwx------. 12 user group  4096 Oct 13 12:11 ..\n -rw-------.  1 user group   113 Jul 15 20:23 authorized_keys\n -rw-------.  1 user group 12686 Jul 15 20:23 id_rsa\n -rw-r--r--.  1 user group  2785 Jul 15 20:23 id_rsa.pub\n -rw-r--r--.  1 user group  1967 Oct 13 14:11 known_hosts\n</code></pre> <p>The important section here is the string of letters and dashes at  the start, for the lines ending in <code>.</code>, <code>id_rsa</code>, and  <code>id_rsa.pub</code>, which indicate permissions on the containing  directory, private key, and public key, respectively. If your  permissions are not correct, they can be set with <code>chmod</code>. Consult  the table below for the relevant <code>chmod</code> command. </p> Target Permissions <code>chmod</code> Code Directory <code>drwx------</code> 700 Private Key <code>-rw-------</code> 600 Public Key <code>-rw-r--r--</code> 644 </li> </ul> <p><code>chmod</code> can be used to set permissions on the target in the following way: <code>chmod &lt;code&gt; &lt;target&gt;</code>. So for example to set correct permissions on the private key file <code>id_rsa_ARCHER2</code>, use the command <code>chmod 600 id_rsa_ARCHER2</code>.</p> <p>On Windows, permissions are handled differently but can be set by right-clicking on the file and selecting Properties &gt; Security &gt; Advanced. The user, SYSTEM, and Administrators should have <code>Full control</code>, and no other permissions should exist for both the public and private key files, as well as the containing folder.</p> <p>Tip</p> <p>Unix file permissions can be understood in the following way. There are three groups that can have file permissions: (owning) users, (owning) groups, and others. The available permissions are read, write, and execute. The first character indicates whether the target is a file <code>-</code>, or directory <code>d</code>. The next three characters indicate the owning user's permissions. The first character is <code>r</code> if they have read permission, <code>-</code> if they don't, the second character is <code>w</code> if they have write permission, <code>-</code> if they don't, the third character is <code>x</code> if they have execute permission, <code>-</code> if they don't. This pattern is then repeated for group, and other permissions. For example the pattern <code>-rw-r--r--</code> indicates that the owning user can read and write the file, members of the owning group can read it, and anyone else can also read it. The <code>chmod</code> codes are constructed by treating the user, group, and owner permission strings as binary numbers, then converting them to decimal. For example the permission string <code>-rwx------</code> becomes <code>111 000 000</code> -&gt; <code>700</code>.</p>"},{"location":"user-guide/connecting/#ssh-verbose-output","title":"SSH verbose output","text":"<p>The verbose-debugging output from <code>ssh</code> can be very useful for diagnosing issues. In particular, it can be used to distinguish between problems with the SSH key and password. To enable verbose output, add the <code>-vvv</code> flag to your SSH command. For example:</p> <pre><code>ssh -vvv username@login.archer2.ac.uk\n</code></pre> <p>The output is lengthy, but somewhere in there you should see lines similar to the following:</p> <pre><code>debug1: Next authentication method: publickey\ndebug1: Offering public key: RSA SHA256:&lt;key_hash&gt; &lt;path_to_private_key&gt;\ndebug3: send_pubkey_test\ndebug3: send packet: type 50\ndebug2: we sent a publickey packet, wait for reply\ndebug3: receive packet: type 60\ndebug1: Server accepts key: pkalg rsa-sha2-512 blen 2071\ndebug2: input_userauth_pk_ok: fp SHA256:&lt;key_hash&gt;\ndebug3: sign_and_send_pubkey: RSA SHA256:&lt;key_hash&gt;\nEnter passphrase for key '&lt;path_to_private_key&gt;':\ndebug3: send packet: type 50\ndebug3: receive packet: type 51\nAuthenticated with partial success.\ndebug1: Authentications that can continue: password, keyboard-interactive\n</code></pre> <p>In the text above, you can see which files ssh has checked for private keys, and you can see if any key is accepted. The line <code>Authenticated succeeded</code> indicates that the SSH key has been accepted. By default SSH will go through a list of standard private-key files, as well as any you have specified with <code>-i</code> or a config file. To succeed, one of these private keys needs to match to the public key uploaded to SAFE.</p> <p>If your SSH key passphrase is incorrect, you will be asked to try again up to three times in total, before being disconnected with <code>Permission denied (publickey)</code>. If you enter your passphrase correctly, but still see this error message, please consider the advice under SSH key above.</p> <p>You should next see something similiar to:</p> <pre><code>debug1: Next authentication method: keyboard-interactive\ndebug2: userauth_kbdint\ndebug3: send packet: type 50\ndebug2: we sent a keyboard-interactive packet, wait for reply\ndebug3: receive packet: type 60\ndebug2: input_userauth_info_req\ndebug2: input_userauth_info_req: num_prompts 1\nPassword:\ndebug3: send packet: type 61\ndebug3: receive packet: type 60\ndebug2: input_userauth_info_req\ndebug2: input_userauth_info_req: num_prompts 0\ndebug3: send packet: type 61\ndebug3: receive packet: type 52\ndebug1: Authentication succeeded (keyboard-interactive).\n</code></pre> <p>If you do not see the <code>Password:</code> prompt you may have connection issues, or there could be a problem with the ARCHER2 login nodes. If you do not see <code>Authenticated with partial success</code> it means your password was not accepted. You will be asked to re-enter your password, usually two more times before the connection will be rejected. Consider the suggestions under Password above. If you do see <code>Authenticated with partial success</code>, it means your password was accepted, and your SSH key will now be checked.</p> <p>The equivalent information can be obtained in PuTTY by enabling All Logging in settings.</p>"},{"location":"user-guide/connecting/#related-software","title":"Related Software","text":""},{"location":"user-guide/connecting/#tmux","title":"tmux","text":"<p>tmux is a multiplexer application  available on the ARCHER2 login nodes. It allows for multiple sessions to  be open concurrently and these sessions can be detached and run in the  background. Furthermore, sessions will continue to run after a user logs  off and can be reattached to upon logging in again. It is particularly  useful if you are connecting to ARCHER2 on an unstable Internet connection  or if you wish to keep an arrangement of terminal applications running  while you disconnect your client from the Internet -- for example, when  moving between your home and workplace. </p>"},{"location":"user-guide/containers/","title":"Containers","text":"<p>This page was originally based on the documentation at the University of Sheffield HPC service</p> <p>Designed around the notion of mobility of compute and reproducible science, Singularity enables users to have full control of their operating system environment. This means that a non-privileged user can \"swap out\" the Linux operating system and environment on the host for a Linux OS and environment that they control. So if the host system is running CentOS Linux but your application runs in Ubuntu Linux with a particular software stack, you can create an Ubuntu image, install your software into that image, copy the image to another host (e.g. ARCHER2), and run your application on that host in its native Ubuntu environment.</p> <p>Singularity also allows you to leverage the resources of whatever host you are on. This includes high-speed interconnects (e.g. Slingshot on ARCHER2), file systems (e.g. /home and /work on ARCHER2) and potentially other resources.</p> <p>Note</p> <p>Singularity only supports Linux containers. You cannot create images that use Windows or macOS (this is a restriction of the containerisation model rather than Singularity).</p>"},{"location":"user-guide/containers/#useful-links","title":"Useful Links","text":"<ul> <li>Singularity website</li> <li>Singularity documentation</li> </ul>"},{"location":"user-guide/containers/#about-singularity-containers-images","title":"About Singularity Containers (Images)","text":"<p>Similar to Docker, a Singularity container is a self-contained software stack. As Singularity does not require a root-level daemon to run its containers (as is required by Docker) it is suitable for use on multi-user HPC systems such as ARCHER2. Within the container, you have exactly the same permissions as you do in a standard login session on the system.</p> <p>In practice, this means that a container image created on your local machine with all your research software installed for local development will also run on ARCHER2.</p> <p>Pre-built container images (such as those on DockerHub or SingularityHub archive can simply be downloaded and used on ARCHER2 (or anywhere else Singularity is installed).</p> <p>Creating and modifying container images requires root permission and so must be done on a system where you have such access (in practice, this is usually within a virtual machine on your laptop/workstation).</p> <p>Note</p> <p>SingularityHub was a publicly available cloud service for Singularity container images active from 2016 to 2021. It built container recipes from Github repositories on Google Cloud, and container images were available via the command line Singularity or sregistry software. These container images are still available now in the SingularityHub Archive</p>"},{"location":"user-guide/containers/#using-singularity-images-on-archer2","title":"Using Singularity Images on ARCHER2","text":"<p>Singularity containers can be used on ARCHER2 in a number of ways, including:</p> <ul> <li>Interactively on the login nodes</li> <li>Interactively on compute nodes</li> <li>As serial processes within a non-interactive batch script</li> <li>As parallel processes within a non-interactive batch script</li> </ul> <p>We provide information on each of these scenarios below. First, we describe briefly how to get existing container images onto ARCHER2 so that you can launch containers based on them.</p>"},{"location":"user-guide/containers/#getting-existing-container-images-onto-archer2","title":"Getting existing container images onto ARCHER2","text":"<p>Singularity container images are files, so, if you already have a container image, you can use <code>scp</code> to copy the file to ARCHER2 as you would with any other file.</p> <p>If you wish to get a file from one of the container image repositories, then Singularity allows you to do this from ARCHER2 itself.</p> <p>For example, to retrieve a container image from SingularityHub on ARCHER2 we can simply issue a Singularity command to pull the image.</p> <pre><code>auser@ln03:~&gt; singularity pull hello-world.sif shub://vsoch/hello-world\n</code></pre> <p>The container image located at the <code>shub</code> URI is written to a Singularity Image File (SIF) called <code>hello-world.sif</code>.</p>"},{"location":"user-guide/containers/#interactive-use-on-the-login-nodes","title":"Interactive use on the login nodes","text":"<p>Once you have a container image file, launching a container based on the container image on the login nodes in an interactive way is extremely simple: you use the <code>singularity shell</code> command. Using the container image we built in the example above:</p> <pre><code>auser@ln03:~&gt; singularity shell hello-world.sif\nSingularity&gt;\n</code></pre> <p>Within a Singularity container your home directory will be available.</p> <p>Once you have finished using your container, you can return to the ARCHER2 login node prompt with the <code>exit</code> command:</p> <pre><code>Singularity&gt; exit\nexit\nauser@ln03:~&gt;\n</code></pre>"},{"location":"user-guide/containers/#interactive-use-on-the-compute-nodes","title":"Interactive use on the compute nodes","text":"<p>The process for using a container interactively on the compute nodes is very similar to that for the login nodes. The only difference is that you first have to submit an interactive serial job (from a location on <code>/work</code>) in order to get interactive access to the compute node.</p> <p>For example, to reserve a full node for you to work on interactively you would use:</p> <pre><code>auser@ln03:/work/t01/t01/auser&gt; srun --nodes=1 --exclusive --time=00:20:00 \\\n                                      --account=[budget code] \\\n                                      --partition=standard --qos=standard \\\n                                      --pty /bin/bash\n\n...wait until job starts...\n\nauser@nid00001:/work/t01/t01/auser&gt;\n</code></pre> <p>Note that the prompt has changed to show you are on a compute node. Now you can launch a container in the same way as on the login node.</p> <pre><code>auser@nid00001:/work/t01/t01/auser&gt; singularity shell hello-world.sif\nSingularity&gt; exit\nexit\nauser@nid00001:/work/t01/t01/auser&gt; exit\nauser@ln03:/work/t01/t01/auser&gt;\n</code></pre> <p>Note</p> <p>We used <code>exit</code> to leave the interactive container shell and then <code>exit</code> again to leave the interactive job on the compute node.</p>"},{"location":"user-guide/containers/#serial-processes-within-a-non-interactive-batch-script","title":"Serial processes within a non-interactive batch script","text":"<p>You can also use Singularity containers within a non-interactive batch script as you would any other command. If your container image contains a runscript then you can use <code>singularity run</code> to execute the runscript in the job. You can also use <code>singularity exec</code> to execute arbitrary commands (or scripts) within the container.</p> <p>An example job submission script to run a serial job that executes the runscript within a container based on the container image in the <code>hello-world.sif</code> file that we downloaded previously to an ARCHER2 login node would be as follows.</p> <pre><code>#!/bin/bash --login\n\n# Slurm job options (name, compute nodes, job time)\n\n#SBATCH --job-name=helloworld\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:10:00\n\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Run the serial executable\nsingularity run $SLURM_SUBMIT_DIR/hello-world.sif\n</code></pre> <p>You submit this in the usual way and the standard output and error should be written to <code>slurm-...</code>, where the output filename ends with the job number.</p>"},{"location":"user-guide/containers/#parallel-processes-within-a-non-interactive-batch-script","title":"Parallel processes within a non-interactive batch script","text":"<p>Running a Singularity container in parallel across a number of compute nodes requires some preparation. In general though, Singularity can be run within the parallel job launcher (<code>srun</code>).</p> <pre><code>srun &lt;options&gt; \\\n    singularity &lt;options&gt; /path/to/image/file \\\n        app &lt;options&gt;\n</code></pre> <p>The code snippet above shows the launch command as having three nested parts, <code>srun</code>, the singularity environment and the containerised application.</p> <p>The Singularity container image must be compatible with the MPI environment on the host; either, the containerised app has been built against the appropriate MPI libraries or the container itself contains an MPI library that is compatible with the host MPI. The latter situation is known as the hybrid model; this is the approach taken in the sections that follow.</p>"},{"location":"user-guide/containers/#creating-your-own-singularity-container-images","title":"Creating Your Own Singularity Container Images","text":"<p>As we saw above, you can create Singularity container images by importing from DockerHub or Singularity Hub on ARCHER2 itself. If you wish to create your own custom container image to use with Singularity then you must use a system where you have root (or administrator) privileges - often your own laptop or workstation.</p> <p>There are a number of different options to create container images on your local system to use with Singularity on ARCHER2. We are going to use Docker on our  local system to create the container image, push the new container image to Docker Hub and then use Singularity on ARCHER2 to convert the Docker container image to a Singularity container image SIF file.</p> <p>For macOS and Windows users we recommend installing Docker Desktop. For Linux users, we recommend installing Docker directly on your local system. See the Docker documentation for full details on how to install Docker Desktop/Docker.</p>"},{"location":"user-guide/containers/#building-container-images-using-docker","title":"Building container images using Docker","text":"<p>Note</p> <p>We assume that you are familiar with using Docker in these instructions. You  can find an introduction to Docker at Reproducible Computational Environments Using Containers: Introduction to Docker</p> <p>As usual, you can build container images with a command similar to:</p> <pre><code>docker build --platform linux/amd64 -t &lt;username&gt;/&lt;image name&gt;:&lt;version&gt; .\n</code></pre> <p>Where:</p> <ul> <li><code>&lt;username&gt;</code> is your Docker Hub username</li> <li><code>&lt;image name&gt;</code> is the name of the container image you wish to create</li> <li><code>&lt;version&gt;</code> - specifies the version of the image you are creating (e.g. \"latest\", \"v1\")</li> <li><code>.</code> is the build context - in this example it is the location of the Dockerfile</li> </ul> <p>Note, you should use the <code>--platform linux/amd64</code> option to ensure that the container image is compatible with the processor architecture on ARCHER2.</p>"},{"location":"user-guide/containers/#using-singularity-with-mpi-on-archer2","title":"Using Singularity with MPI on ARCHER2","text":"<p>MPI on ARCHER2 is provided by the Cray MPICH libraries with the interface to the high-performance Slingshot interconnect provided via the OFI interface. Therefore, as per the Singularity MPI Hybrid model, we will build our container image such that it contains a version of the MPICH MPI library compiled with support for OFI. Below, we provide instructions on creating a container image with a version of MPICH compiled in this way. We then provide an  example of how to run a Singularity container with MPI over multiple  ARCHER2 compute nodes.</p>"},{"location":"user-guide/containers/#building-an-image-with-mpi-from-scratch","title":"Building an image with MPI from scratch","text":"<p>Warning</p> <p>Remember, all these steps should be executed on your local system where you have administrator privileges and Docker installed, not on ARCHER2.</p> <p>We will illustrate the process of building a Singularity image with MPI from scratch by building an image that contains MPI provided by MPICH and the OSU MPI benchmarks. As part of the container image creation we need to download the source code for both MPICH and the OSU benchmarks. At the time of writing, the stable MPICH release is 3.4.2 and the stable OSU benchmark release is 5.8 - this may have changed by the time you are following these instructions.</p> <p>First, create a Dockerfile that describes how to build the image:</p> <pre><code>FROM ubuntu:20.04\n\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install the necessary packages (from repo)\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\napt-utils \\\nbuild-essential \\\ncurl \\\nlibcurl4-openssl-dev \\\nlibzmq3-dev \\\npkg-config \\\nsoftware-properties-common\nRUN apt-get clean\nRUN apt-get install -y dkms\nRUN apt-get install -y autoconf automake build-essential numactl libnuma-dev autoconf automake gcc g++ git libtool\n\n# Download and build an ABI compatible MPICH\nRUN curl -sSLO http://www.mpich.org/static/downloads/3.4.2/mpich-3.4.2.tar.gz \\\n&amp;&amp; tar -xzf mpich-3.4.2.tar.gz -C /root \\\n&amp;&amp; cd /root/mpich-3.4.2 \\\n&amp;&amp; ./configure --prefix=/usr --with-device=ch4:ofi --disable-fortran \\\n&amp;&amp; make -j8 install \\\n&amp;&amp; rm -rf /root/mpich-3.4.2 \\\n&amp;&amp; rm /mpich-3.4.2.tar.gz\n\n# OSU benchmarks\nRUN curl -sSLO http://mvapich.cse.ohio-state.edu/download/mvapich/osu-micro-benchmarks-5.4.1.tar.gz \\\n&amp;&amp; tar -xzf osu-micro-benchmarks-5.4.1.tar.gz -C /root \\\n&amp;&amp; cd /root/osu-micro-benchmarks-5.4.1 \\\n&amp;&amp; ./configure --prefix=/usr/local CC=/usr/bin/mpicc CXX=/usr/bin/mpicxx \\\n&amp;&amp; cd mpi \\\n&amp;&amp; make -j8 install \\\n&amp;&amp; rm -rf /root/osu-micro-benchmarks-5.4.1 \\\n&amp;&amp; rm /osu-micro-benchmarks-5.4.1.tar.gz\n\n# Add the OSU benchmark executables to the PATH\nENV PATH=/usr/local/libexec/osu-micro-benchmarks/mpi/pt2pt:$PATH\nENV PATH=/usr/local/libexec/osu-micro-benchmarks/mpi/collective:$PATH\n\n# path to mlx libraries in Ubuntu\nENV LD_LIBRARY_PATH=/usr/lib/libibverbs:$LD_LIBRARY_PATH\n</code></pre> <p>A quick overview of what the above Dockerfile is doing:</p> <ul> <li>The image is being bootstrapped from the <code>ubuntu:20.04</code> Docker image.</li> <li>The first set of <code>RUN</code> sections with <code>apt-get</code> commands: install the base packages required from the Ubunntu package repos</li> <li>MPICH install: downloads and compiles the MPICH 3.4.2 in a way that is compatible with Cray MPICH on ARCHER2</li> <li>OSU MPI benchmarks install: downloads and compiles the OSU micro benchmarks</li> <li><code>ENV</code> sections: add the OSU benchmark executables to the PATH so they can be executed in the container without specifying the full path; set the correct paths to the network libraries within the container.</li> </ul> <p>Now we can go ahead and build the container image using Docker (this assumes that you issue the command in the same directory as the Dockerfile you created based on the specification above):</p> <pre><code>docker build --platform linux/amd64 -t auser/osu-benchmarks:5.4.1 .\n</code></pre> <p>(Remember to change <code>auser</code> to your Dockerhub username.)</p> <p>Once you have successfully built your container image, you should push it to Dockerhub:</p> <pre><code>docker push auser/osu-benchmarks:5.4.1\n</code></pre> <p>Finally, you need to use Singularity on ARCHER2 to convert the Docker container image to a Singularity container image file. Log into ARCHER2, move to the work file system and then use a command like:</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; singularity build osu-benchmarks_5.4.1.sif docker://auser/osu-benchmarks:5.4.1\n</code></pre> <p>Tip</p> <p>You can find a copy of the <code>osu-benchmarks_5.4.1.sif</code> image on ARCHER2 in the directory <code>$EPCC_SINGULARITY_DIR</code> if you do not want to build it yourself but still want to test.</p>"},{"location":"user-guide/containers/#running-parallel-mpi-jobs-using-singularity-containers","title":"Running parallel MPI jobs using Singularity containers","text":"<p>Tip</p> <p>These instructions assume you have built a Singularity container image file on  ARCHER2 that includes MPI provided by MPICH with the OFI interface. See the sections above for how to build such container images.</p> <p>Once you have built your Singularity container image file that includes MPICH built with OFI for ARCHER2, you can use it to run parallel jobs in a similar way to non-Singularity jobs. The example job submission script below uses the container image file we built above with MPICH and the OSU benchmarks to run the Allreduce benchmark on two nodes where all 128 cores on each node are used for MPI processes (so, 256 MPI processes in total).</p> <pre><code>#!/bin/bash\n\n# Slurm job options (name, compute nodes, job time)\n#SBATCH --job-name=singularity_parallel\n#SBATCH --time=0:10:0\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n\n# Replace [budget code] below with your budget code (e.g. t01)\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n#SBATCH --account=[budget code]\n\n# Load the module to make the Cray MPICH ABI available\nmodule load cray-mpich-abi\n\nexport OMP_NUM_THREADS=1\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n#\u00a0Set the LD_LIBRARY_PATH environment variable within the Singularity container\n# to ensure that it used the correct MPI libraries.\nexport SINGULARITYENV_LD_LIBRARY_PATH=\"/opt/cray/pe/mpich/8.1.23/ofi/gnu/9.1/lib-abi-mpich:/opt/cray/pe/mpich/8.1.23/gtl/lib:/opt/cray/libfabric/1.12.1.2.2.0.0/lib64:/opt/cray/pe/gcc-libs:/opt/cray/pe/gcc-libs:/opt/cray/pe/lib64:/opt/cray/pe/lib64:/opt/cray/xpmem/default/lib64:/usr/lib64/libibverbs:/usr/lib64:/usr/lib64\"\n\n# This makes sure HPE Cray Slingshot interconnect libraries are available\n# from inside the container.\nexport SINGULARITY_BIND=\"/opt/cray,/var/spool,/opt/cray/pe/mpich/8.1.23/ofi/gnu/9.1/lib-abi-mpich:/opt/cray/pe/mpich/8.1.23/gtl/lib,/etc/host.conf,/etc/libibverbs.d/mlx5.driver,/etc/libnl/classid,/etc/resolv.conf,/opt/cray/libfabric/1.12.1.2.2.0.0/lib64/libfabric.so.1,/opt/cray/pe/gcc-libs/libatomic.so.1,/opt/cray/pe/gcc-libs/libgcc_s.so.1,/opt/cray/pe/gcc-libs/libgfortran.so.5,/opt/cray/pe/gcc-libs/libquadmath.so.0,/opt/cray/pe/lib64/libpals.so.0,/opt/cray/pe/lib64/libpmi2.so.0,/opt/cray/pe/lib64/libpmi.so.0,/opt/cray/xpmem/default/lib64/libxpmem.so.0,/run/munge/munge.socket.2,/usr/lib64/libibverbs/libmlx5-rdmav34.so,/usr/lib64/libibverbs.so.1,/usr/lib64/libkeyutils.so.1,/usr/lib64/liblnetconfig.so.4,/usr/lib64/liblustreapi.so,/usr/lib64/libmunge.so.2,/usr/lib64/libnl-3.so.200,/usr/lib64/libnl-genl-3.so.200,/usr/lib64/libnl-route-3.so.200,/usr/lib64/librdmacm.so.1,/usr/lib64/libyaml-0.so.2\"\n\n# Launch the parallel job.\nsrun --hint=nomultithread --distribution=block:block \\\nsingularity run osu-benchmarks_5.4.1.sif \\\nosu_allreduce\n</code></pre> <p>The only changes from a standard submission script are:</p> <ul> <li>We set the environment variable <code>SINGULARITY_LD_LIBRARY_PATH</code> to ensure that the excutable can find the correct libraries are available within the container to be able to use HPE Cray Slingshot interconnect.</li> <li>We set the environment variable <code>SINGULARITY_BIND</code> to ensure that the correct libraries are available within the container to be able to use HPE Cray Slingshot interconnect.</li> <li><code>srun</code> calls the <code>singularity</code> software with the container image file we created rather than the parallel program directly.</li> </ul> <p>Important</p> <p>Remember that the image file must be located on <code>/work</code> to run jobs on the compute nodes.</p> <p>If the job runs correctly, you should see output similar to the following in your <code>slurm-*.out</code>  file:</p> <pre><code>Lmod is automatically replacing \"cray-mpich/8.1.23\" with\n\"cray-mpich-abi/8.1.23\".\n\n\n# OSU MPI Allreduce Latency Test v5.4.1\n# Size       Avg Latency(us)\n4                       7.93\n8                       7.93\n16                      8.13\n32                      8.69\n64                      9.54\n128                    13.75\n256                    17.04\n512                    25.94\n1024                   29.43\n2048                   43.53\n4096                   46.53\n8192                   46.20\n16384                  55.85\n32768                  83.11\n65536                 136.90\n131072                257.13\n262144                486.50\n524288               1025.87\n1048576              2173.25\n</code></pre>"},{"location":"user-guide/data-migration/","title":"Data migration from ARCHER to ARCHER2","text":"<p>This content has been moved to archer-migration/data-migration</p>"},{"location":"user-guide/data/","title":"Data management and transfer","text":"<p>This section covers best practice and tools for data management on ARCHER2 along with a description of the different storage available on the service.</p> <p>The IO section has information on achieving good performance for reading and writing data to the ARCHER2 storage along with information and advice on different IO patterns.</p> <p>Information</p> <p>If you have any questions on data management and transfer please do not hesitate to contact the ARCHER2 service desk at support@archer2.ac.uk.</p>"},{"location":"user-guide/data/#useful-resources-and-links","title":"Useful resources and links","text":"<ul> <li>Harry Mangalam's guide on How to transfer large amounts of data      via      network.      This provides lots of useful advice on transferring data.</li> </ul>"},{"location":"user-guide/data/#data-management","title":"Data management","text":"<p>We strongly recommend that you give some thought to how you use the various data storage facilities that are part of the ARCHER2 service. This will not only allow you to use the machine more effectively but also to ensure that your valuable data is protected.</p> <p>Here are the main points you should consider:</p> <ul> <li>Not all data are created equal, understand your data. Know what data you have. What is your   critical data that needs to be copied to a secure location? Which data do you need in a different   location to analyse? Which data would it be easier to regenerate rather than transfer? You should   create a brief data management plan laying this out as this will allow you to understand which   tools to use and when.</li> <li>Minimise the data you are transferring. Transferring large amounts of data is costly in both   researcher time and actual time. Make sure you are only transferring the data you need to transfer.</li> <li>Minimise the number of files you are transferring. Each individual file has a static overhead in   data transfers so it is efficient to bundle multiple files together into a single large   archive file for transfer.</li> <li>Does compression help or hinder? Many tools have the option to use compression (e.g. <code>rsync</code>,   <code>tar</code>, <code>zip</code>) and generally encourage you to use them to reduce data volumes. However, in some cases,   the time spent compressing the data can take longer than actually transferring the uncompressed   data; particularly when transferring data between two locations that both have large data transfer   bandwidth available.</li> <li>Be aware of encryption overheads. When transferring data using <code>scp</code> (and <code>rsync</code> over <code>scp</code>)   your data will be encrypted introducing a static overhead per file. This issue can be minimised by   reducing the number files to be transferred by creating archives. You can also change the encryption   algorithm to one that involves minimal encryption. The fastest performing cipher that is commonly    available in SSH at the moment is generally <code>aes128-ctr</code> as most common processors provide a   hardware implementation.</li> </ul>"},{"location":"user-guide/data/#archer2-storage","title":"ARCHER2 storage","text":"<p>The ARCHER2 service, like many HPC systems, has a complex structure. There are a number of different data storage types available to users:</p> <ul> <li>Home file systems</li> <li>Work file systems</li> <li>Solid state (NVMe) file system</li> <li>RDFaaS (RDF as a Service) file systems (<code>/epsrc</code> and <code>/general</code>)</li> </ul> <p>Each type of storage has different characteristics and policies, and is suitable for different types of use.</p> <p>There are also three different types of node available to users:</p> <ul> <li>Login nodes</li> <li>Compute nodes</li> <li>Data analysis nodes</li> </ul> <p>Each type of node sees a different combination of the storage types. The following table shows which storage options are avalable on  different node types:</p> Storage Login Nodes Compute Nodes Data analysis nodes Notes /home yes no yes Incremental backup /work yes yes yes No backup, high performance Solid state (NVMe) yes yes yes No backup, high performance RDFaaS yes no yes Disaster recovery backup <p>Important</p> <p>Only the work file systems and the solid state (NVMe) file system are visible on the compute nodes. This means that all data required by calculations at runtime (input data, application binaries, software libraries, etc.) must be placed on one of these file systems.</p> <p>You may see \"file not found\" errors if you try to access data on the /home or RDFaaS file systems when running on the compute nodes.</p>"},{"location":"user-guide/data/#home-file-systems","title":"Home file systems","text":"<p>There are four independent home file-systems. Every project has an allocation on one of the four. You do not need to know which one your project uses as your projects space can always be accessed via the path <code>/home/project-code</code>. Each home file-system is approximately 100 TB in size and is implemented using standard Network Attached Storage (NAS) technology. This means that these disks are not particularly high performance but are well suited to standard operations like compilation and file editing. These file systems are visible from the ARCHER2 login nodes.</p>"},{"location":"user-guide/data/#accessing-snapshots-of-home-file-systems","title":"Accessing snapshots of home file systems","text":"<p>The home file systems are fully backed up. The home file systems retain snapshots which can be used to recover past versions of files. Snapshots are taken weekly (for each of the past two weeks), daily (for each of the past two days) and hourly (for each of the last 6 hours). You can access the snapshots at <code>.snapshot</code> from any given directory on the home file systems. Note that the <code>.snapshot</code> directory will not show up under any version of \u201cls\u201d and will not tab complete.</p> <p>These file systems are a good location to keep source code, copies of scripts and compiled binaries. Small amounts of important data can also be copied here for safe keeping though the file systems are not fast enough to manipulate large datasets effectively.</p>"},{"location":"user-guide/data/#quotas-on-home-file-systems","title":"Quotas on home file systems","text":"<p>All projects are assigned a quota on the home file systems. The project PI or manager can split this quota up between users or groups of users if they wish.</p> <p>You can view any home file system quotas that apply to your account by logging into SAFE and navigating to the page for your ARCHER2 login  account.</p> <ol> <li>Log into SAFE</li> <li>Use the \"Login accounts\" menu and select your ARCHER2 login account</li> <li>The \"Login account details\" table lists any user or group quotas that    are linked with your account. (If there is no quota shown for a row    then you have an unlimited quota for that item, but you may still may    be limited by another quota.)</li> </ol> <p>Tip</p> <p>Quota and usage data on SAFE is updated twice daily so may not be exactly up to date with the situation on the systems themselves.</p>"},{"location":"user-guide/data/#work-file-systems","title":"Work file systems","text":"<p>There are currently three work file systems on the full ARCHER2 service. Each of these file systems is 3.4 PB and a portion of one of these file systems is available to each project.</p> <p>All of these are high-performance, Lustre parallel file systems. They are designed to support data in large files. The performance for data stored in large numbers of small files is probably not going to be as good.</p> <p>These file systems are available on the compute nodes and are the default location users should use for data required at runtime on the compute nodes.</p> <p>Warning</p> <p>There are no backups of any data on the work file systems. You should not rely on these file systems for long term storage.</p> <p>Ideally, these file systems should only contain data that is:</p> <ul> <li>actively in use;</li> <li>recently generated and in the process of being saved elsewhere; or</li> <li>being made ready for up-coming work.</li> </ul> <p>In practice it may be convenient to keep copies of datasets on the work file systems that you know will be needed at a later date. However, make sure that important data is always backed up elsewhere and that your work would not be significantly impacted if the data on the work file systems was lost.</p> <p>Large data sets can be moved to the RDFaaS storage or transferred off the ARCHER2 service entirely.</p> <p>If you have data on the work file systems that you are not going to need in the future please delete it.</p>"},{"location":"user-guide/data/#quotas-on-the-work-file-systems","title":"Quotas on the work file systems","text":"<p>As for the home file systems, all projects are assigned a quota on the work file systems. The project PI or manager can split this quota up between users or groups of users if they wish.</p> <p>You can view any work file system quotas that apply to your account by logging into SAFE and navigating to the page for your ARCHER2 login  account.</p> <ol> <li>Log into SAFE</li> <li>Use the \"Login accounts\" menu and select your ARCHER2 login account</li> <li>The \"Login account details\" table lists any user or group quotas that    are linked with your account. (If there is no quota shown for a row    then you have an unlimited quota for that item, but you may still may    be limited by another quota.)</li> </ol> <p>Tip</p> <p>Quota and usage data on SAFE is updated twice daily so may not be exactly up to date with the situation on the systems themselves.</p> <p>You can also examine up to date quotas and usage on the ARCHER2 systems themselves using the <code>lfs quota</code> command. To do this:</p> <ul> <li>Change directory to the work directory where you want to check the    quota. For example, if I wanted to check the quota for user <code>auser</code> in    project <code>t01</code> then I would:</li> </ul> <pre><code>cd /work/t01/t01/auser\n</code></pre> <ul> <li>To check your user quota, you would use the command:</li> </ul> <pre><code>auser@ln03:/work/t01/t01/auser&gt; lfs quota -hu auser .\nDisk quotas for usr auser (uid 5496):\n  Filesystem    used   quota   limit   grace   files   quota   limit   grace\n           .  1.366G      0k      0k       -    5486       0       0       -\nuid 5496 is using default block quota setting\nuid 5496 is using default file quota setting\n</code></pre> <p>the <code>quota</code> and <code>limit</code> of <code>0k</code> here indicate that no user quota is set for this    user</p> <ul> <li>To check your project quota, you would use the command:</li> </ul> <pre><code>auser@ln03:/work/t01/t01/auser&gt; lfs quota -hp $(id -g) .\nDisk quotas for prj 1009 (pid 1009):\n  Filesystem    used   quota   limit   grace   files   quota   limit   grace\n           .  2.905G      0k      0k       -   25300       0       0       -\npid 1009 is using default block quota setting\npid 1009 is using default file quota setting\n</code></pre>"},{"location":"user-guide/data/#solid-state-nvme-file-system","title":"Solid state (NVMe) file system","text":"<p>The solid state storage file system is a 1 PB high performance parallel Lustre file system similar to the work file systems. However, unlike the work file systems, all of the disks are based solid state storage (NVMe) technology. This changes the performance characteristics of the  file system compared to the work file systems. Testing by the ARCHER2 CSE team at EPCC has shown that you may see I/O performance improvements from the solid state storage compared to the standard work Lustre file systems on ARCHER2 if your I/O model has the following characteristics or similar:</p> <ul> <li>You read/write lots of files in parallel (e.g. your software uses a file-per-process   model or similar)</li> <li>You use the ADIOS 2 I/O system</li> </ul> <p>Data on the solid state (NVMe) file system is visible on the compute nodes</p> <p>Important</p> <p>If you use MPI-IO approaches to reading/writing data - this includes parallel HDF5 and parallel NetCDF - then you very unlikely to see any performance improvements from using the solid state storage over the standard parallel Lustre file systems on ARCHER2.</p> <p>Warning</p> <p>There are no backups of any data on the solid state (NVMe) file system. You should not rely on this file system for long term storage.</p>"},{"location":"user-guide/data/#access-to-the-solid-state-file-system","title":"Access to the solid state file system","text":"<p>Projects do not have access to the solid state file system by default. If you would like access to the solid state file system, you should contact the ARCHER2 Service Desk with a short description of why you want access, how much space you require and how long you require access for.</p> <p>Important</p> <p>While we will endeavour to meet all reasonable requests for access, the capacity of the solid state file system is limited and we may not be able to fulfil all requests.</p>"},{"location":"user-guide/data/#location-of-directories","title":"Location of directories","text":"<p>If your project has been granted access to the solid state file system, you can find your directory on the file system at:</p> <pre><code>/mnt/lustre/a2fs-nvme/work/&lt;project code&gt;/&lt;project code&gt;/&lt;username&gt;\n</code></pre> <p>For example, if my username is <code>auser</code> and I am in project <code>t01</code>, I could find my  solid state storage directory at:</p> <pre><code>/mnt/lustre/a2fs-nvme/work/t01/t01/auser\n</code></pre>"},{"location":"user-guide/data/#quotas-on-solid-state-file-system","title":"Quotas on solid state file system","text":"<p>You query quotas for the solid state file system in the same way as quotas on the work file systems.</p> <p>Bug</p> <p>Usage and quotas of the solid state file system are not yet available in SAFE - you should use commands such as <code>lfs quota -hp $(id -g) .</code> to query quotas on the solid state file system. </p>"},{"location":"user-guide/data/#rdfaas-file-systems","title":"RDFaaS file systems","text":"<p>The RDFaaS file systems provide additional capacity for projects to store data that is not currently required on the compute nodes but which is too large for the Home file systems.</p> <p>Warning</p> <p>The RDFaaS file systems are backed up for disaster recovery purposes only (e.g. loss of the whole file system) so it is not possible to recover individual files if they are deleted by mistake or otherwise lost.</p> <p>Tip</p> <p>Not all projects on ARCHER2 have access to RDFaaS, if you do have access, this will show up in the login account page on SAFE for your ARCHER2 login account.</p> <p>If you have access to RDFaaS, you will have a directory in one of two file systems: either <code>/epsrc</code> or <code>/general</code>.</p> <p>For example, if your username is <code>auser</code> and you are in the <code>e05</code> project, then your RDFaaS directory will be at:</p> <pre><code>/epsrc/e05/e05/auser\n</code></pre> <p>The RDFaaS file systems are not available on the ARCHER2 compute nodes.</p> <p>Tip</p> <p>If you are having issues accessing data on the RDFaaS file system then  please contact the ARCHER2 Service Desk</p>"},{"location":"user-guide/data/#copying-data-from-rdfaas-to-work-file-systems","title":"Copying data from RDFaaS to Work file systems","text":"<p>You should use the standard Linux <code>cp</code> command to copy data from the RDFaaS file  system to other ARCHER2 file systems (usually <code>/work</code>). For example, to transfer the file <code>important-data.tar.gz</code> from the RDFaaS file system to <code>/work</code> you would use the following command (assuming you are user <code>auser</code> in project <code>e05</code>):</p> <pre><code>cp /epsrc/e05/e05/auser/important-data.tar.gz /work/e05/e05/auser/\n</code></pre> <p>(remember to replace the project code and username with your own username and project code. You may also need to use <code>/general</code> if your data was  there on the RDF file systems).</p>"},{"location":"user-guide/data/#subprojects","title":"Subprojects","text":"<p>Some large projects may choose to split their resources into multiple subprojects.  These subprojects will have identifiers appended to the main project ID. For example, the <code>rse</code> subgroup of the <code>z19</code> project would have the ID <code>z19-rse</code>. If the main project has allocated storage quotas to the subproject the directories for this storage will be found at, for example: <pre><code>/home/z19/z19-rse/auser\n</code></pre></p> <p>Your Linux home directory will generally not be changed when you are made a member of a subproject so you must change directories manually (or change the ownership of files) to make use of this different storage quota allocation.</p>"},{"location":"user-guide/data/#sharing-data-with-other-archer2-users","title":"Sharing data with other ARCHER2 users","text":"<p>How you share data with other ARCHER2 users depends on whether or not they belong to the same project as you. Each project has two shared folders that can be used for sharing data.</p>"},{"location":"user-guide/data/#sharing-data-with-archer2-users-in-your-project","title":"Sharing data with ARCHER2 users in your project","text":"<p>Each project has an inner shared folder.</p> <pre><code>/work/[project code]/[project code]/shared\n</code></pre> <p>This folder has read/write permissions for all project members. You can place any data you wish to share with other project members in this directory. For example, if your project code is x01 the inner shared folder would be located at <code>/work/x01/x01/shared</code>.</p>"},{"location":"user-guide/data/#sharing-data-with-archer2-users-within-the-same-project-group","title":"Sharing data with  ARCHER2 users within the same project group","text":"<p>Some projects have subprojects (also often referred to as a 'project groups' or sub-budgets)   e.g. project e123 might have a project group e123-fred  for a sub-group of researchers working with Fred.</p> <p>Often project groups do not have a disk quota set, but if the project PI does set up a group disk quota e.g. for /work then additional directories are created:</p> <pre><code>/work/e123/e123-fred\n/work/e123/e123-fred/shared\n/work/e123/e123-fred/&lt;user&gt; (for every user in the group)\n</code></pre> <p>and all members of the <code>/work/e123/e123-fred</code> group will be able to use the <code>/work/e123/e123-fred/shared</code> directory to share their files.</p> <p>Note</p> <p>If files are copied from their usual directories they will keep the original ownership. To grant ownership to the group:</p> <p><code>chown -R $USER:e123-fred /work/e123/e123-fred/ ...</code></p>"},{"location":"user-guide/data/#sharing-data-with-all-archer2-users","title":"Sharing data with all ARCHER2 users","text":"<p>Each project also has an outer shared folder.:</p> <pre><code>/work/[project code]/shared\n</code></pre> <p>It is writable by all project members and readable by any user on the system. You can place any data you wish to share with other ARCHER2 users who are not members of your project in this directory. For example, if your project code is x01 the outer shared folder would be located at <code>/work/x01/shared</code>.</p>"},{"location":"user-guide/data/#permissions","title":"Permissions","text":"<p>You should check the permissions of any files that you place in the shared area, especially if those files were created in your own ARCHER2 account. Files of the latter type are likely to be readable by you only.</p> <p>The <code>chmod</code> command below shows how to make sure that a file placed in the outer shared folder is also readable by all ARCHER2 users.</p> <pre><code>chmod a+r /work/x01/shared/your-shared-file.txt\n</code></pre> <p>Similarly, for the inner shared folder, <code>chmod</code> can be called such that read permission is granted to all users within the x01 project.</p> <pre><code>chmod g+r /work/x01/x01/shared/your-shared-file.txt\n</code></pre> <p>If you're sharing a set of files stored within a folder hierarchy the <code>chmod</code> is slightly more complicated.</p> <pre><code>chmod -R a+Xr /work/x01/shared/my-shared-folder\nchmod -R g+Xr /work/x01/x01/shared/my-shared-folder\n</code></pre> <p>The <code>-R</code> option ensures that the read permission is enabled recursively and the <code>+X</code> guarantees that the user(s) you're sharing the folder with can access the subdirectories below <code>my-shared-folder</code>.</p>"},{"location":"user-guide/data/#sharing-data-between-projects-and-subprojects","title":"Sharing data between projects and subprojects","text":"<p>Every file has an owner group that specifies access permissions for users belonging to that group. It's usually the case that the group id is synonymous with the project code. Somewhat confusingly however, projects can contain groups of their own, called subprojects, which can be assigned disk space quotas distinct from the project.</p> <pre><code>chown -R $USER:x01-subproject /work/x01/x01-subproject/$USER/my-folder\n</code></pre> <p>The <code>chown</code> command above changes the owning group for all the files within <code>my-folder</code> to the <code>x01-subproject</code> group. This might be necessary if previously those files were owned by the x01 group and thereby using some of the x01 disk quota.</p>"},{"location":"user-guide/data/#archiving-and-data-transfer","title":"Archiving and data transfer","text":"<p>Data transfer speed may be limited by many different factors so the best data transfer mechanism to use depends on the type of data being transferred and where the data is going.</p> <ul> <li>Disk speed - The ARCHER2 /work file system is highly parallel,      consisting of a very large number      of high performance disk drives. This allows it to support a      very high data bandwidth. Unless the remote system has a similar      parallel file-system you may find your transfer speed limited by      disk performance.</li> <li>Meta-data performance - Meta-data operations such as opening      and closing files or listing the owner or size of a file are much      less parallel than read/write operations. If your data consists of      a very large number of small files you may find your transfer      speed is limited by meta-data operations. Meta-data operations      performed by other users of the system will interact strongly with      those you perform so reducing the number of such operations you      use, may reduce variability in your IO timings.</li> <li>Network speed - Data transfer performance can be limited by      network speed. More importantly it is limited by the slowest      section of the network between source and destination.</li> <li>Firewall speed - Most modern networks are protected by some      form of firewall that filters out malicious traffic. This      filtering has some overhead and can result in a reduction in data      transfer performance. The needs of a general purpose network that      hosts email/web-servers and desktop machines are quite different      from a research network that needs to support high volume data      transfers. If you are trying to transfer data to or from a host on      a general purpose network you may find the firewall for that      network will limit the transfer rate you can achieve.</li> </ul> <p>The method you use to transfer data to/from ARCHER2 will depend on how much you want to transfer and where to. The methods we cover in this guide are:</p> <ul> <li>scp/sftp/rsync - These are the simplest methods of      transferring data and can be used up to moderate amounts of data.      If you are transferring data to your workstation/laptop then this      is the method you will use.</li> <li>GridFTP - It is sometimes more convenient to transfer large      amounts of data (&gt; 100 GBs) using GridFTP servers.</li> </ul> <p>Before discussing specific data transfer methods, we cover archiving which is an essential process for transferring data efficiently.</p>"},{"location":"user-guide/data/#archiving","title":"Archiving","text":"<p>If you have related data that consists of a large number of small files it is strongly recommended to pack the files into a larger \"archive\" file for ease of transfer and manipulation. A single large file makes more efficient use of the file system and is easier to move and copy and transfer because significantly fewer meta-data operations are required. Archive files can be created using tools like <code>tar</code> and <code>zip</code>.</p>"},{"location":"user-guide/data/#tar","title":"tar","text":"<p>The <code>tar</code> command packs files into a \"tape archive\" format. The command has general form:</p> <pre><code>tar [options] [file(s)]\n</code></pre> <p>Common options include:</p> <ul> <li><code>-c</code> create a new archive</li> <li><code>-v</code> verbosely list files processed</li> <li><code>-W</code> verify the archive after writing</li> <li><code>-l</code> confirm all file hard links are included in the archive</li> <li><code>-f</code> use an archive file (for historical reasons, tar writes its      output to stdout by default rather than a file).</li> </ul> <p>Putting these together:</p> <pre><code>tar -cvWlf mydata.tar mydata\n</code></pre> <p>will create and verify an archive.</p> <p>To extract files from a tar file, the option <code>-x</code> is used. For example:</p> <pre><code>tar -xf mydata.tar\n</code></pre> <p>will recover the contents of <code>mydata.tar</code> to the current working directory.</p> <p>To verify an existing tar file against a set of data, the <code>-d</code> (diff) option can be used. By default, no output will be given if a verification succeeds and an example of a failed verification follows:</p> <pre><code>$&gt; tar -df mydata.tar mydata/*\nmydata/damaged_file: Mod time differs\nmydata/damaged_file: Size differs\n</code></pre> <p>Note</p> <p>tar files do not store checksums with their data, requiring the original data to be present during verification.</p> <p>Tip</p> <p>Further information on using <code>tar</code> can be found in the <code>tar</code> manual (accessed via <code>man tar</code> or at man tar).</p>"},{"location":"user-guide/data/#zip","title":"zip","text":"<p>The zip file format is widely used for archiving files and is supported by most major operating systems. The utility to create zip files can be run from the command line as:</p> <pre><code>zip [options] mydata.zip [file(s)]\n</code></pre> <p>Common options are:</p> <ul> <li><code>-r</code> used to zip up a directory</li> <li><code>-#</code> where \"#\" represents a digit ranging from 0 to 9 to specify      compression level, 0 being the least and 9 the most. Default      compression is -6 but we recommend using -0 to speed up the      archiving process.</li> </ul> <p>Together:</p> <pre><code>zip -0r mydata.zip mydata\n</code></pre> <p>will create an archive.</p> <p>Note</p> <p>Unlike tar, zip files do not preserve hard links. File data will be copied on archive creation, e.g. an uncompressed zip archive of a 100MB file and a hard link to that file will be approximately 200MB in size. This makes zip an unsuitable format if you wish to precisely reproduce the file system layout.</p> <p>The corresponding <code>unzip</code> command is used to extract data from the archive. The simplest use case is:</p> <pre><code>unzip mydata.zip\n</code></pre> <p>which recovers the contents of the archive to the current working directory.</p> <p>Files in a zip archive are stored with a CRC checksum to help detect data loss. <code>unzip</code> provides options for verifying this checksum against the stored files. The relevant flag is <code>-t</code> and is used as follows:</p> <pre><code>$&gt; unzip -t mydata.zip\nArchive:  mydata.zip\n    testing: mydata/                 OK\n    testing: mydata/file             OK\nNo errors detected in compressed data of mydata.zip.\n</code></pre> <p>Tip</p> <p>Further information on using <code>zip</code> can be found in the <code>zip</code> manual (accessed via <code>man zip</code> or at man zip).</p>"},{"location":"user-guide/data/#data-transfer-via-ssh","title":"Data transfer via SSH","text":"<p>The easiest way of transferring data to/from ARCHER2 is to use one of the standard programs based on the SSH protocol such as <code>scp</code>, <code>sftp</code> or <code>rsync</code>. These all use the same underlying mechanism (SSH) as you normally use to log-in to ARCHER2. So, once the the command has been executed via the command line, you will be prompted for your password for the specified account on the remote machine (ARCHER2 in this case).</p> <p>To avoid having to type in your password multiple times you can set up a SSH key pair and use an SSH agent as documented in the User Guide at <code>connecting</code>.</p>"},{"location":"user-guide/data/#ssh-data-transfer-performance-considerations","title":"SSH data transfer performance considerations","text":"<p>The SSH protocol encrypts all traffic it sends. This means that file transfer using SSH consumes a relatively large amount of CPU time at both ends of the transfer (for encryption and decryption). The ARCHER2 login nodes have fairly fast processors that can sustain about 100 MB/s transfer. The encryption algorithm used is negotiated between the SSH client and the SSH server. There are command line flags that allow you to specify a preference for which encryption algorithm should be used. You may be able to improve transfer speeds by requesting a different algorithm than the default. The <code>aes128-ctr</code> or <code>aes256-ctr</code> algorithms are well supported and fast as they are implemented in hardware. These are not usually the default choice when using <code>scp</code> so you will need to manually specify them.</p> <p>A single SSH based transfer will usually not be able to saturate the available network bandwidth or the available disk bandwidth so you may see an overall improvement by running several data transfer operations in parallel. To reduce metadata interactions it is a good idea to overlap transfers of files from different directories.</p> <p>In addition, you should consider the following when transferring data:</p> <ul> <li>Only transfer those files that are required. Consider which data      you really need to keep.</li> <li>Combine lots of small files into a single tar archive, to reduce      the overheads associated in initiating many separate data      transfers (over SSH, each file counts as an individual transfer).</li> <li>Compress data before transferring it, e.g. using <code>gzip</code>.</li> </ul>"},{"location":"user-guide/data/#scp","title":"scp","text":"<p>The <code>scp</code> command creates a copy of a file, or if given the <code>-r</code> flag, a directory either from a local machine onto a remote machine or from a remote machine onto a local machine.</p> <p>For example, to transfer files to ARCHER2 from a local machine:</p> <pre><code>scp [options] source user@login.archer2.ac.uk:[destination]\n</code></pre> <p>(Remember to replace <code>user</code> with your ARCHER2 username in the example above.)</p> <p>In the above example, the <code>[destination]</code> is optional, as when left out <code>scp</code> will copy the source into your home directory. Also, the <code>source</code> should be the absolute path of the file/directory being copied or the command should be executed in the directory containing the source file/directory.</p> <p>If you want to request a different encryption algorithm add the <code>-c [algorithm-name]</code> flag to the <code>scp</code> options. For example, to use the (usually faster) arcfour encryption algorithm you would     use:</p> <pre><code>scp [options] -c aes128-ctr source user@login.archer2.ac.uk:[destination]\n</code></pre> <p>(Remember to replace <code>user</code> with your ARCHER2 username in the example above.)</p>"},{"location":"user-guide/data/#rsync","title":"rsync","text":"<p>The <code>rsync</code> command can also transfer data between hosts using a <code>ssh</code> connection. It creates a copy of a file or, if given the <code>-r</code> flag, a directory at the given destination, similar to <code>scp</code> above.</p> <p>Given the <code>-a</code> option rsync can also make exact copies (including permissions), this is referred to as mirroring. In this case the <code>rsync</code> command is executed with <code>ssh</code> to create the copy on a remote machine.</p> <p>To transfer files to ARCHER2 using <code>rsync</code> with <code>ssh</code> the command has the form:</p> <pre><code>rsync [options] -e ssh source user@login.archer2.ac.uk:[destination]\n</code></pre> <p>(Remember to replace <code>user</code> with your ARCHER2 username in the example above.)</p> <p>In the above example, the <code>[destination]</code> is optional, as when left out rsync will copy the source into your home directory. Also the <code>source</code> should be the absolute path of the file/directory being copied or the command should be executed in the directory containing the source file/directory.</p> <p>Additional flags can be specified for the underlying <code>ssh</code> command by using a quoted string as the argument of the <code>-e</code> flag.     e.g.</p> <pre><code>rsync [options] -e \"ssh -c arcfour\" source user@login.archer2.ac.uk:[destination]\n</code></pre> <p>(Remember to replace <code>user</code> with your ARCHER2 username in the example above.)</p> <p>Tip</p> <p>Further information on using <code>rsync</code> can be found in the <code>rsync</code> manual (accessed via <code>man rsync</code> or at man rsync).</p>"},{"location":"user-guide/data/#data-transfer-via-gridftp","title":"Data transfer via GridFTP","text":"<p>ARCHER2 provides a module for grid computing, <code>gct/6.2</code>, otherwise known as the Globus Grid Community Toolkit v6.2.20201212. This toolkit provides a command line interface for moving data to and from GridFTP servers. </p> <p>Data transfers are managed by the <code>globus-url-copy</code> command. Full details concerning this command's use can be found in the GCT 6.2 GridFTP User's Guide.</p> <p>Info</p> <p>Further information on using GridFTP on ARCHER2 to transfer data to the JASMIN facility can be found in the JASMIN user documentation.</p>"},{"location":"user-guide/data/#ssh-data-transfer-example-laptopworkstation-to-archer2","title":"SSH data transfer example: laptop/workstation to ARCHER2","text":"<p>Here we have a short example demonstrating transfer of data directly from a laptop/workstation to ARCHER2.</p> <p>Note</p> <p>This guide assumes you are using a command line interface to transfer data. This means the terminal on Linux or macOS, MobaXterm local terminal on Windows or Powershell.</p> <p>Before we can transfer of data to ARCHER2 we need to make sure we have an SSH key setup to access ARCHER2 from the system we are transferring data from. If you are using the same system that you use to log into ARCHER2 then you should be all set. If you want to use a different system you will need to generate a new SSH key there (or use SSH key forwarding) to allow you to  connect to ARCHER2.</p> <p>Tip</p> <p>Remember that you will need to use both a key and your password to transfer data to ARCHER2.</p> <p>Once we know our keys are setup correctly, we are now ready to transfer data directly between the two machines. We begin by combining our important research data in to a single archive file using the following command:</p> <pre><code>tar -czf all_my_files.tar.gz file1.txt file2.txt file3.txt\n</code></pre> <p>We then initiate the data transfer from our system to ARCHER2, here using <code>rsync</code> to allow the transfer to be recommenced without needing to start again, in the event of a loss of connection or other failure. For example, using the SSH key in the file <code>~/.ssh/id_RSA_A2</code> on our local system:</p> <pre><code>rsync -Pv -e\"ssh -c aes128-gcm@openssh.com -i $HOME/.ssh/id_RSA_A2\" ./all_my_files.tar.gz otbz19@login.archer2.ac.uk:/work/z19/z19/otbz19/\n</code></pre> <p>Note the use of the <code>-P</code> flag to allow partial transfer -- the same command could be used to restart the transfer after a loss of connection. The <code>-e</code> flag allows specification of the ssh command - we have used this to add the location of the identity file.  The <code>-c</code> option specifies the cipher to be used as <code>aes128-gcm</code> which has been found to increase performance Unfortunately the <code>~</code> shortcut is not correctly expanded, so we have specified the full path. We move our research archive to our project work directory on ARCHER2.</p> <p>Note</p> <p>Remember to replace <code>otbz19</code> with your username on ARCHER2.</p> <p>If we were unconcerned about being able to restart an interrupted transfer, we could instead use the <code>scp</code> command,</p> <pre><code>scp -c aes128-gcm@openssh.com -i ~/.ssh/id_RSA_A2 all_my_files.tar.gz otbz19@login.archer2.ac.uk:/work/z19/z19/otbz19/\n</code></pre> <p>but <code>rsync</code> is recommended for larger transfers.</p>"},{"location":"user-guide/debug/","title":"Debugging","text":"<p>The following debugging tools are available on ARCHER2:</p> <ul> <li>Arm Forge (DDT) is an easy-to-use graphical     interface for source-level debugging of compiled C/C++ or Fortran codes.     It can also be used for non-interactive debugging, and there     is also some limited support for python debugging.</li> <li>gdb4hpc is a command-line debugging tool provided by     HPE Cray. It works similarly to     gdb, but allows the user to     debug multiple parallel processes without multiple windows. gdb4hpc     can be used to investigate deadlocked code, segfaults, and other     errors for C/C++ and Fortran code. Users can single-step code and     focus on specific processes groups to help identify unexpected code     behavior. (text from     ALCF).</li> <li>valgrind4hpc is a parallel memory debugging tool     that aids in detection of memory leaks and errors in parallel     applications. It aggregates like errors across processes and threads     to simply debugging of parallel applications.</li> <li>STAT generate merged stack traces for parallel applications.     Also has visualisation tools.</li> <li>ATP provides scalable core file and backtrace analysis when parallel     programs crash.</li> <li>CCDB Cray Comparative Debugger. Compare two versions of code     side-by-side to analyse differences. (Not currently described in this     documentation.)</li> </ul>"},{"location":"user-guide/debug/#arm-forge","title":"Arm Forge","text":"<p>The Arm Forge tool (now Linaro Forge) provides the DDT parallel debugger. See:</p> <ul> <li>ARCHER2 Arm Forge documentation</li> </ul>"},{"location":"user-guide/debug/#gdb4hpc","title":"gdb4hpc","text":"<p>The GNU Debugger for HPC (gdb4hpc) is a GDB-based debugger used to debug applications compiled with CCE, PGI, GNU, and Intel Fortran, C and C++ compilers. It allows programmers to either launch an application within it or to attach to an already-running application. Attaching to an already-running and hanging application is a quick way of understanding why the application is hanging, whereas launching an application through gdb4hpc will allow you to see your application running step-by-step, output the values of variables, and check whether the application runs as expected.</p> <p>Tip</p> <p>For your executable to be compatible with gdb4hpc, it will need to be coded with MPI. You will also need to compile your code with the debugging flag <code>-g</code> (e.g. <code>cc -g my_program.c -o my_exe</code>).</p>"},{"location":"user-guide/debug/#launching-through-gdb4hpc","title":"Launching through gdb4hpc","text":"<p>Launch <code>gdb4hpc</code>:</p> <pre><code>module load gdb4hpc\ngdb4hpc\n</code></pre> <p>You will get some information about this version of the program and, eventually, you will get a command prompt:</p> <pre><code>gdb4hpc 4.5 - Cray Line Mode Parallel Debugger\nWith Cray Comparative Debugging Technology.\nCopyright 2007-2019 Cray Inc. All Rights Reserved.\nCopyright 1996-2016 University of Queensland. All Rights Reserved.\nType \"help\" for a list of commands.\nType \"help &lt;cmd&gt;\" for detailed help about a command.\ndbg all&gt;\n</code></pre> <p>We will use <code>launch</code> to begin a multi-process application within gdb4hpc. Consider that we are wanting to test an application called <code>my_exe</code>, and that we want this to be launched across all 256 processes in two nodes. We would launch this in gdb4hpc by     running:</p> <pre><code>dbg all&gt; launch --launcher-args=\"--account=[budget code] --partition=standard --qos=standard --nodes=2 --ntasks-per-node=128 --cpus-per-task=1 --exclusive --export=ALL\" $my_prog{256} ./my_ex\n</code></pre> <p>Make sure to replace the <code>--account</code> input to your budget code (e.g. if you are using budget t01, that part should look like <code>--account=t01</code>).</p> <p>The default launcher is <code>srun</code> and the <code>--launcher-args=\"...\"</code> allows you to set launcher flags for <code>srun</code>. The variable <code>$my_prog</code> is a dummy name for the program being launched and you could use whatever name you want for it -- this will be the name of the <code>srun</code> job that will be run. The number in the brackets <code>{256}</code> is the number of processes over which the program will be executed, it's 256 here, but you could use any number. You should try to run this on as few processors as possible -- the more you use, the longer it will take for gdb4hpc to load the program.</p> <p>Once the program is launched, gdb4hpc will load up the program and begin to run it. You will get output to screen something that looks like:</p> <pre><code>Starting application, please wait...\nCreating MRNet communication network...\nWaiting for debug servers to attach to MRNet communications network...\nTimeout in 400 seconds. Please wait for the attach to complete.\nNumber of dbgsrvs connected: [0];  Timeout Counter: [1]\nNumber of dbgsrvs connected: [0];  Timeout Counter: [2]\nNumber of dbgsrvs connected: [0];  Timeout Counter: [3]\nNumber of dbgsrvs connected: [1];  Timeout Counter: [0]\nNumber of dbgsrvs connected: [1];  Timeout Counter: [1]\nNumber of dbgsrvs connected: [2];  Timeout Counter: [0]\nFinalizing setup...\nLaunch complete.\nmy_prog{0..255}: Initial breakpoint, main at /PATH/TO/my_program.c:34\n</code></pre> <p>The line number at which the initial breakpoint is made (in the above example, line 34) corresponds to the line number at which MPI is initialised. You will not be able to see any parts of the code outside of the MPI region of a code with gdb4hpc.</p> <p>Once the code is loaded, you can use various commands to move through your code. The following lists and describes some of the most useful ones:</p> <ul> <li><code>help</code> -- Lists all gdb4hpc commands. You can run <code>help      COMMAND_NAME</code> to learn more about a specific command (e.g. <code>help      launch</code> will tell you about the launch command</li> <li><code>list</code> -- Will show the current line of code and the 9 lines      following. Repeated use of <code>list</code> will move you down the code in      ten-line chunks.</li> <li><code>next</code> -- Will jump to the next step in the program for each      process and output which line of code each process is one. It will      not enter subroutines. !!! note that there is no reverse-step in      gdb4hpc.</li> <li><code>step</code> -- Like <code>next</code>, but this will step into subroutines.</li> <li><code>up</code> -- Go up one level in the program (e.g. from a subroutine      back to main).</li> <li><code>print var</code> -- Prints the value of variable <code>var</code> at this point in      the code.</li> <li><code>watch var</code> -- Like print, but will print whenever a variable      changes value.</li> <li><code>quit</code> -- Exits gdb4hpc.</li> </ul> <p>Remember to exit the interactive session once you are done debugging.</p>"},{"location":"user-guide/debug/#attaching-with-gdb4hpc","title":"Attaching with gdb4hpc","text":"<p>Attaching to a hanging job using gdb4hpc is a great way of seeing which state each processor is in. However, this does not produce the most visually appealing results. For a more easy-to-read program, please take a look at the STAT tool.</p> <p>In your interactive session, launch your executable as a background task (by adding an <code>&amp;</code> at the end of the command). For example, if you are running an executable called <code>my_exe</code> using 256 processes, you would run:</p> <pre><code>srun -n 256 --nodes=2 --ntasks-per-node=128 --cpus-per-task=1 --time=01:00:00 --export=ALL \\\n            --account=[budget code] --partition=standard --qos=standard ./my_exe &amp;\n</code></pre> <p>Make sure to replace the <code>--account</code> input to your budget code (e.g. if you are using budget t01, that part should look like <code>--account=t01</code>).</p> <p>You will need to get the full job ID of the job you have just launched. To do this, run:</p> <pre><code>squeue -u $USER\n</code></pre> <p>and find the job ID associated with this interactive session -- this will be the one with the jobname <code>bash</code>. In this     example:</p> <pre><code>JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\n1050     workq my_mpi_j   jsindt  R       0:16      1 nid000001\n1051     workq     bash   jsindt  R       0:12      1 nid000002\n</code></pre> <p>the appropriate job id is 1051. Next, you will need to run <code>sstat</code> on this job id:</p> <pre><code>sstat 1051\n</code></pre> <p>This will output a large amount of information about this specific job. We are looking for the first number of this output, which should look like <code>JOB_ID.##</code> -- the number after the job ID is the number of slurm tasks performed in this interactive session. For our example (where <code>srun</code> is the first slurm task performed), the number is 1051.0.</p> <p>Launch <code>gdb4hpc</code>:</p> <pre><code>module load gdb4hpc\ngdb4hpc\n</code></pre> <p>You will get some information about this version of the program and, eventually, you will get a command prompt:</p> <pre><code>gdb4hpc 4.5 - Cray Line Mode Parallel Debugger\nWith Cray Comparative Debugging Technology.\nCopyright 2007-2019 Cray Inc. All Rights Reserved.\nCopyright 1996-2016 University of Queensland. All Rights Reserved.\nType \"help\" for a list of commands.\nType \"help &lt;cmd&gt;\" for detailed help about a command.\ndbg all&gt;\n</code></pre> <p>We will be using the <code>attach</code> command to attach to our program that hangs. This is done by writing:</p> <pre><code>dbg all&gt; attach $my_prog JOB_ID.##\n</code></pre> <p>where <code>JOB_ID.##</code> is the full job ID found using <code>sstat</code> (in our example, this would be 1051.0). The name <code>$my_prog</code> is a dummy-name -- it could be whatever name you like.</p> <p>As it is attaching, gdb4hpc will output text to screen that looks like:</p> <pre><code>Attaching to application, please wait...\nCreating MRNet communication network...\nWaiting for debug servers to attach to MRNet communications network...\nTimeout in 400 seconds. Please wait for the attach to complete.\nNumber of dbgsrvs connected: [0];  Timeout Counter: [1]\n\n...\n\nFinalizing setup...\nAttach complete.\nCurrent rank location:\n</code></pre> <p>After this, you will get an output that, among other things, tells you which line of your code each process is on, and what each process is doing. This can be helpful to see where the hang-up is.</p> <p>If you accidentally attached to the wrong job, you can detach by running:</p> <pre><code>dbg all&gt; release $my_prog\n</code></pre> <p>and re-attach with the correct job ID. You will need to change your dummy name from <code>$my_prog</code> to something else.</p> <p>When you are finished using <code>gbd4hpc</code>, simply run:</p> <pre><code>dbg all&gt; quit\n</code></pre> <p>Do not forget to exit your interactive session.</p>"},{"location":"user-guide/debug/#valgrind4hpc","title":"valgrind4hpc","text":"<p>valgrind4hpc is a Valgrind-based debugging tool to aid in the detection of memory leaks and errors in parallel applications. Valgrind4hpc aggregates any duplicate messages across ranks to help provide an understandable picture of program behavior. Valgrind4hpc manages starting and redirecting output from many copies of Valgrind, as well as recombining and filtering Valgrind messages. If your program can be debugged with Valgrind, it can be debugged with valgrind4hpc.</p> <p>The valgrind4hpc module enables the use of standard valgrind as well as the valgrind4hpc version more suitable to parallel programs.</p>"},{"location":"user-guide/debug/#using-valgrind-with-serial-programs","title":"Using Valgrind with serial programs","text":"<p>Launch <code>valgrind4hpc</code>:</p> <pre><code>module load valgrind4hpc\n</code></pre> <p>Next, run your executable through valgrind:</p> <pre><code>valgrind --tool=memcheck --leak-check=yes my_executable\n</code></pre> <p>The log outputs to screen. The <code>ERROR SUMMARY</code> will tell you whether, and how many, memory errors there are in your program. Furthermore, if you compile your code using the <code>-g</code> debugging flag (e.g. <code>gcc -g my_program.c -o my_executable.c</code>), the log will point out the code lines where the error occurs.</p> <p>Valgrind also includes a tool called Massif that can be used to give insight into the memory usage of your program. It takes regular snapshots and outputs this data into a single file, which can be visualised to show the total amount of memory used as a function of time. This shows when peaks and bottlenecks occur and allows you to identify which data structures in your code are responsible for the largest memory usage of your program.</p> <p>Documentation explaining how to use Massif is available at the official Massif manual. In short, you should run your executable as follows:</p> <pre><code>valgrind --tool=massif my_executable\n</code></pre> <p>The memory profiling data will be output into a file called <code>massif.out.pid</code>, where pid is the runtime process ID of your program. A custom filename can be chosen using the <code>--massif-out-file option</code>, as follows:</p> <pre><code>valgrind --tool=massif --massif-out-file=optional_filename.out my_executable\n</code></pre> <p>The output file contains raw profiling statistics. To view a summary including a graphical plot of memory usage over time, use the <code>ms_print</code> command as follows:</p> <pre><code>ms_print massif.out.12345\n</code></pre> <p>or, to save to a file:</p> <pre><code>ms_print massif.out.12345 &gt; massif.analysis.12345\n</code></pre> <p>This will show total memory usage over time as well as a breakdown of the top data structures contributing to memory usage at each snapshot where there has been a significant allocation or deallocation of memory.</p>"},{"location":"user-guide/debug/#using-valgrind4hpc-with-parallel-programs","title":"Using Valgrind4hpc with parallel programs","text":"<p>First, load <code>valgrind4hpc</code>:</p> <pre><code>module load valgrind4hpc\n</code></pre> <p>To run valgrind4hpc, first reserve the resources you will use with <code>salloc</code>. The following reservation request is for 2 nodes (256 physical cores) for 20 minutes on the short queue:</p> <pre><code>auser@uan01:&gt; salloc --nodes=2 --ntasks-per-node=128 --cpus-per-task=1 \\\n              --time=00:20:00 --partition=standard --qos=short \\\n              --hint=nomultithread \\\n              --distribution=block:block --account=[budget code]\n</code></pre> <p>Once your allocation is ready, Use valgrind4hpc to run and profile your executable. To test an executable called <code>my_executable</code> that requires two arguments <code>arg1</code> and <code>arg2</code> on 2 nodes and 256 processes, run:</p> <pre><code>valgrind4hpc --tool=memcheck --num-ranks=256 my_executable -- arg1 arg2\n</code></pre> <p>In particular, note the <code>--</code> separating the executable from the arguments (this is not necessary if your executable takes no arguments).</p> <p>Valgrind4hpc only supports certain tools found in valgrind. These are: memcheck, helgrind, exp-sgcheck, or drd. The <code>--valgrind-args=\"arguments\"</code> allows users to use valgrind options not supported in valgrind4hpc (e.g. <code>--leak-check</code>) -- note, however, that some of these options might interfere with valgrind4hpc.</p> <p>More information on valgrind4hpc can be found in the manual (<code>man valgrind4hpc</code>).</p>"},{"location":"user-guide/debug/#stat","title":"STAT","text":"<p>The Stack Trace Analysis Tool (STAT) is a cross-platform debugging tool from the University of Wisconsin-Madison. ATP is based on the same technology as STAT, both are designed to gather and merge stack traces from a running application's parallel processes. The STAT tool can be useful when application seems to be deadlocked or stuck, i.e. they don't crash but they don't progress as expected, and it has been designed to scale to a very large number of processes. Full information on STAT, including use cases, is available at the STAT website.</p> <p>STAT will attach to a running program and query that program to find out where all the processes in that program currently are. It will then process that data and produce a graph displaying the unique process locations (i.e. where all the processes in the running program currently are). To make this easily understandable it collates together all processes that are in the same place providing only unique program locations for display.</p>"},{"location":"user-guide/debug/#using-stat-on-archer2","title":"Using STAT on ARCHER2","text":"<p>On the login node, load the <code>cray-stat</code> module:</p> <pre><code>module load cray-stat\n</code></pre> <p>Then, launch your job using <code>srun</code> as a background task (by adding an <code>&amp;</code> at the end of the command). For example, if you are running an executable called <code>my_exe</code> using 256 processes, you would     run:</p> <pre><code>srun -n 256 --nodes=2 --ntasks-per-node=128 --cpus-per-task=1 --time=01:00:00  --export=ALL\\\n            --account=[budget code] --partition=standard --qos=standard./my_exe &amp;\n</code></pre> <p>Note</p> <p>This example has set the job time limit to 1 hour -- if you need longer, change the <code>--time</code> command.</p> <p>You will need the Program ID (PID) of the job you have just launched -- the PID is printed to screen upon launch, or you can get it by running:</p> <pre><code>ps -u $USER\n</code></pre> <p>This will present you with a set of text that looks like this:</p> <pre><code>PID TTY          TIME CMD\n154296 ?     00:00:00 systemd\n154297 ?     00:00:00 (sd-pam)\n154302 ?     00:00:00 sshd\n154303 pts/8 00:00:00 bash\n157150 pts/8 00:00:00 salloc\n157152 pts/8 00:00:00 bash\n157183 pts/8 00:00:00 srun\n157185 pts/8 00:00:00 srun\n157191 pts/8 00:00:00 ps\n</code></pre> <p>Once your application has reached the point where it hangs, issue the following command (replacing PID with the ID of the first srun task -- in the above example, I would replace PID with 157183):</p> <pre><code>stat-cl -i PID\n</code></pre> <p>You will get an output that looks like this:</p> <pre><code>STAT started at 2020-07-22-13:31:35\nAttaching to job launcher (null):157565 and launching tool daemons...\nTool daemons launched and connected!\nAttaching to application...\nAttached!\nApplication already paused... ignoring request to pause\nSampling traces...\nTraces sampled!\nResuming the application...\nResumed!\nPausing the application...\nPaused!\n\n...\n\nDetaching from application...\nDetached!\n\nResults written to $PATH_TO_RUN_DIRECTORY/stat_results/my_exe.0000\n</code></pre> <p>Once STAT is finished, you can kill the srun job using <code>scancel</code> (replacing JID with the job ID of the job you just launched):</p> <pre><code>scancel JID\n</code></pre> <p>You can view the results that STAT has produced using the following command (note that \"my_exe\" will need to be replaced with the name of the executable you  ran):</p> <pre><code>stat-view stat_results/my_exe.0000/00_my_exe.0000.3D.dot\n</code></pre> <p>This produces a graph displaying all the different places within the program that the parallel processes were when you queried them.</p> <p>Note</p> <p>To see the graph, you will need to have exported your X display when logging in.</p> <p>Larger jobs may spend significant time queueing, requiring submission as a batch job. In this case, a slightly different invocation is illustrated as follows:</p> <pre><code>#!/bin/bash --login\n\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=02:00:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load additional modules\nmodule load cray-stat\n\nexport OMP_NUM_THREADS=1\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# This environment variable is required\nexport CTI_SLURM_OVERRIDE_MC=1\n\n# Request that stat sleeps for 3600 seconds before attaching\n# to our executable which we launch with command introduced\n# with -C:\n\nstat-cl -s 3600 -C srun --unbuffered ./my_exe\n</code></pre> <p>If the job is hanging it will continue to run until the wall clock exceeds the requested time. Use the <code>stat-view</code> utility to inspect the results, as discussed above.</p>"},{"location":"user-guide/debug/#atp","title":"ATP","text":"<p>To enable ATP you should load the atp module and set the <code>ATP_ENABLED</code> environment variable to 1 on the login node:</p> <pre><code>module load atp\nexport ATP_ENABLED=1\n</code></pre> <p>Then, launch your job using <code>srun</code> as a background task (by adding an <code>&amp;</code> at the end of the command). For example, if you are running an executable called <code>my_exe</code> using 256 processes, you would     run:</p> <pre><code>srun -n=256 --nodes=2 --ntasks-per-node=128 --cpus-per-task=1 --time=01:00:00 --export=ALL \\\n            --account=[budget code] --partition=standard --qos=standard ./my_exe &amp;\n</code></pre> <p>Note</p> <p>This example has set the job time limit to 1 hour -- if you need longer, change the <code>--time</code> command.</p> <p>Once the job has finished running, load the <code>stat</code> module to view the results:</p> <pre><code>module load cray-stat\n</code></pre> <p>and view the merged stack trace using:</p> <pre><code>stat-view atpMergedBT.dot\n</code></pre> <p>Note</p> <p>To see the graph, you will need to have exported your X display when logging in.</p>"},{"location":"user-guide/dev-environment-4cab/","title":"Application development environment: 4-cabinet system","text":"<p>Important</p> <p>This section covers the application development environment on the initial, 4-cabinet ARCHER2 system. For docmentation on the application development environment on the full ARCHER2 system, please see Application development environment: full system.</p>"},{"location":"user-guide/dev-environment-4cab/#whats-available","title":"What's available","text":"<p>ARCHER2 runs on the Cray Linux Environment (a version of SUSE Linux), and provides a development environment which includes:</p> <ul> <li>Software modules via a standard module framework</li> <li>Three different compiler environments (AMD, Cray, and GNU)</li> <li>MPI, OpenMP, and SHMEM</li> <li>Scientific and numerical libraries</li> <li>Parallel Python and R</li> <li>Parallel debugging and profiling</li> <li>Singularity containers</li> </ul> <p>Access to particular software, and particular versions, is managed by a standard TCL module framework. Most software is available via standard software modules and the different programming environments are available via module collections.</p> <p>You can see what programming environments are available with:</p> <pre><code>auser@uan01:~&gt; module savelist\nNamed collection list:\n 1) PrgEnv-aocc   2) PrgEnv-cray   3) PrgEnv-gnu\n</code></pre> <p>Other software modules can be listed with</p> <pre><code>auser@uan01:~&gt; module avail\n------------------------------- /opt/cray/pe/perftools/20.09.0/modulefiles --------------------------------\nperftools       perftools-lite-events  perftools-lite-hbm    perftools-nwpc     \nperftools-lite  perftools-lite-gpu     perftools-lite-loops  perftools-preload  \n\n---------------------------------- /opt/cray/pe/craype/2.7.0/modulefiles ----------------------------------\ncraype-hugepages1G  craype-hugepages8M   craype-hugepages128M  craype-network-ofi          \ncraype-hugepages2G  craype-hugepages16M  craype-hugepages256M  craype-network-slingshot10  \ncraype-hugepages2M  craype-hugepages32M  craype-hugepages512M  craype-x86-rome             \ncraype-hugepages4M  craype-hugepages64M  craype-network-none   \n\n------------------------------------- /usr/local/Modules/modulefiles --------------------------------------\ndot  module-git  module-info  modules  null  use.own  \n\n-------------------------------------- /opt/cray/pe/cpe-prgenv/7.0.0 --------------------------------------\ncpe-aocc  cpe-cray  cpe-gnu  \n\n-------------------------------------------- /opt/modulefiles ---------------------------------------------\naocc/2.1.0.3(default)  cray-R/4.0.2.0(default)  gcc/8.1.0  gcc/9.3.0  gcc/10.1.0(default)  \n\n\n---------------------------------------- /opt/cray/pe/modulefiles -----------------------------------------\natp/3.7.4(default)              cray-mpich-abi/8.0.15             craype-dl-plugin-py3/20.06.1(default)  \ncce/10.0.3(default)             cray-mpich-ucx/8.0.15             craype/2.7.0(default)                  \ncray-ccdb/4.7.1(default)        cray-mpich/8.0.15(default)        craypkg-gen/1.3.10(default)            \ncray-cti/2.7.3(default)         cray-netcdf-hdf5parallel/4.7.4.0  gdb4hpc/4.7.3(default)                 \ncray-dsmml/0.1.2(default)       cray-netcdf/4.7.4.0               iobuf/2.0.10(default)                  \ncray-fftw/3.3.8.7(default)      cray-openshmemx/11.1.1(default)   papi/6.0.0.2(default)                  \ncray-ga/5.7.0.3                 cray-parallel-netcdf/1.12.1.0     perftools-base/20.09.0(default)        \ncray-hdf5-parallel/1.12.0.0     cray-pmi-lib/6.0.6(default)       valgrind4hpc/2.7.2(default)            \ncray-hdf5/1.12.0.0              cray-pmi/6.0.6(default)           \ncray-libsci/20.08.1.2(default)  cray-python/3.8.5.0(default)      \n</code></pre> <p>A full discussion of the module system is available in the Software environment section.</p> <p>A consistent set of modules is loaded on login to the machine (currently <code>PrgEnv-cray</code>, see below). Developing applications then means selecting and loading the appropriate set of modules before starting work.</p> <p>This section is aimed at code developers and will concentrate on the compilation environment and building libraries and executables, and specifically parallel executables. Other topics such as Python and Containers are covered in more detail in separate sections of the documentation.</p>"},{"location":"user-guide/dev-environment-4cab/#managing-development","title":"Managing development","text":"<p>ARCHER2 supports common revision control software such as <code>git</code>.</p> <p>Standard GNU autoconf tools are available, along with <code>make</code> (which is GNU Make). Versions of <code>cmake</code> are available.</p> <p>Note</p> <p>Some of these tools are part of the system software, and typically reside in <code>/usr/bin</code>, while others are provided as part of the module system. Some tools may be available in different versions via both <code>/usr/bin</code> and via the module system.</p>"},{"location":"user-guide/dev-environment-4cab/#compilation-environment","title":"Compilation environment","text":"<p>There are three different compiler environments available on ARCHER2: AMD (AOCC), Cray (CCE), and GNU (GCC). The current compiler suite is selected via the programming environment, while the specific compiler versions are determined by the relevant compiler module. A summary is:</p> Suite name Module Programming environment collection CCE <code>cce</code> <code>PrgEnv-cray</code> GCC <code>gcc</code> <code>PrgEnv-gnu</code> AOCC <code>aocc</code> <code>PrgEnv-aocc</code> <p>For example, at login, the default set of modules are:</p> <pre><code>Currently Loaded Modulefiles:\n1) cpe-cray                          7) cray-dsmml/0.1.2(default)                           \n2) cce/10.0.3(default)               8) perftools-base/20.09.0(default)                     \n3) craype/2.7.0(default)             9) xpmem/2.2.35-7.0.1.0_1.3__gd50fabf.shasta(default)  \n4) craype-x86-rome                  10) cray-mpich/8.0.15(default)                          \n5) libfabric/1.11.0.0.233(default)  11) cray-libsci/20.08.1.2(default)                      \n6) craype-network-ofi  \n</code></pre> <p>from which we see the default programming environment is Cray (indicated by <code>cpe-cray</code> (at 1 in the list above) and the default compiler module is <code>cce/10.0.3</code> (at 2 in the list above). The programming environment will give access to a consistent set of compiler, MPI library via <code>cray-mpich</code> (at 10), and other libraries e.g., <code>cray-libsci</code> (at 11 in the list above) infrastructure.</p> <p>Within a given programming environment, it is possible to swap to a different compiler version by swapping the relevant compiler module.</p> <p>To ensure consistent behaviour, compilation of C, C++, and Fortran source code should then take place using the appropriate compiler wrapper: <code>cc</code>, <code>CC</code>, and <code>ftn</code>, respectively. The wrapper will automatically call the relevant underlying compiler and add the appropriate include directories and library locations to the invocation. This typically eliminates the need to specify this additional information explicitly in the configuration stage. To see the details of the exact compiler invocation use the <code>-craype-verbose</code> flag to the compiler wrapper.</p> <p>The default link time behaviour is also related to the current programming environment. See the section below on Linking and libraries.</p> <p>Users should not, in general, invoke specific compilers at compile/link stages. In particular, <code>gcc</code>, which may default to <code>/usr/bin/gcc</code>, should not be used. The compiler wrappers <code>cc</code>, <code>CC</code>, and <code>ftn</code> should be used via the appropriate module. Other common MPI compiler wrappers e.g., <code>mpicc</code> should also be replaced by the relevant wrapper <code>cc</code> (<code>mpicc</code> etc are not available).</p> <p>Important</p> <p>Always use the compiler wrappers <code>cc</code>, <code>CC</code>, and/or <code>ftn</code> and not a specific compiler invocation. This will ensure consistent compile/link time behaviour.</p>"},{"location":"user-guide/dev-environment-4cab/#compiler-man-pages-and-help","title":"Compiler man pages and help","text":"<p>Further information on both the compiler wrappers, and the individual compilers themselves are available via the command line, and via standard <code>man</code> pages. The <code>man</code> page for the compiler wrappers is common to all programming environments, while the <code>man</code> page for individual compilers depends on the currently loaded programming environment. The following table summarises options for obtaining information on the compiler and compile options:</p> Compiler suite C C++ Fortran Cray <code>man craycc</code> <code>man crayCC</code> <code>man crayftn</code> GNU <code>man gcc</code> <code>man g++</code> <code>man gfortran</code> Wrappers <code>man cc</code> <code>man CC</code> <code>man ftn</code> <p>Tip</p> <p>You can also pass the <code>--help</code> option to any of the compilers or wrappers to get a summary of how to use them. The Cray Fortran compiler uses <code>ftn --craype-help</code> to access the help options.</p> <p>Tip</p> <p>There are no <code>man</code> pages for the AOCC compilers at the moment.</p> <p>Tip</p> <p>Cray C/C++ is based on Clang and therefore supports similar options to clang/gcc (<code>man clang</code> is in fact equivalent to <code>man craycc</code>). <code>clang --help</code> will produce a full summary of options with Cray-specific options marked \"Cray\". The <code>craycc</code> man page concentrates on these Cray extensions to the <code>clang</code> front end and does not provide an exhaustive description of all <code>clang</code> options. Cray Fortran is not based on Flang and so takes different options from flang/gfortran.</p>"},{"location":"user-guide/dev-environment-4cab/#dynamic-linking","title":"Dynamic Linking","text":"<p>Executables on ARCHER2 link dynamically, and the Cray Programming Environment does not currently support static linking. This is in contrast to ARCHER where the default was to build statically.</p> <p>If you attempt to link statically, you will see errors similar to:</p> <pre><code>/usr/bin/ld: cannot find -lpmi\n/usr/bin/ld: cannot find -lpmi2\ncollect2: error: ld returned 1 exit status\n</code></pre> <p>The compiler wrapper scripts on ARCHER link runtime libraries in using the <code>runpath</code> by default. This means that the paths to the runtime libraries are encoded into the executable so you do not need to load the compiler environment in your job submission scripts.</p>"},{"location":"user-guide/dev-environment-4cab/#which-compiler-environment","title":"Which compiler environment?","text":"<p>If you are unsure which compiler you should choose, we suggest the starting point should be the GNU compiler collection (GCC, <code>PrgEnv-gnu</code>); this is perhaps the most commonly used by code developers, particularly in the open source software domain. A portable, standard-conforming code should (in principle) compile in any of the three programming environments.</p> <p>For users requiring specific compiler features, such as co-array Fortran, the recommended starting point would be Cray. The following sections provide further details of the different programming environments.</p> <p>Warning</p> <p>Intel compilers are not available on ARCHER2.</p>"},{"location":"user-guide/dev-environment-4cab/#amd-optimizing-cc-compiler-aocc","title":"AMD Optimizing C/C++ Compiler (AOCC)","text":"<p>The AMD Optimizing C/++ Compiler (AOCC) is a clang-based optimising compiler. AOCC (despite its name) includes a flang-based Fortran compiler.</p> <p>Switch the the AOCC programming environment via</p> <pre><code>$ module restore PrgEnv-aocc\n</code></pre> <p>Note</p> <p>Further details on AOCC will appear here as they become available.</p>"},{"location":"user-guide/dev-environment-4cab/#aocc-reference-material","title":"AOCC reference material","text":"<ul> <li>AMD website https://developer.amd.com/amd-aocc/</li> </ul>"},{"location":"user-guide/dev-environment-4cab/#cray-compiler-environment-cce","title":"Cray compiler environment (CCE)","text":"<p>The Cray compiler environment (CCE) is the default compiler at the point of login. CCE supports C/C++ (along with unified parallel C UPC), and Fortran (including co-array Fortran). Support for OpenMP parallelism is available for both C/C++ and Fortran (currently OpenMP 4.5, with a number of exceptions).</p> <p>The Cray C/C++ compiler is based on a clang front end, and so compiler options are similar to those for gcc/clang. However, the Fortran compiler remains based around Cray-specific options. Be sure to separate C/C++ compiler options and Fortran compiler options (typically <code>CFLAGS</code> and <code>FFLAGS</code>) if compiling mixed C/Fortran applications.</p> <p>Switch the the Cray programming environment via</p> <pre><code>$ module restore PrgEnv-cray\n</code></pre>"},{"location":"user-guide/dev-environment-4cab/#useful-cce-cc-options","title":"Useful CCE C/C++ options","text":"<p>When using the compiler wrappers <code>cc</code> or <code>CC</code>, some of the following options may be useful:</p> <p>Language, warning, Debugging options:</p> Option Comment <code>-std=&lt;standard&gt;</code> Default is <code>-std=gnu11</code> (<code>gnu++14</code> for C++) [1] <p>Performance options:</p> Option Comment <code>-Ofast</code> Optimisation levels: -O0, -O1, -O2, -O3, -Ofast <code>-ffp=level</code> Floating point maths optimisations levels 0-4 [2] <code>-flto</code> Link time optimisation <p>Miscellaneous options:</p> Option Comment <code>-fopenmp</code> Compile OpenMP (default is off) <code>-v</code> Display verbose output from compiler stages <p>Notes</p> <ol> <li>Option <code>-std=gnu11</code> gives <code>c11</code> plus GNU extensions (likewise     <code>c++14</code> plus GNU extensions). See     https://gcc.gnu.org/onlinedocs/gcc-4.8.2/gcc/C-Extensions.html</li> <li>Option <code>-ffp=3</code> is implied by <code>-Ofast</code> or <code>-ffast-math</code></li> </ol>"},{"location":"user-guide/dev-environment-4cab/#useful-cce-fortran-options","title":"Useful CCE Fortran options","text":"<p>Language, Warning, Debugging options:</p> Option Comment <code>-m &lt;level&gt;</code> Message level (default <code>-m 3</code> errors and warnings) <p>Performance options:</p> Option Comment <code>-O &lt;level&gt;</code> Optimisation levels: -O0 to -O3 (default -O2) <code>-h fp&lt;level&gt;</code> Floating point maths optimisations levels 0-3 <code>-h ipa</code> Inter-procedural analysis <p>Miscellaneous options:</p> Option Comment <code>-h omp</code> Compile OpenMP (default is <code>-hnoomp</code>) <code>-v</code> Display verbose output from compiler stages"},{"location":"user-guide/dev-environment-4cab/#gnu-compiler-collection-gcc","title":"GNU compiler collection (GCC)","text":"<p>The commonly used open source GNU compiler collection is available and provides C/C++ and Fortran compilers.</p> <p>The GNU compiler collection is loaded by switching to the GNU programming environment:</p> <pre><code>$ module restore PrgEnv-gnu\n</code></pre> <p>Bug</p> <p>The <code>gcc/8.1.0</code> module is available on ARCHER2 but cannot be used as the supporting scientific and system libraries are not available. You should not use this version of GCC.</p> <p>Warning</p> <p>If you want to use GCC version 10 or greater to compile Fortran code, with the old MPI interfaces (i.e. <code>use mpi</code> or <code>INCLUDE 'mpif.h'</code>) you must add the <code>-fallow-argument-mismatch</code> option (or equivalent) when compiling otherwise you will see compile errors associated with MPI functions. The reason for this is that past versions of <code>gfortran</code> have allowed mismatched arguments to external procedures (e.g., where an explicit interface is not available). This is often the case for MPI routines using the old MPI interfaces where arrays of different types are passed to, for example, <code>MPI_Send()</code>. This will now generate an error as not standard conforming. The <code>-fallow-argument-mismatch</code> option is used to reduce the error to a warning. The same effect may be achieved via <code>-std=legacy</code>.</p> <p>If you use the Fortran 2008 MPI interface (i.e. <code>use mpi_f08</code>) then you should not need to add this option.</p> <p>Fortran language MPI bindings are described in more detail at in the MPI Standard documentation.</p>"},{"location":"user-guide/dev-environment-4cab/#useful-gnu-fortran-options","title":"Useful Gnu Fortran options","text":"Option Comment <code>-std=&lt;standard&gt;</code> Default is gnu <code>-fallow-argument-mismatch</code> Allow mismatched procedure arguments. This argument is required for compiling MPI Fortran code with GCC version 10 or greater if you are using the older MPI interfaces (see warning above) <code>-fbounds-check</code> Use runtime checking of array indices <code>-fopenmp</code> Compile OpenMP (default is no OpenMP) <code>-v</code> Display verbose output from compiler stages <p>Tip</p> <p>The <code>standard</code> in <code>-std</code> may be one of <code>f95</code> <code>f2003</code>, <code>f2008</code> or <code>f2018</code>. The default option <code>-std=gnu</code> is the latest Fortran standard plus gnu extensions.</p> <p>Warning</p> <p>Past versions of <code>gfortran</code> have allowed mismatched arguments to external procedures (e.g., where an explicit interface is not available). This is often the case for MPI routines where arrays of different types are passed to <code>MPI_Send()</code> and so on. This will now generate an error as not standard conforming. Use <code>-fallow-argument-mismatch</code> to reduce the error to a warning. The same effect may be achieved via <code>-std=legacy</code>.</p>"},{"location":"user-guide/dev-environment-4cab/#reference-material","title":"Reference material","text":"<ul> <li> <p>C/C++ documentation https://gcc.gnu.org/onlinedocs/gcc-9.3.0/gcc/</p> </li> <li> <p>Fortran documentation https://gcc.gnu.org/onlinedocs/gcc-9.3.0/gfortran/</p> </li> </ul>"},{"location":"user-guide/dev-environment-4cab/#message-passing-interface-mpi","title":"Message passing interface (MPI)","text":""},{"location":"user-guide/dev-environment-4cab/#hpe-cray-mpich","title":"HPE Cray MPICH","text":"<p>HPE Cray provide, as standard, an MPICH implementation of the message passing interface which is specifically optimised for the ARCHER2 network. The current implementation supports MPI standard version 3.1.</p> <p>The HPE Cray MPICH implementation is linked into software by default when compiling using the standard wrapper scripts: <code>cc</code>, <code>CC</code> and <code>ftn</code>.</p>"},{"location":"user-guide/dev-environment-4cab/#mpi-reference-material","title":"MPI reference material","text":"<p>MPI standard documents: https://www.mpi-forum.org/docs/</p>"},{"location":"user-guide/dev-environment-4cab/#linking-and-libraries","title":"Linking and libraries","text":"<p>Linking to libraries is performed dynamically on ARCHER2. One can use the <code>-craype-verbose</code> flag to the compiler wrapper to check exactly what linker arguments are invoked. The compiler wrapper scripts encode the paths to the programming environment system libraries using RUNPATH. This ensures that the executable can find the correct runtime libraries without the matching software modules loaded.</p> <p>The library RUNPATH associated with an executable can be inspected via, e.g.,</p> <pre><code>$ readelf -d ./a.out\n</code></pre> <p>(swap <code>a.out</code> for the name of the executable you are querying).</p>"},{"location":"user-guide/dev-environment-4cab/#commonly-used-libraries","title":"Commonly used libraries","text":"<p>Modules with names prefixed by <code>cray-</code> are provided by HPE Cray, and are supported to be consistent with any of the programming environments and associated compilers. These modules should be the first choice for access to software libraries if available.</p> <p>Tip</p> <p>More information on the different software libraries on ARCHER2 can be found in the Software libraries section of the user guide.</p>"},{"location":"user-guide/dev-environment-4cab/#switching-to-a-different-hpe-cray-programming-environment-release","title":"Switching to a different HPE Cray Programming Environment release","text":"<p>Important</p> <p>See the section below on using non-default versions of HPE Cray libraries below as this process will generally need to be followed when using software from non-default PE installs.</p> <p>Access to non-default PE environments is controlled by the use of the <code>cpe</code> modules. These modules are typically loaded after you have restored a PrgEnv and loaded all the other modules you need and will  set your compile environment to match that in the other PE release. This means:</p> <ul> <li>The compiler version will be switched to the one from the selected PE</li> <li>HPE Cray provided libraries (or modules) that are loaded before you switch   to the new programming environment are switched to those from the programming   environment that you select.</li> </ul> <p>For example, if you have a code that uses the Gnu programming environment, FFTW and NetCDF parallel libraries and you want to compile in the (non-default) 21.03 programming environment, you would do the following:</p> <p>First, restore the Gnu programming environment and load the required library modules (FFTW and NetCDF HDF5 parallel). The loaded module list shows they  are the versions from the default (20.10) programming environment):</p> <pre><code>auser@uan02:/work/t01/t01/auser&gt; module restore -s PrgEnv-gnu\nauser@uan02:/work/t01/t01/auser&gt; module load cray-fftw\nauser@uan02:/work/t01/t01/auser&gt; module load cray-netcdf\nauser@uan02:/work/t01/t01/auser&gt; module load cray-netcdf-hdf5parallel\nauser@uan02:/work/t01/t01/auser&gt; module list\nCurrently Loaded Modulefiles:\n 1) cpe-gnu                           9) xpmem/2.2.35-7.0.1.0_1.9__gd50fabf.shasta(default)               \n 2) gcc/10.1.0(default)              10) cray-mpich/8.0.16(default)                                       \n 3) craype/2.7.2(default)            11) cray-libsci/20.10.1.2(default)                                   \n 4) craype-x86-rome                  12) bolt/0.7                                                         \n 5) libfabric/1.11.0.0.233(default)  13) /work/y07/shared/archer2-modules/modulefiles-cse/epcc-setup-env  \n 6) craype-network-ofi               14) /usr/local/share/epcc-module/epcc-module-loader                  \n 7) cray-dsmml/0.1.2(default)        15) cray-fftw/3.3.8.8(default)                                       \n 8) perftools-base/20.10.0(default)  16) cray-netcdf-hdf5parallel/4.7.4.2(default) \n</code></pre> <p>Now, load the <code>cpe/21.03</code> programming environment module to switch all the currently loaded HPE Cray modules from the default (20.10) programming environment version to the 21.03 programming environment versions:</p> <pre><code>auser@uan02:/work/t01/t01/auser&gt; module load cpe/21.03\nSwitching to cray-dsmml/0.1.3.\nSwitching to cray-fftw/3.3.8.9.\nSwitching to cray-libsci/21.03.1.1.\nSwitching to cray-mpich/8.1.3.\nSwitching to cray-netcdf-hdf5parallel/4.7.4.3.\nSwitching to craype/2.7.5.\nSwitching to gcc/9.3.0.\nSwitching to perftools-base/21.02.0.\n\nLoading cpe/21.03\n  Unloading conflict: cray-dsmml/0.1.2 cray-fftw/3.3.8.8 cray-libsci/20.10.1.2 cray-mpich/8.0.16 cray-netcdf-hdf5parallel/4.7.4.2\n    craype/2.7.2 gcc/10.1.0 perftools-base/20.10.0\n  Loading requirement: cray-dsmml/0.1.3 cray-fftw/3.3.8.9 cray-libsci/21.03.1.1 cray-mpich/8.1.3 cray-netcdf-hdf5parallel/4.7.4.3\n    craype/2.7.5 gcc/9.3.0 perftools-base/21.02.0\nauser@uan02:/work/t01/t01/auser&gt; module list\nCurrently Loaded Modulefiles:\n 1) cpe-gnu                                                           9) cray-dsmml/0.1.3                  17) cpe/21.03(default)  \n 2) craype-x86-rome                                                  10) cray-fftw/3.3.8.9                 \n 3) libfabric/1.11.0.0.233(default)                                  11) cray-libsci/21.03.1.1             \n 4) craype-network-ofi                                               12) cray-mpich/8.1.3                  \n 5) xpmem/2.2.35-7.0.1.0_1.9__gd50fabf.shasta(default)               13) cray-netcdf-hdf5parallel/4.7.4.3  \n 6) bolt/0.7                                                         14) craype/2.7.5                      \n 7) /work/y07/shared/archer2-modules/modulefiles-cse/epcc-setup-env  15) gcc/9.3.0                         \n 8) /usr/local/share/epcc-module/epcc-module-loader                  16) perftools-base/21.02.0   \n</code></pre> <p>Finally (as noted above), you will need to modify the value of <code>LD_LIBRARY_PATH</code> before you compile your software to ensure it picks up the non-default versions of libraries:</p> <pre><code>auser@uan02:/work/t01/t01/auser&gt; export LD_LIBRARY_PATH=$CRAY_LD_LIBRARY_PATH:$LD_LIBRARY_PATH\n</code></pre> <p>Now you can go ahead and compile your software with the new programming environment.</p> <p>Important</p> <p>The <code>cpe</code> modules only change the versions of software modules provided as part of the HPE Cray programming environments. Any modules provided by the ARCHER2 service will need to be loaded manually after you have completed the process described above.</p> <p>Note</p> <p>Unloading the <code>cpe</code> module does not restore the original programming environment release. To restore the default programming environment release you should log  out and then log back in to ARCHER2.</p> <p>Bug</p> <p>The <code>cpe/21.03</code> module has a known issue with <code>PrgEnv-gnu</code> where it loads an old version of GCC (9.3.0) rather than the correct, newer version (10.2.0). You can resolve this by using the sequence: <pre><code>module restore -s PrgEnv-gnu\n...load any other modules you need...\nmodule load cpe/21.03\nmodule unload cpe/21.03\nmodule swap gcc gcc/10.2.0\n</code></pre></p>"},{"location":"user-guide/dev-environment-4cab/#available-hpe-cray-programming-environment-releases-on-archer2","title":"Available HPE Cray Programming Environment releases on ARCHER2","text":"<p>ARCHER2 currently has the following HPE Cray Programming Environment releases available:</p> <ul> <li>20.08: not available via <code>cpe</code> module</li> <li>20.10: Current default</li> <li>21.03: available via <code>cpe/21.03</code> module</li> </ul> <p>Tip</p> <p>You can see which programming environment release you currently have loaded  by using <code>module list</code> and looking at the version number of the <code>cray-libsci</code> module you have loaded. The first two numbers indicate the version of the PE you have loaded. For example, if you have <code>cray-libsci/20.10.1.2</code> loaded then you are using the 20.10 PE release.</p>"},{"location":"user-guide/dev-environment-4cab/#using-non-default-versions-of-hpe-cray-libraries-on-archer2","title":"Using non-default versions of HPE Cray libraries on ARCHER2","text":"<p>If you wish to make use of non-default versions of libraries provided by HPE Cray (usually because they are part of a non-default PE release: either old or new) then you need to make changes at both compile and runtime. In summary, you need to load the correct module and also make changes to the <code>LD_LIBRARY_PATH</code> environment variable.</p> <p>At compile time you need to load the version of the library module before you compile and set the LD_LIBRARY_PATH environment variable to include the contencts of <code>$CRAY_LD_LIBRARY_PATH</code> as the first entry. For example, to use the, non-default, 20.08.1.2 version of HPE Cray LibSci in the default programming environment (Cray Compiler Environment, CCE) you would first setup the environment to compile with:</p> <pre><code>auser@uan01:~/test/libsci&gt; module swap cray-libsci cray-libsci/20.08.1.2 \nauser@uan01:~/test/libsci&gt; export LD_LIBRARY_PATH=$CRAY_LD_LIBRARY_PATH:$LD_LIBRARY_PATH\n</code></pre> <p>The order is important here: every time you change a module, you will need to reset the value of <code>LD_LIBRARY_PATH</code> for the process to work (it will not be updated automatically).</p> <p>Now you can compile your code. You can check that the executable is using the correct version  of LibSci with the <code>ldd</code> command and look for the line beginning <code>libsci_cray.so.5</code>, you should see the version in the path to the library file:</p> <pre><code>auser@uan01:~/test/libsci&gt; ldd dgemv.x \n    linux-vdso.so.1 (0x00007ffe4a7d2000)\n    libsci_cray.so.5 =&gt; /opt/cray/pe/libsci/20.08.1.2/CRAY/9.0/x86_64/lib/libsci_cray.so.5 (0x00007fafd6a43000)\n    libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007fafd683f000)\n    libxpmem.so.0 =&gt; /opt/cray/xpmem/default/lib64/libxpmem.so.0 (0x00007fafd663c000)\n    libquadmath.so.0 =&gt; /opt/cray/pe/cce/10.0.4/cce/x86_64/lib/libquadmath.so.0 (0x00007fafd63fc000)\n    libmodules.so.1 =&gt; /opt/cray/pe/cce/10.0.4/cce/x86_64/lib/libmodules.so.1 (0x00007fafd61e0000)\n    libfi.so.1 =&gt; /opt/cray/pe/cce/10.0.4/cce/x86_64/lib/libfi.so.1 (0x00007fafd5abe000)\n    libcraymath.so.1 =&gt; /opt/cray/pe/cce/10.0.4/cce/x86_64/lib/libcraymath.so.1 (0x00007fafd57e2000)\n    libf.so.1 =&gt; /opt/cray/pe/cce/10.0.4/cce/x86_64/lib/libf.so.1 (0x00007fafd554f000)\n    libu.so.1 =&gt; /opt/cray/pe/cce/10.0.4/cce/x86_64/lib/libu.so.1 (0x00007fafd523b000)\n    libcsup.so.1 =&gt; /opt/cray/pe/cce/10.0.4/cce/x86_64/lib/libcsup.so.1 (0x00007fafd5035000)\n    libstdc++.so.6 =&gt; /opt/cray/pe/gcc-libs/libstdc++.so.6 (0x00007fafd4c62000)\n    libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007fafd4a43000)\n    libc.so.6 =&gt; /lib64/libc.so.6 (0x00007fafd4688000)\n    libm.so.6 =&gt; /lib64/libm.so.6 (0x00007fafd4350000)\n    /lib64/ld-linux-x86-64.so.2 (0x00007fafda988000)\n    librt.so.1 =&gt; /lib64/librt.so.1 (0x00007fafd4148000)\n    libgfortran.so.5 =&gt; /opt/cray/pe/gcc-libs/libgfortran.so.5 (0x00007fafd3c92000)\n    libgcc_s.so.1 =&gt; /opt/cray/pe/gcc-libs/libgcc_s.so.1 (0x00007fafd3a7a000)\n</code></pre> <p>Tip</p> <p>If any of the libraries point to versions in the <code>/opt/cray/pe/lib64</code> directory then these are using the default versions of the libraries rather than the  specific versions. This happens at compile time if you have forgotton to load  the right module and set <code>$LD_LIBRARY_PATH</code> afterwards.</p> <p>At run time (typically in your job script) you need to repeat the environment setup steps (you can also use the <code>ldd</code> command in your job submission script to  check the library is pointing to the correct version). For example, a job submission script to run our <code>dgemv.x</code> executable with the non-default version of LibSci could look like:</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=dgemv\n#SBATCH --time=0:20:0\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=1\n\n# Replace the account code, partition and QoS with those you wish to use\n#SBATCH --account=t01        \n#SBATCH --partition=standard\n#SBATCH --qos=short\n#SBATCH --reservation=shortqos\n\n# Load the standard environment module\nmodule load epcc-job-env\n\n# Setup up the environment to use the non-default version of LibSci\n#   We use \"module swap\" as the \"cray-libsci\" is loaded by default.\n#   This must be done after loading the \"epcc-job-env\" module\nmodule swap cray-libsci cray-libsci/20.08.1.2\nexport LD_LIBRARY_PATH=$CRAY_LD_LIBRARY_PATH:$LD_LIBRARY_PATH\n\n# Check which library versions the executable is pointing too\nldd dgemv.x\n\nexport OMP_NUM_THREADS=1\n\nsrun --hint=nomultithread --distribution=block:block dgemv.x\n</code></pre> <p>Tip</p> <p>As when compiling, the order of commands matters. Setting the value of <code>LD_LIBRARY_PATH</code> must happen after you have finished all your <code>module</code> commands for it to have the correct effect.</p> <p>Important</p> <p>You must setup the environment at both compile and run time otherwise you will end up using the default version of the library.</p>"},{"location":"user-guide/dev-environment-4cab/#compiling-in-compute-nodes","title":"Compiling in compute nodes","text":"<p>Sometimes you may wish to compile in a batch job. For example, the compile process may take a long time or the compile process is part of the research workflow and can be coupled to the production job. Unlike login nodes, the <code>/home</code> file system is not available.</p> <p>An example job submission script for a compile job using <code>make</code> (assuming the Makefile is in the same directory as the job submission script) would be:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=compile\n#SBATCH --time=00:20:00\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=1\n\n# Replace the account code, partition and QoS with those you wish to use\n#SBATCH --account=t01        \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the compilation environment (cray, gnu or aocc)\nmodule restore /etc/cray-pe.d/PrgEnv-cray\n\nmake clean\n\nmake\n</code></pre> <p>Warning</p> <p>Do not forget to include the full path when the compilation environment is restored. For instance:</p> <p><code>module restore /etc/cray-pe.d/PrgEnv-cray</code></p> <p>You can also use a compute node in an interactive way using <code>salloc</code>. Please see Section Using salloc to reserve resources for further details. Once your interactive session is ready, you can load the compilation environment and compile the code.</p>"},{"location":"user-guide/dev-environment-4cab/#build-instructions-for-software-on-archer2","title":"Build instructions for software on ARCHER2","text":"<p>The ARCHER2 CSE team at EPCC and other contributors provide build configurations ando instructions for a range of research software, software libraries and tools on a variety of HPC systems (including ARCHER2) in a public Github repository. See:</p> <ul> <li>Build instructions repository</li> </ul> <p>The repository always welcomes contributions from the ARCHER2 user community.</p>"},{"location":"user-guide/dev-environment-4cab/#support-for-building-software-on-archer2","title":"Support for building software on ARCHER2","text":"<p>If you run into issues building software on ARCHER2 or the software you require is not available then please contact the ARCHER2 Service Desk with any questions you have.</p>"},{"location":"user-guide/dev-environment/","title":"Application development environment","text":""},{"location":"user-guide/dev-environment/#whats-available","title":"What's available","text":"<p>ARCHER2 runs the HPE Cray Linux Environment (a version of SUSE Linux), and provides a development environment which includes:</p> <ul> <li>Software modules via a standard module framework</li> <li>Three different compiler environments (AMD, Cray, and GNU)</li> <li>MPI, OpenMP, and SHMEM</li> <li>Scientific and numerical libraries</li> <li>Parallel Python and R</li> <li>Parallel debugging and profiling</li> <li>Singularity containers</li> </ul> <p>Access to particular software, and particular versions, is managed by an  Lmod module framework. Most software is available by loading modules, including the different compiler environments</p> <p>You can see what compiler environments are available with:</p> <pre><code>auser@uan01:~&gt; module avail PrgEnv\n\n--------------------------------------- /opt/cray/pe/lmod/modulefiles/core ----------------------------------------\n   PrgEnv-aocc/8.3.3    PrgEnv-cray/8.3.3 (L)    PrgEnv-gnu/8.3.3\n\n  Where:\n   L:  Module is loaded\n\nModule defaults are chosen based on Find First Rules due to Name/Version/Version modules found in the module tree.\nSee https://lmod.readthedocs.io/en/latest/060_locating.html for details.\n\nUse \"module spider\" to find all possible modules and extensions.\nUse \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\".\n</code></pre> <p>Other software modules can be searched using the <code>module spider</code> command:</p> <pre><code>auser@uan01:~&gt; module spider\n\n---------------------------------------------------------------------------------------------------------------\nThe following is a list of the modules and extensions currently available:\n---------------------------------------------------------------------------------------------------------------\n  PrgEnv-aocc: PrgEnv-aocc/8.3.3\n\n  PrgEnv-cray: PrgEnv-cray/8.3.3\n\n  PrgEnv-gnu: PrgEnv-gnu/8.3.3\n\n  amd-uprof: amd-uprof/3.6.449\n\n  aocc: aocc/3.2.0\n\n  aocc-mixed: aocc-mixed/3.2.0\n\n  aocl: aocl/3.1, aocl/4.0\n\n  arm/forge: arm/forge/22.1.3\n\n  atp: atp/3.14.16\n\n  bolt: bolt/0.7, bolt/0.8\n\n  boost: boost/1.72.0, boost/1.81.0\n\n  castep: castep/22.11\n\n  cce: cce/15.0.0\n\n...output trimmed...\n</code></pre> <p>A full discussion of the module system is available in the Software environment section.</p> <p>A consistent set of modules is loaded on login to the machine (currently <code>PrgEnv-cray</code>, see below). Developing applications then means selecting and loading the appropriate set of modules before starting work.</p> <p>This section is aimed at code developers and will concentrate on the compilation environment, building libraries and executables, specifically parallel executables. Other topics such as Python and Containers are covered in more detail in separate sections of the documentation.</p> <p>Tip</p> <p>If you want to get back to the login module state without having to logout and back in again, you can just use: <pre><code>module restore\n</code></pre> This is also handy for build scripts to ensure you are starting from a known state.</p>"},{"location":"user-guide/dev-environment/#compiler-environments","title":"Compiler environments","text":"<p>There are three different compiler environments available on ARCHER2:</p> <ul> <li>AMD Compiler Collection (AOCC)</li> <li>GNU Compiler Collection (GCC)</li> <li>HPE Cray Compiler Collection (CCE) (current default compiler environment)</li> </ul> <p>The current compiler suite is selected via the <code>PrgEnv</code> module , while the specific compiler versions are determined by the relevant compiler module. A summary is:</p> Suite name Compiler Environment Module Compiler Version Module CCE <code>PrgEnv-cray</code> <code>cce</code> GCC <code>PrgEnv-gnu</code> <code>gcc</code> AOCC <code>PrgEnv-aocc</code> <code>aocc</code> <p>For example, at login, the default set of modules are:</p> <pre><code>auser@ln03:~&gt; module list\n\n  1) craype-x86-rome                         6) cce/15.0.0             11) PrgEnv-cray/8.3.3\n  2) libfabric/1.12.1.2.2.0.0                7) craype/2.7.19          12) bolt/0.8\n  3) craype-network-ofi                      8) cray-dsmml/0.2.2       13) epcc-setup-env\n  4) perftools-base/22.12.0                  9) cray-mpich/8.1.23      14) load-epcc-module\n  5) xpmem/2.5.2-2.4_3.30__gd0f7936.shasta  10) cray-libsci/22.12.1.1\n</code></pre> <p>from which we see the default compiler environment is Cray (indicated by <code>PrgEnv-cray</code> (at 11 in the list above) and the default compiler module is <code>cce/15.0.0</code> (at 6 in the list above). The compiler environment will give access to a consistent set of compiler, MPI library via <code>cray-mpich</code> (at 9), and other libraries e.g., <code>cray-libsci</code> (at 10 in the list above).</p>"},{"location":"user-guide/dev-environment/#switching-between-compiler-environments","title":"Switching between compiler environments","text":"<p>Switching between different compiler environments is achieved using the <code>module load</code> command. For example, to switch from the default HPE Cray (CCE) compiler environment to the GCC environment, you would use:</p> <pre><code>auser@ln03:~&gt; module load PrgEnv-gnu\n\nLmod is automatically replacing \"cce/15.0.0\" with \"gcc/11.2.0\".\n\n\nLmod is automatically replacing \"PrgEnv-cray/8.3.3\" with \"PrgEnv-gnu/8.3.3\".\n\n\nDue to MODULEPATH changes, the following have been reloaded:\n  1) cray-mpich/8.1.23\n</code></pre> <p>If you then use the <code>module list</code> command, you will see that your environment has been changed to the GCC environment:</p> <pre><code>auser@ln03:~&gt; module list\n\nCurrently Loaded Modules:\n  1) craype-x86-rome                         6) bolt/0.8          11) cray-dsmml/0.2.2\n  2) libfabric/1.12.1.2.2.0.0                7) epcc-setup-env    12) cray-mpich/8.1.23\n  3) craype-network-ofi                      8) load-epcc-module  13) cray-libsci/22.12.1.1\n  4) perftools-base/22.12.0                  9) gcc/11.2.0        14) PrgEnv-gnu/8.3.3\n  5) xpmem/2.5.2-2.4_3.30__gd0f7936.shasta  10) craype/2.7.19\n</code></pre>"},{"location":"user-guide/dev-environment/#switching-between-compiler-versions","title":"Switching between compiler versions","text":"<p>Within a given compiler environment, it is possible to swap to a different compiler version by swapping the relevant compiler module. To switch to the GNU compiler environment from the default HPE Cray compiler environment and than swap the version of GCC from the 11.2.0 default to  the older 10.3.0 version, you would use</p> <pre><code>auser@ln03:~&gt; module load PrgEnv-gnu\n\nLmod is automatically replacing \"cce/15.0.0\" with \"gcc/11.2.0\".\n\n\nLmod is automatically replacing \"PrgEnv-cray/8.3.3\" with \"PrgEnv-gnu/8.3.3\".\n\n\nDue to MODULEPATH changes, the following have been reloaded:\n  1) cray-mpich/8.1.23\n\nauser@ln03:~&gt; module load gcc/10.3.0\n\nThe following have been reloaded with a version change:\n  1) gcc/11.2.0 =&gt; gcc/10.3.0\n</code></pre> <p>The first swap command moves to the GNU compiler environment and the second swap command moves to the older version of GCC. As before, <code>module list</code> will show that your environment has been changed:</p> <pre><code>auser@ln03:~&gt; module list\n\nCurrently Loaded Modules:\n  1) craype-x86-rome                         6) bolt/0.8          11) cray-libsci/22.12.1.1\n  2) libfabric/1.12.1.2.2.0.0                7) epcc-setup-env    12) PrgEnv-gnu/8.3.3\n  3) craype-network-ofi                      8) load-epcc-module  13) gcc/10.3.0\n  4) perftools-base/22.12.0                  9) craype/2.7.19     14) cray-mpich/8.1.23\n  5) xpmem/2.5.2-2.4_3.30__gd0f7936.shasta  10) cray-dsmml/0.2.2\n</code></pre>"},{"location":"user-guide/dev-environment/#compiler-wrapper-scripts-cc-cc-ftn","title":"Compiler wrapper scripts: <code>cc</code>, <code>CC</code>, <code>ftn</code>","text":"<p>To ensure consistent behaviour, compilation of C, C++, and Fortran source code should then take place using the appropriate compiler wrapper: <code>cc</code>, <code>CC</code>, and <code>ftn</code>, respectively. The wrapper will automatically call the relevant underlying compiler and add the appropriate include directories and library locations to the invocation. This typically eliminates the need to specify this additional information explicitly in the configuration stage. To see the details of the exact compiler invocation use the <code>-craype-verbose</code> flag to the compiler wrapper.</p> <p>The default link time behaviour is also related to the current programming environment. See the section below on Linking and libraries.</p> <p>Users should not, in general, invoke specific compilers at compile/link stages. In particular, <code>gcc</code>, which may default to <code>/usr/bin/gcc</code>, should not be used. The compiler wrappers <code>cc</code>, <code>CC</code>, and <code>ftn</code> should be used (with the underlying compiler type and version set by the module system). Other common MPI compiler wrappers e.g., <code>mpicc</code>, should also be replaced by the relevant wrapper, e.g. <code>cc</code> (commands such as <code>mpicc</code> are not available on ARCHER2).</p> <p>Important</p> <p>Always use the compiler wrappers <code>cc</code>, <code>CC</code>, and/or <code>ftn</code> and not a specific compiler invocation. This will ensure consistent compile/link time behaviour.</p> <p>Tip</p> <p>If you are using a build system such as Make or CMake then you  will need to replace all occurrences of <code>mpicc</code> with <code>cc</code>, <code>mpicxx</code>/<code>mpic++</code> with <code>CC</code> and <code>mpif90</code> with <code>ftn</code>.</p>"},{"location":"user-guide/dev-environment/#compiler-man-pages-and-help","title":"Compiler man pages and help","text":"<p>Further information on both the compiler wrappers, and the individual compilers themselves are available via the command line, and via standard <code>man</code> pages. The <code>man</code> page for the compiler wrappers is common to all programming environments, while the <code>man</code> page for individual compilers depends on the currently loaded programming environment. The following table summarises options for obtaining information on the compiler and compile options:</p> Compiler suite C C++ Fortran Cray <code>man clang</code> <code>man clang++</code> <code>man crayftn</code> GNU <code>man gcc</code> <code>man g++</code> <code>man gfortran</code> Wrappers <code>man cc</code> <code>man CC</code> <code>man ftn</code> <p>Tip</p> <p>You can also pass the <code>--help</code> option to any of the compilers or wrappers to get a summary of how to use them. The Cray Fortran compiler uses <code>ftn --craype-help</code> to access the help options.</p> <p>Tip</p> <p>There are no <code>man</code> pages for the AOCC compilers at the moment.</p> <p>Tip</p> <p>Cray C/C++ is based on Clang and therefore supports similar options to clang/gcc. <code>clang --help</code> will produce a full summary of options with Cray-specific options marked \"Cray\". The <code>clang</code> man page on ARCHER2 concentrates on these Cray extensions to the <code>clang</code> front end and does not provide an exhaustive description of all <code>clang</code> options. Cray Fortran is not based on Flang and so takes different options from flang/gfortran.</p>"},{"location":"user-guide/dev-environment/#which-compiler-environment","title":"Which compiler environment?","text":"<p>If you are unsure which compiler you should choose, we suggest the starting point should be the GNU compiler collection (GCC, <code>PrgEnv-gnu</code>); this is perhaps the most commonly used by code developers, particularly in the open source software domain. A portable, standard-conforming code should (in principle) compile in any of the three compiler environments.</p> <p>For users requiring specific compiler features, such as coarray Fortran, the recommended starting point would be Cray. The following sections provide further details of the different compiler environments.</p> <p>Warning</p> <p>Intel compilers are not currently available on ARCHER2.</p>"},{"location":"user-guide/dev-environment/#gnu-compiler-collection-gcc","title":"GNU compiler collection (GCC)","text":"<p>The commonly used open source GNU compiler collection is available and provides C/C++ and Fortran compilers.</p> <p>Switch the the GCC compiler environment from the default CCE (cray) compiler environment via:</p> <pre><code>auser@ln03:~&gt; module load PrgEnv-gnu\n\nLmod is automatically replacing \"cce/15.0.0\" with \"gcc/11.2.0\".\n\n\nLmod is automatically replacing \"PrgEnv-cray/8.3.3\" with \"PrgEnv-gnu/8.3.3\".\n\n\nDue to MODULEPATH changes, the following have been reloaded:\n  1) cray-mpich/8.1.23\n</code></pre> <p>Warning</p> <p>If you want to use GCC version 10 or greater to compile Fortran code, with the old MPI interfaces (i.e. <code>use mpi</code> or <code>INCLUDE 'mpif.h'</code>) you must add the <code>-fallow-argument-mismatch</code> option (or equivalent) when compiling otherwise you will see compile errors associated with MPI functions. The reason for this is that past versions of <code>gfortran</code> have allowed mismatched arguments to external procedures (e.g., where an explicit interface is not available). This is often the case for MPI routines using the old MPI interfaces where arrays of different types are passed to, for example, <code>MPI_Send()</code>. This will now generate an error as not standard conforming. The <code>-fallow-argument-mismatch</code> option is used to reduce the error to a warning. The same effect may be achieved via <code>-std=legacy</code>.</p> <p>If you use the Fortran 2008 MPI interface (i.e. <code>use mpi_f08</code>) then you should not need to add this option.</p> <p>Fortran language MPI bindings are described in more detail at in the MPI Standard documentation.</p>"},{"location":"user-guide/dev-environment/#useful-gnu-fortran-options","title":"Useful Gnu Fortran options","text":"Option Comment <code>-O&lt;level&gt;</code> Optimisation levels: <code>-O0</code>, <code>-O1</code>, <code>-O2</code>, <code>-O3</code>, <code>-Ofast</code>. <code>-Ofast</code> is not recommended without careful regression testing on numerical output. <code>-std=&lt;standard&gt;</code> Default is gnu <code>-fallow-argument-mismatch</code> Allow mismatched procedure arguments. This argument is required for compiling MPI Fortran code with GCC version 10 or greater if you are using the older MPI interfaces (see warning above) <code>-fbounds-check</code> Use runtime checking of array indices <code>-fopenmp</code> Compile OpenMP (default is no OpenMP) <code>-v</code> Display verbose output from compiler stages <p>Tip</p> <p>The <code>standard</code> in <code>-std</code> may be one of <code>f95</code> <code>f2003</code>, <code>f2008</code> or <code>f2018</code>. The default option <code>-std=gnu</code> is the latest Fortran standard plus gnu extensions.</p> <p>Warning</p> <p>Past versions of <code>gfortran</code> have allowed mismatched arguments to external procedures (e.g., where an explicit interface is not available). This is often the case for MPI routines where arrays of different types are passed to <code>MPI_Send()</code> and so on. This will now generate an error as not standard conforming. Use <code>-fallow-argument-mismatch</code> to reduce the error to a warning. The same effect may be achieved via <code>-std=legacy</code>.</p>"},{"location":"user-guide/dev-environment/#reference-material","title":"Reference material","text":"<ul> <li> <p>C/C++ documentation https://gcc.gnu.org/onlinedocs/gcc-9.3.0/gcc/</p> </li> <li> <p>Fortran documentation https://gcc.gnu.org/onlinedocs/gcc-9.3.0/gfortran/</p> </li> </ul>"},{"location":"user-guide/dev-environment/#cray-compiling-environment-cce","title":"Cray Compiling Environment (CCE)","text":"<p>The Cray Compiling Environment (CCE) is the default compiler at the point of login. CCE supports C/C++ (along with unified parallel C UPC), and Fortran (including co-array Fortran). Support for OpenMP parallelism is available for both C/C++ and Fortran (currently OpenMP 4.5, with a number of exceptions).</p> <p>The Cray C/C++ compiler is based on a clang front end, and so compiler options are similar to those for gcc/clang. However, the Fortran compiler remains based around Cray-specific options. Be sure to separate C/C++ compiler options and Fortran compiler options (typically <code>CFLAGS</code> and <code>FFLAGS</code>) if compiling mixed C/Fortran applications.</p> <p>As CCE is the default compiler environment on ARCHER2, you do not usually need to issue any commands to enable CCE.</p> <p>Note</p> <p>The CCE Clang compiler uses a GCC 8 toolchain so only C++ standard library features available in GCC 8 will be available in CCE Clang. You can add the compile option <code>--gcc-toolchain=/opt/gcc/11.2.0/snos</code> to use a more recent version of the C++ standard library if you wish.</p>"},{"location":"user-guide/dev-environment/#useful-cce-cc-options","title":"Useful CCE C/C++ options","text":"<p>When using the compiler wrappers <code>cc</code> or <code>CC</code>, some of the following options may be useful:</p> <p>Language, warning, Debugging options:</p> Option Comment <code>-std=&lt;standard&gt;</code> Default is <code>-std=gnu11</code> (<code>gnu++14</code> for C++) [1] <code>--gcc-toolchain=/opt/gcc/11.2.0/snos</code> Use the GCC 11.2.0 toolchain instead of the default 8.1.0 version packaged with CCE <p>Performance options:</p> Option Comment <code>-Ofast</code> Optimisation levels: <code>-O0</code>, <code>-O1</code>, <code>-O2</code>, <code>-O3</code>, <code>-Ofast</code>. <code>-Ofast</code> is not recommended without careful regression testing on numerical output. <code>-ffp=level</code> Floating point maths optimisations levels 0-4 [2] <code>-flto</code> Link time optimisation <p>Miscellaneous options:</p> Option Comment <code>-fopenmp</code> Compile OpenMP (default is off) <code>-v</code> Display verbose output from compiler stages <p>Notes</p> <ol> <li>Option <code>-std=gnu11</code> gives <code>c11</code> plus GNU extensions (likewise     <code>c++14</code> plus GNU extensions). See     https://gcc.gnu.org/onlinedocs/gcc-4.8.2/gcc/C-Extensions.html</li> <li>Option <code>-ffp=3</code> is implied by <code>-Ofast</code> or <code>-ffast-math</code></li> </ol>"},{"location":"user-guide/dev-environment/#useful-cce-fortran-options","title":"Useful CCE Fortran options","text":"<p>Language, Warning, Debugging options:</p> Option Comment <code>-m &lt;level&gt;</code> Message level (default <code>-m 3</code> errors and warnings) <p>Performance options:</p> Option Comment <code>-O &lt;level&gt;</code> Optimisation levels: -O0 to -O3 (default -O2) <code>-h fp&lt;level&gt;</code> Floating point maths optimisations levels 0-3 <code>-h ipa</code> Inter-procedural analysis <p>Miscellaneous options:</p> Option Comment <code>-h omp</code> Compile OpenMP (default is <code>-hnoomp</code>) <code>-v</code> Display verbose output from compiler stages"},{"location":"user-guide/dev-environment/#cce-reference-documentation","title":"CCE Reference Documentation","text":"<ul> <li>Clang/Clang++ documentation, CCE-specific    details are available via <code>man clang</code> once the CCE compiler environment is loaded.</li> <li>Cray Fortran documentation</li> </ul>"},{"location":"user-guide/dev-environment/#amd-optimizing-compiler-collection-aocc","title":"AMD Optimizing Compiler Collection (AOCC)","text":"<p>The AMD Optimizing Compiler Collection (AOCC) is a clang-based optimising compiler. AOCC also includes a flang-based Fortran compiler.</p> <p>Load the AOCC compiler environment from the default CCE (cray) compiler environment via:</p> <pre><code>auser@ln03:~&gt; module load PrgEnv-aocc\n\nLmod is automatically replacing \"cce/15.0.0\" with \"aocc/3.2.0\".\n\n\nLmod is automatically replacing \"PrgEnv-cray/8.3.3\" with \"PrgEnv-aocc/8.3.3\".\n\n\nDue to MODULEPATH changes, the following have been reloaded:\n  1) cray-mpich/8.1.23\n</code></pre>"},{"location":"user-guide/dev-environment/#aocc-reference-material","title":"AOCC reference material","text":"<ul> <li>AMD website https://developer.amd.com/amd-aocc/</li> </ul>"},{"location":"user-guide/dev-environment/#message-passing-interface-mpi","title":"Message passing interface (MPI)","text":""},{"location":"user-guide/dev-environment/#hpe-cray-mpich","title":"HPE Cray MPICH","text":"<p>HPE Cray provide, as standard, an MPICH implementation of the message passing interface which is specifically optimised for the ARCHER2 interconnect. The current implementation supports MPI standard version 3.1.</p> <p>The HPE Cray MPICH implementation is linked into software by default when compiling using the standard wrapper scripts: <code>cc</code>, <code>CC</code> and <code>ftn</code>.</p> <p>You do not need to do anything to make HPE Cray MPICH available when you log into ARCHER2, it is available by default to all users.</p>"},{"location":"user-guide/dev-environment/#switching-to-alternative-ucx-mpi-implementation","title":"Switching to alternative UCX MPI implementation","text":"<p>HPE Cray MPICH can use two different low-level protocols to transfer data across the network. The default is the Open Fabrics Interface (OFI), but you can switch to the UCX protocol from Mellanox.</p> <p>Which performs better will be application-dependent, but our experience is that UCX is often faster for programs that send a lot of data collectively between many processes, e.g. all-to-all communications patterns such as occur in parallel FFTs.</p> <p>Note</p> <p>You do not need to recompile your program - you simply load    different modules in your Slurm script.</p> <pre><code>module load craype-network-ucx \nmodule load cray-mpich-ucx \n</code></pre> <p>The performance benefits will also vary depending on the number of processes, so it is important to benchmark your application at the scale used in full production runs.</p>"},{"location":"user-guide/dev-environment/#mpi-reference-material","title":"MPI reference material","text":"<p>MPI standard documents: https://www.mpi-forum.org/docs/</p>"},{"location":"user-guide/dev-environment/#linking-and-libraries","title":"Linking and libraries","text":"<p>Linking to libraries is performed dynamically on ARCHER2.</p> <p>Important</p> <p>Static linking is not supported on ARCHER2. If you attempt to link statically, you will see errors similar to: <pre><code>/usr/bin/ld: cannot find -lpmi\n/usr/bin/ld: cannot find -lpmi2\ncollect2: error: ld returned 1 exit status\n</code></pre></p> <p>One can use the <code>-craype-verbose</code> flag to the compiler wrapper to check exactly what linker arguments are invoked. The compiler wrapper scripts encode the paths to the programming environment system libraries using RUNPATH. This ensures that the executable can find the correct runtime libraries without the matching software modules loaded.</p> <p>The library RUNPATH associated with an executable can be inspected via, e.g.,</p> <pre><code>$ readelf -d ./a.out\n</code></pre> <p>(swap <code>a.out</code> for the name of the executable you are querying).</p>"},{"location":"user-guide/dev-environment/#commonly-used-libraries","title":"Commonly used libraries","text":"<p>Modules with names prefixed by <code>cray-</code> are provided by HPE Cray, and work with any of the compiler environments and. These modules should be the first choice for access to software libraries if available.</p> <p>Tip</p> <p>More information on the different software libraries on ARCHER2 can be found in the Software libraries section of the user guide.</p>"},{"location":"user-guide/dev-environment/#available-hpe-cray-programming-environment-releases-on-archer2","title":"Available HPE Cray Programming Environment releases on ARCHER2","text":"<p>ARCHER2 currently has the following HPE Cray Programming Environment releases available:</p> <ul> <li>22.12: Current default</li> </ul> <p>You can find information, notes, and lists of changes for current and upcoming ARCHER2  HPE Cray programming environments in the HPE Cray Programming Environment GitHub repository.</p> <p>Tip</p> <p>We recommend that users use the most recent version of the PE available to get the latest improvements and bug fixes.</p>"},{"location":"user-guide/dev-environment/#compiling-on-compute-nodes","title":"Compiling on compute nodes","text":"<p>Sometimes you may wish to compile in a batch job. For example, the compile process may take a long time or the compile process is part of the research workflow and can be coupled to the production job. Unlike login nodes, the <code>/home</code> file system is not available.</p> <p>An example job submission script for a compile job using <code>make</code> (assuming the Makefile is in the same directory as the job submission script) would be:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=compile\n#SBATCH --time=00:20:00\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=1\n\n# Replace the account code, partition and QoS with those you wish to use\n#SBATCH --account=t01        \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n\nmake clean\n\nmake\n</code></pre> <p>Note</p> <p>If you want to use a compiler environment other than the default then you will need to add the <code>module load</code> command before the <code>make</code> command. e.g. to use the GCC compiler environemnt:</p> <pre><code>module load PrgEnv-gnu\n</code></pre> <p>You can also use a compute node in an interactive way using <code>salloc</code>. Please see Section Using salloc to reserve resources for further details. Once your interactive session is ready, you can load the compilation environment and compile the code.</p>"},{"location":"user-guide/dev-environment/#using-the-compiler-wrappers-for-serial-compilations","title":"Using the compiler wrappers for serial compilations","text":"<p>The compiler wrappers link with a number of HPE-provided libraries automatically.  It is possible to compile codes in serial with the compiler wrappers to take  advantage of the HPE libraries.</p> <p>To set up your environment for serial compilation, you will need to run:</p> <pre><code>  module load craype-network-none\n  module remove cray-mpich\n</code></pre> <p>Once this is done, you can use the compiler wrappers (<code>cc</code> for C, <code>CC</code> for  C++, and <code>ftn</code> for Fortran) to compile your code in serial.</p>"},{"location":"user-guide/dev-environment/#managing-development","title":"Managing development","text":"<p>ARCHER2 supports common revision control software such as <code>git</code>.</p> <p>Standard GNU autoconf tools are available, along with <code>make</code> (which is GNU Make). Versions of <code>cmake</code> are available.</p> <p>Tip</p> <p>Some of these tools are part of the system software, and typically reside in <code>/usr/bin</code>, while others are provided as part of the module system. Some tools may be available in different versions via both <code>/usr/bin</code> and via the module system. If you find the default version is too old, then look in the module system for a more recent version.</p>"},{"location":"user-guide/dev-environment/#build-instructions-for-software-on-archer2","title":"Build instructions for software on ARCHER2","text":"<p>The ARCHER2 CSE team at EPCC and other contributors provide build configurations ando instructions for a range of research software, software libraries and tools on a variety of HPC systems (including ARCHER2) in a public Github repository. See:</p> <ul> <li>Build instructions repository</li> </ul> <p>The repository always welcomes contributions from the ARCHER2 user community.</p>"},{"location":"user-guide/dev-environment/#support-for-building-software-on-archer2","title":"Support for building software on ARCHER2","text":"<p>If you run into issues building software on ARCHER2 or the software you require is not available then please contact the ARCHER2 Service Desk with any questions you have.</p>"},{"location":"user-guide/energy/","title":"Energy use","text":"<p>This section covers how to monitor energy use for your jobs on ARCHER2 and how to control the CPU frequency which allows some control over how much energy is consumed by jobs.</p> <p>Important</p> <p>The default CPU frequency on ARCHER2 compute nodes for jobs launched using <code>srun</code> is currently set to 2.0 GHz. Information below describes how to control the CPU frequency using Slurm.</p>"},{"location":"user-guide/energy/#monitoring-energy-use","title":"Monitoring energy use","text":"<p>The Slurm accounting database stores the total energy consumed by a job and you can also directly access the counters on compute nodes which capture instantaneous power and energy data broken down by different hardware components.</p>"},{"location":"user-guide/energy/#using-sacct-to-get-energy-usage-for-individual-jobs","title":"Using sacct to get energy usage for individual jobs","text":"<p>Energy usage for a particular job may be obtained using the <code>sacct</code> command. For instance</p> <pre><code>sacct -j 2658300 --format=JobID,Elapsed,ReqCPUFreq,ConsumedEnergy\n</code></pre> <p>will provide the elapsed time and consumed energy in joules for the job(s) specified with <code>-j</code>. The output of this command is: </p> <pre><code>JobID           Elapsed ReqCPUFreq ConsumedEnergy \n------------ ---------- ---------- -------------- \n2658300        02:19:48    Unknown          4.58M \n2658300.bat+   02:19:48          0          4.58M \n2658300.ext+   02:19:48          0          4.58M \n2658300.0      02:19:09    Unknown          4.57M \n</code></pre> <p>In this case we can see that the job consumed 4.58 MJ for a run lasting 2 hours, 19 minutes and 48 seconds with the CPU frequency unset. To convert the energy to kWh we can multiply the energy in joules by 2.78e-7, in this case resulting in 1.27 kWh. </p> <p>The Slurm database may be cleaned without notice so you should gather any data you want as soon as possible after the job completes - you can even add the <code>sacct</code> command to the end of your job script to ensure this data is captured.</p> <p>In addition to energy statistics <code>sacct</code> provides a number of other statistics that can be specified to the <code>--format</code> option, the full list of which can be viewed with</p> <pre><code>sacct --helpformat\n</code></pre> <p>or using the <code>man</code> pages. </p>"},{"location":"user-guide/energy/#accessing-the-node-energypower-counters","title":"Accessing the node energy/power counters","text":"<p>Note</p> <p>The counters are available on each compute node and record data only for that compute node. If you are running multi-node jobs, you will need to combine data from multiple nodes to get data for the whole job. </p> <p>On compute nodes, the raw energy counters and instantaneous power draw data are available at:</p> <pre><code>/sys/cray/pm_counters\n</code></pre> <p>There are a number of files in this directory, all the counter files include the current value and a timestamp.</p> <ul> <li>power - Point-in-time power (Watts).</li> <li>energy - Accumulated energy (Joules)</li> <li>cpu_power - Point-in-time power (Watts) used by the CPU domain.</li> <li>cpu_energy - The total energy (Joules) used by the CPU domain.</li> <li>cpu*_temp - Temperature reading (Celsius) of the CPU domain - one file per CPU socket.</li> <li>memory_power - Point-in-time power (Watts) used by the memory domain.</li> <li>memory_energy - The total energy (Joules) used by the memory domain.</li> <li>generation - A counter that increments each time a power cap value is changed.</li> <li>startup - Startup counter.</li> <li>freshness - Free-running counter that increments at a rate of approximately 10Hz.</li> <li>version - Version number for power management counter support.</li> <li>power_cap - Current power cap limit in Watts; 0 indicates no capping.</li> <li>raw_scan_hz - The power management scanning rate for all data in pm_counters.</li> </ul> <p>Note</p> <p>There exists an MPI-based wrapper library that can gather the <code>pm</code> counter values at runtime via a simple set of function calls. See the link below for details.</p> <ul> <li>Power Management MPI Library</li> </ul>"},{"location":"user-guide/energy/#controlling-cpu-frequency","title":"Controlling CPU frequency","text":"<p>You can request specific CPU frequencies (in kHz) for compute nodes through <code>srun</code> options or environment variables. The available frequencies on the ARCHER2 processors along with the options and environment variables:</p> Frequency <code>srun</code> option Slurm environment variable Turbo boost enabled? 2.25 GHz <code>--cpu-freq=2250000</code> <code>export SLURM_CPU_FREQ_REQ=2250000</code> Yes 2.00 GHz <code>--cpu-freq=2000000</code> <code>export SLURM_CPU_FREQ_REQ=2000000</code> No 1.50 GHz <code>--cpu-freq=1500000</code> <code>export SLURM_CPU_FREQ_REQ=1500000</code> No <p>The only frequencies available on the processors on ARCHER2 are 1.5 GHz, 2.0 GHz and 2.25GHz.</p> <p>For example, you can add the following option to <code>srun</code> commands in your job submission scripts to set the CPU frequency to 2.25 GHz (and also enable turbo boost):</p> <pre><code>srun --cpu-freq=2250000 ...usual srun options and arguments...\n</code></pre> <p>Alternatively, you could add the following line to your job submission script before you use <code>srun</code> to launch the application:</p> <pre><code>export SLURM_CPU_FREQ_REQ=2250000\n</code></pre> <p>Tip</p> <p>Testing by the ARCHER2 CSE team has shown that most software are most energy efficient when 2.0 GHz  is selected as the CPU frequency.</p> <p>Tip</p> <p>When the highest frequency (2.25 GHz) is selected this also enables frequency turbo boost. Experiments on ARCHER2 have shown that under typical use, with all 128 cores heavily loaded, the processors turbo boost up to around 2.8 GHz when the frequency is set to 2.25 GHz.</p> <p>Important</p> <p>The CPU frequency settings only affect applications launched using the <code>srun</code> command.</p> <p>Priority of frequency settings:</p> <ul> <li>The default <code>SLURM_CPU_FREQ_REQ</code> setting set by the ARCHER2 service applies if no other mechnism    is used to set the CPU frequency</li> <li>Setting the <code>SLURM_CPU_FREQ_REQ</code> environment variable in a job script overrides options provided   the default environment variable setting for any subsequent <code>srun</code> commands in the job script.</li> <li>Adding the <code>--cpu-freq=&lt;freq in kHz&gt;</code> option to the <code>srun</code> launch command itself overrides all other   options.</li> </ul> <p>Tip</p> <p>Adding the <code>--cpu-freq=&lt;freq in kHz&gt;</code> option to <code>sbatch</code> (e.g. using <code>#SBATCH --cpu-freq=&lt;freq in kHz&gt;</code> will not change the CPU frequency of <code>srun</code> commands used in the job as the default setting for ARCHER2 will override the <code>sbatch</code> option when the script runs.</p>"},{"location":"user-guide/energy/#default-cpu-frequency","title":"Default CPU frequency","text":"<p>If you do not specify a CPU frequency then you will get the default setting for the ARCHER2 service when you lanch an application using <code>srun</code>. The table below lists the history of default CPU frequency settings on the ARCHER2 service</p> Date range Default CPU frequency 12 Dec 2022 - current date 2.0 GHz Nov 2021 - 11 Dec 2022 Unspecified - defaults to 2.25 GHz"},{"location":"user-guide/energy/#slurm-cpu-frequency-settings-for-centrally-installed-software","title":"Slurm CPU frequency settings for centrally-installed software","text":"<p>Most centrally installed research software (available via <code>module load</code> commands) uses the same default Slurm CPU frequency as set globally for all ARCHER2 users (see above for this value). However, a small number of software have performance that is significantly  degraded by using lower frequency settings and so the modules for these packages reset the  CPU frequency to the highest value (2.25 GHz). The packages that currently do this are:</p> <ul> <li>GROMACS</li> <li>LAMMPS</li> <li>NAMD</li> </ul> <p>Important</p> <p>If you specify the Slurm CPU frequency in your job scripts using one of the mechanisms described above after you have loaded the module, you will override the setting from the module.</p>"},{"location":"user-guide/hardware/","title":"ARCHER2 hardware","text":"<p>Note</p> <p>Some of the material in this section is closely based on information provided by NASA as part of the documentation for the Aitkin HPC system.</p>"},{"location":"user-guide/hardware/#system-overview","title":"System overview","text":"<p>ARCHER2 is a HPE Cray EX supercomputing system which has a total of 5,860 compute nodes. Each compute node has 128 cores (dual AMD EPYC 7742 64-core 2.25GHz processors) giving a total of 750,080 cores. Compute nodes are connected together by a HPE Slingshot interconnect. </p> <p>There are additional User Access Nodes (UAN, also called login nodes), which provide access to the system, and data-analysis nodes, which are well-suited for preparation of job inputs and analysis of job outputs.</p> <p>Compute nodes are only accessible via the Slurm job scheduling system.</p> <p>There are two storage types: home and work. Home is available on login nodes and data-analysis nodes. Work is available on login, data-analysis nodes and compute nodes (see I/O and file systems).</p> <p>This is shown in the ARCHER2 architecture diagram: </p> <p>The home file system is provided by dual NetApp FAS8200A systems (one primary and one disaster recovery) with a capacity of 1 PB each.</p> <p>The work file system consists of four separate HPE Cray L300 storage systems, each with a capacity of 3.6 PB. The interconnect uses a dragonfly topology, and has a bandwidth of 100 Gbps.</p> <p>The system also includes 1.1 PB burst buffer NVMe storage, provided by an HPE Cray E1000.</p>"},{"location":"user-guide/hardware/#compute-node-overview","title":"Compute node overview","text":"<p>The compute nodes each have 128 cores. They are dual socket nodes with two 64-core AMD EPYC 7742 processors.  There are 5,276 standard memory nodes and 584 high memory nodes.</p> <p>Note</p> <p>Note due to Simultaneous Multi-Threading (SMT) each core has 2 threads, therefore a node has 128 cores / 256 threads. Most users will not want to use SMT, see Launching parallel jobs.</p> Component Details Processor 2x AMD Zen2 (Rome) EPYC 7742, 64-core, 2.25 Ghz Cores per node 128 NUMA structure 8 NUMA regions per node (16 cores per NUMA region) Memory per node 256 GB (standard), 512 GB (high memory) Memory per core 2 GB (standard), 4 GB (high memory) L1 cache 32 kB/core L2 cache 512 kB/core L3 cache 16 MB/4-cores Vector support AVX2 Network connection 2x 100 Gb/s injection ports per node <p></p> <p>Each socket contains eight Core Complex Dies (CCDs) and one I/O die (IOD). Each CCD contains two Core Complexes (CCXs). Each CCX has 4 cores and 16 MB of L3 cache. Thus, there are 64 cores per socket and 128 cores per node.</p> <p>More information on the architecture of the AMD EPYC Zen2 processors:</p> <ul> <li>HPC Tuning Guide for AMD EPYC 7002 Processors</li> </ul>"},{"location":"user-guide/hardware/#amd-zen2-microarchitecture","title":"AMD Zen2 microarchitecture","text":"<p>The AMD EPYC 7742 Rome processor has a base CPU clock of 2.25 GHz and a maximum boost clock of 3.4 GHz. There are eight processor dies (CCDs) with a total of 64 cores per socket.</p> <p>Tip</p> <p>The processors can only access their boost frequencies if the CPU frequency is set to 2.25 GHz. See the  documentation on setting CPU frequency for information on how to  select the correct CPU frequency.</p> <p>Note</p> <p>When all 128 compute cores on a node are loaded with computationally intensive work, we typically see the processor clock frequency boost to around 2.8 GHz.</p> <p>Hybrid multi-die design:</p> <p>Within each socket, the eight processor dies are fabricated on a 7 nanometer (nm) process, while the I/O die is fabricated on a 14 nm process. This design decision was made because the processor dies need the leading edge (and more expensive) 7 nm technology in order to reduce the amount of power and space needed to double the number of cores, and to add more cache, compared to the first-generation EPYC processors. The I/O die retains the less expensive, older 14 nm technology.</p> <p>2nd-generation Infinity Fabric technology:</p> <p>Infinity Fabric technology is used for communication among different components throughout the node: within cores, between cores, between core complexes (CCX) in a core complex die (CCD), among CCDs in a socket, to the main memory and PCIe, and between the two sockets. The Rome processors are the first x86 systems to support 4th-generation PCIe, which delivers twice the I/O performance (to the Slingshot interconnect, storage, NVMe SSD, etc.) compared to 3rd-generation PCIe.</p>"},{"location":"user-guide/hardware/#processor-hierarchy","title":"Processor hierarchy","text":"<p>The Zen2 processor hierarchy is as follows:</p> <ul> <li>Core: A CPU core has private L1I, L1D, and L2 caches, which are shared by two hyperthreads on the core.</li> <li>CCX: A core complex includes four cores and a common L3 cache of 16 MB. Different CCXs do not share L3.</li> <li>CCD: A core complex die includes two CCXs and an Infinity Link to the I/O die (IOD). The CCDs connect to memory, I/O, and each other through the IOD.</li> <li>Socket: A socket includes eight CCDs (total of 64 cores), a common centralized I/O die (includes eight unified memory controllers and eight IO x16 PCIe 4.0 lanes\u2014total of 128 lanes), and a link to the network interface controller (NIC).</li> <li>Node: A node includes two sockets and two network interface controllers (NIC).</li> </ul> <p>CPU core</p> <p>AMD 7742 is a 64-bit x86 server microprocessor. A partial list of instructions and features supported in Rome includes SSE, SSE2, SSE3, SSSE3, SSE4a, SSE4.1, SSE4.2, AES, FMA, AVX, AVX2 (256 bit), Integrated x87 FPU (FPU), Multi-Precision Add-Carry (ADX), 16-bit Floating Point Conversion (F16C), and No-eXecute (NX). For a complete list, run <code>cat /proc/cpuinfo</code> on the ARCHER2 login nodes.</p> <p>Each core:</p> <ul> <li>Can sustain execution of four x86 instructions per cycle, using features such as the micro-op cache, advanced branch prediction, and prefetching. The prefetcher works on streaming data and on variable strides, allowing it to accelerate many different data structures.</li> <li>Has two 256-bit Fused Multiply-Add (FMA) units and can deliver up to 16 double-precision floating point operations (flops) per cycle. Thus, the peak double-precision flops per node (at base frequency) is: 128 cores x 2.25 GHz x 16 = 4.6 teraflops.</li> <li>Can support Simultaneous Multi-threading (SMT), allowing two threads to execute simultaneously per core. SMT is available on ARCHER2 compute nodes but example submission scripts all use physical cores only as SMT is not usually beneficial for HPC applications.</li> </ul>"},{"location":"user-guide/hardware/#cache-hierarchy","title":"Cache hierarchy","text":"<p>The cache hierarchy is as follows:</p> <ul> <li> <p>op cache (OC): 4K ops, private to each core; 64 sets; 64 bytes/line; 8-way. OC holds instructions that have already been decoded into micro-operations (micro-ops). This is useful when the CPU repeatedly executes a loop of code. Using OC improves:</p> <ul> <li>Pipeline latency: because the op cache pipeline is shorter than the traditional fetch and decode pipeline.</li> <li>Bandwidth: because the maximum throughput from the op cache is eight instructions per cycle, whereas the maximum throughput from the traditional fetch and decode pipeline is four instructions per cycle.</li> <li>Power: because there is no need to re-decode instructions.</li> </ul> </li> <li> <p>L1 instruction cache: 32 KB, private to each core; 64 bytes/line; 8-way. The processor fetches instructions from the instruction cache in 32-byte naturally aligned blocks.</p> </li> <li>L1 data cache: 32 KB, private to each core; 64 bytes/line; 8-way; latency: 7\u20138 cycles for floating point and 4\u20135 cycles for integer; 2 x 256 bits/cycle load bandwidth to registers; 1 x 256 bits/cycle store bandwidth from registers; write-back policy.</li> <li>L2 cache: 512 KB, private to each core; unified; inclusive of L1 cache; 64 bytes/line; 8-way; latency: &gt;= 12 cycles; 1 x 256 bits/cycle load bandwidth to L1 cache; 1 x 256 bits/cycle store bandwidth from L1 cache; write-back policy.</li> <li>L3 cache: 16 MB shared among four cores in a core complex (CCX); different CCXs do not share L3; total of 256 MB per socket. Within each CCX: 64 bytes/line; 16-way; latency: 39 cycles on average.</li> </ul> <p>Note</p> <p>With the write-back policy, data is updated in the current level cache first. The update in the next level storage is done later when the cache line is ready to be replaced.</p> <p>Note</p> <p>If a core misses in its local L2 and also in the L3, the shadow tags are consulted. If the shadow tag indicates that the data resides in another L2 within the CCX, a cache-to-cache transfer is initiated. 1 x 256 bits/cycle load bandwidth to L2 of each core; 1 x 256 bits/cycle store bandwidth from L2 of each core; write-back policy; populated by L2 victims.</p>"},{"location":"user-guide/hardware/#intra-socket-interconnect","title":"Intra-socket interconnect","text":"<p>The Infinity Fabric, evolved from AMD's previous generation HyperTransport interconnect, is a software-defined, scalable, coherent, and high-performance fabric. It uses sensors embedded in each die to scale control (Scalable Control Fabric, or SCF) and data flow (Scalable Data Fabric, or SDF).</p> <ul> <li>The SCF uses sensors to monitor die temperature, speed, and voltage across all cores within the dies and controls power management, security, reset, etc.</li> <li>The SDF connects the L3 caches to memory and to the configurable I/O lanes. SDF uses the configurable I/O lanes for memory-coherent communications between compute elements on a single die, between different dies on a socket, and between sockets in a node.</li> <li>The die-to-die Infinity Fabric bandwidth is 32 bytes for read and 16 bytes for write per Infinity Fabric clock (which has a maximum speed of 1,467 MHz).</li> </ul>"},{"location":"user-guide/hardware/#inter-socket-interconnect","title":"Inter-socket interconnect","text":"<p>Two EPYC 7742 SoCs are interconnected via Socket to Socket Global Memory Interconnect (xGMI) links, part of the Infinity Fabric that connects all the components of the SoC together. On ARCHER2 compute nodes there are 3 xGMI links using a total of 48 PCIe lanes. With the xGMI link speed set at 16 GT/s, the theoretical throughput for each direction is 96 GB/s (3 links x 16 GT/s x 2 bytes/transfer) without factoring in the encoding for xGMI, since there is no publication from AMD available. However, the expected efficiencies are 66\u201375%, so the sustained bandwidth per direction will be 63.5\u201372 GB/s. xGMI Dynamic Link Width Management saves power during periods of low socket-to-socket data traffic by reducing the number of active xGMI lanes per link from 16 to 8.</p>"},{"location":"user-guide/hardware/#memory-subsystem","title":"Memory subsystem","text":"<p>The Zen 2 microarchitecture places eight unified memory controllers in the centralized I/O die. The memory channels can be split into one, two, or four Non-Uniform Memory Access (NUMA) Nodes per Socket (NPS1, NPS2, and NPS4). ARCHER2 compute nodes are configured as NPS4, which is the highest memory bandwidth configuration geared toward HPC applications.</p> <p>With eight 3,200-GHz memory channels, an 8-byte read or write operation taking place per cycle per channel results in a maximum total memory bandwidth of 204.8 GB/s per socket.</p> <p>Each memory channel can be connected with up to two Double Data Rate (DDR) fourth-generation Dual In-line Memory Modules (DIMMs). On ARCHER2 standard memory nodes, each channel is connected to a single 16 GB DDR4 registered DIMM (RDIMM) with error correcting code (ECC) support leading to 128 GB per socket and 256 GB per node. For the high memory nodes, each channel is connected to a single 32 GB DDR4 registered DIMM (RDIMM) with error correcting code (ECC) support leading to 256 GB per socket and 512 GB per node.</p>"},{"location":"user-guide/hardware/#interconnect-details","title":"Interconnect details","text":"<p>ARCHER2 has a HPE Slingshot interconnect with 200 Gb/s signalling per node. It uses a dragonfly topology:</p> <ul> <li> <p>Nodes are organized into groups.</p> <ul> <li>128 Nodes in a group.</li> <li>Electrical links between Network Interface Card (NIC) and switch.</li> <li>16 switches per group.</li> <li>2x NIC per node.</li> <li>All-to-all connection amongst switches in a group using electrical links.</li> </ul> </li> <li> <p>All-to-all connection between groups using optical links.</p> <ul> <li>2 groups per ARCHER2 Cabinet.</li> </ul> </li> </ul>"},{"location":"user-guide/hardware/#storage-details","title":"Storage details","text":"<p>Information on the ARCHER2 parallel Lustre file systems and how to get best performance is available in the IO section.</p>"},{"location":"user-guide/io/","title":"I/O performance and tuning","text":"<p>This section describes common IO patterns and how to get good performance on the ARCHER2 storage. </p> <p>Information on the file systems, directory layouts, quotas, archiving and transferring data can be found in the Data management and transfer section.</p> <p>The advice here is targetted at use of the parallel file systems available on the compute nodes on ARCHER2 (i.e. Not the home and RDFaaS file systems).</p>"},{"location":"user-guide/io/#common-io-patterns","title":"Common I/O patterns","text":"<p>There are number of I/O patterns that are frequently used in parallel applications:</p>"},{"location":"user-guide/io/#single-file-single-writer-serial-io","title":"Single file, single writer (Serial I/O)","text":"<p>A common approach is to funnel all the I/O through one controller process (e.g. rank 0 in an MPI program). Although this has the advantage of producing a single file, the fact that only one client is doing all the I/O means that it gains little benefit from the parallel file system. In practice this severely limits the I/O rates, e.g. when writing large files the speed is not likely to significantly exceed 1 GB/s.</p>"},{"location":"user-guide/io/#file-per-process-fpp","title":"File-per-process (FPP)","text":"<p>One of the first parallel strategies people use for I/O is for each parallel process to write to its own file. This is a simple scheme to implement and understand and can achieve high bandwidth as, with many I/O clients active at once, it benefits from the parallel Lustre filesystem. However, it has the distinct disadvantage that the data is spread across many different files and may therefore be very difficult to use for further analysis without a data reconstruction stage to recombine potentially thousands of small files.</p> <p>In addition, having thousands of files open at once can overload the filesystem and lead to poor performance.</p> <p>Tip</p> <p>The ARCHER2 solid state file system can give very high performance when using this model of I/O</p> <p>The ADIOS 2 I/O library uses an approach similar to file-per-process and so can achieve very good performance on modern parallel file systems.</p>"},{"location":"user-guide/io/#file-per-node-fpn","title":"File-per-node (FPN)","text":"<p>A simple way to reduce the sheer number of files is to write a file per node rather than a file per process; as ARCHER2 has 128 CPU-cores per node, this can reduce the number of files by more than a factor of 100 and should not significantly affect the I/O rates. However, it still produces multiple files which can be hard to work with in practice.</p>"},{"location":"user-guide/io/#single-file-multiple-writers-without-collective-operations","title":"Single file, multiple writers without collective operations","text":"<p>All aspects of data management are simpler if your parallel program produces a single file in the same format as a serial code, e.g. analysis or program restart are much more straightforward.</p> <p>There are a number of ways to achieve this. For example, many processes can open the same file but access different parts by skipping some initial offset, although this is problematic when writing as locking may be needed to ensure consistency. Parallel I/O libraries such as MPI-IO, HDF5 and NetCDF allow for this form of access and will implement locking automatically.</p> <p>The problem is that, with many clients all individually accessing the same file, there can be a lot of contention for file system resources, leading to poor I/O rates. When writing, file locking can effectively serialise the access and there is no benefit from the parallel filesystem.</p>"},{"location":"user-guide/io/#single-shared-file-with-collective-writes-ssf","title":"Single Shared File with collective writes (SSF)","text":"<p>The problem with having many clients performing I/O at the same time is that the I/O library may have to restrict access to one client at a time by locking. However if I/O is done collectively, where the library knows that all clients are doing I/O at the same time, then reads and writes can be explicitly coordinated to avoid clashes and no locking is required.</p> <p>It is only through collective I/O that the full bandwidth of the file system can be realised while accessing a single file.  Whatever I/O library you are using, it is essential to use collective forms of the read and write calls to achieve good performance.</p>"},{"location":"user-guide/io/#achieving-efficient-io","title":"Achieving efficient I/O","text":"<p>This section provides information on getting the best performance out of the parallel <code>/work</code> file systems on ARCHER2 when writing data, particularly using parallel I/O patterns.</p>"},{"location":"user-guide/io/#lustre","title":"Lustre","text":"<p>The ARCHER2 <code>/work</code> file systems use Lustre as a parallel file system technology. It has many disk units (called Object Storage Targets or OSTs), all under the control of a single Meta Data Server (MDS) so that it appears to the user as a single file system.  The Lustre file system provides POSIX semantics (changes on one node are immediately visible on other nodes) and can support very high data rates for appropriate I/O patterns.</p>"},{"location":"user-guide/io/#striping","title":"Striping","text":"<p>One of the main factors leading to the high performance of Lustre file systems is the ability to store data on multiple OSTs. For many small files, this is achieved by storing different files on different OSTs; large files must be striped across multiple OSTs to benefit from the parallel nature of Lustre.</p> <p>When a file is striped it is split into chunks and stored across multiple OSTs in a round-robin fashion. Striping can improve the I/O performance because it increases the available bandwidth: multiple processes can read and write the same file simultaneously by accessing different OSTs. However striping can also increase the overhead. Choosing the right striping configuration is key to obtain high performance results.</p> <p>Users have control of a number of striping settings on Lustre file systems. Although these parameters can be set on a per-file basis they are usually set on the directory where your output files will be written so that all output files inherit the same settings.</p>"},{"location":"user-guide/io/#default-configuration","title":"Default configuration","text":"<p>The <code>/work</code> file systems on ARCHER2 have the same default stripe  settings:</p> <ul> <li>A default stripe count of 1</li> <li>A default stripe size of 1 MiB (2<sup>20</sup> = 1048576 bytes)</li> </ul> <p>These settings have been chosen to provide a good compromise for the wide variety of I/O patterns that are seen on the system but are unlikely to be optimal for any one particular scenario. The Lustre command to query the stripe settings for a directory (or file) is <code>lfs getstripe</code>. For example, to query the stripe settings of an already created directory <code>resdir</code>:</p> <pre><code>auser@ln03:~&gt; lfs getstripe resdir/\nresdir\nstripe_count:   1 stripe_size:    1048576 stripe_offset:  -1\n</code></pre>"},{"location":"user-guide/io/#setting-custom-striping-configurations","title":"Setting Custom Striping Configurations","text":"<p>Users can set stripe settings for a directory (or file) using the <code>lfs setstripe</code> command. The options for <code>lfs setstripe</code> are:</p> <ul> <li><code>[--stripe-count|-c]</code> to set the stripe count; 0 means use the     system default (usually 1) and -1 means stripe over all available     OSTs.</li> <li><code>[--stripe-size|-S]</code> to set the stripe size; 0 means use the system     default (usually 1 MB) otherwise use k, m or g for KB, MB or GB     respectively</li> <li><code>[--stripe-index|-i]</code> to set the OST index (starting at 0) on which     to start striping for this file. An index of -1 allows the MDS to     choose the starting index and it is strongly recommended, as this     allows space and load balancing to be done by the MDS as needed.</li> </ul> <p>For example, to set a stripe size of 4 MiB for the existing directory <code>resdir</code>, along with maximum striping count you would use:</p> <pre><code>auser@ln03:~&gt; lfs setstripe -S 4m -c -1 resdir/\n</code></pre>"},{"location":"user-guide/io/#recommended-archer2-io-settings","title":"Recommended ARCHER2 I/O settings","text":"<p>As mentioned above, it is very important to use collective calls when doing parallel I/O to a single shared file.</p> <p>However, with the default settings, parallel I/O on multiple nodes can currently give poor performance. We recommend always setting the following environment variable in your SLURM batch script:</p> <pre><code>export FI_OFI_RXM_SAR_LIMIT=64K\n</code></pre> <p>Although I/O requirements vary significantly between different applications, the following settings should be good in most cases:</p> <ul> <li> <p>If each process or node is writing to its own individual file then     the default settings (unstriped files) should give good     performance.</p> </li> <li> <p>If processes are writing to a single shared file (e.g. using     MPI-IO, HDF5 or NetCDF), set the appropriate directories to be     fully striped: <code>lfs setstripe -c -1 resdir</code>. On ARCHER2 this will     use all of the 12 OSTs.</p> </li> </ul>"},{"location":"user-guide/io/#alternative-mpi-library","title":"Alternative MPI library","text":"<p>Setting the environment variable <code>FI_OFI_RXM_SAR_LIMIT</code> can improve the performance of MPI collectives when handling large amounts of data, which in turn can improve collective file I/O. An alternative is to use the non-default UCX implementation of the MPI library as an alternative to the default OFI version.</p> <p>To switch library version see the Application Development Environment section of the User Guide.</p> <p>Note</p> <p>This will affect all your MPI calls, not just those related to I/O, so you should check the overall performance of your program before and after the switch. It is possible that other functions may run slower even if the I/O performance improves.</p>"},{"location":"user-guide/io/#io-profiling","title":"I/O Profiling","text":"<p>If you are concerned about your I/O performance, you should quantify your transfer rates in terms of GB/s of data read or written to disk. Small files can achieve very high I/O rates due to data caching in Lustre. However, for large files you should be able to achieve a maximum of around 1 GB/s for an unstriped file, or up to 10 GB/s for a fully striped file (across all 12 OSTs).</p> <p>Warning</p> <p>You share <code>/work</code> with all other users so I/O rates can be very variable, especially if the machine is heavily loaded.</p> <p>If your I/O rates are poor then you can get useful summary information about how the parallel libraries are performing by setting this variable in your Slurm script</p> <pre><code>export MPICH_MPIIO_STATS=1\n</code></pre> <p>Amongst other things, this will give you information on how many independent and collective I/O operations were issued. If you see a large number of independent operations compared to collectives, this indicates that you have inefficient I/O patterns and you should check that you are calling your parallel I/O library correctly.</p> <p>Although this information comes from the MPI library, it is still useful for users of higher-level libraries such as HDF5 as they all call MPI-IO at the lowest level.</p>"},{"location":"user-guide/profile/","title":"Profiling","text":"<p>There are a number of different ways to access profiling data on  ARCHER2. In this section, we discuss the HPE Cray profiling tools, CrayPat-lite and CrayPat. We also show how to get usage data on currently running jobs from Slurm batch system.</p> <p>You can also use the Arm Forge tool to profile applications on ARCHER2</p>"},{"location":"user-guide/profile/#craypat-lite","title":"CrayPat-lite","text":"<p>CrayPat-lite is a simplified and easy-to-use version of the Cray Performance Measurement and Analysis Tool (CrayPat). CrayPat-lite provides basic performance analysis information automatically, with a minimum of user interaction, and yet offers information useful to users wishing to explore a program's behaviour further using the full CrayPat suite.</p>"},{"location":"user-guide/profile/#how-to-use-craypat-lite","title":"How to use CrayPat-lite","text":"<ol> <li> <p>Ensure the <code>perftools-base</code> module is loaded.</p> <p><code>module list</code></p> </li> <li> <p>Load the <code>perftools-lite</code> module.</p> <p><code>module load perftools-lite</code></p> </li> <li> <p>Compile your application normally. An informational message from     CrayPat-lite will appear indicating that the executable has been     instrumented.</p> <pre><code>cc -h std=c99  -o myapplication.x myapplication.c\n</code></pre> <pre><code>INFO: creating the CrayPat-instrumented executable 'myapplication.x' (lite-samples) ...OK  \n</code></pre> </li> <li> <p>Run the generated executable normally by submitting a job.</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=CrayPat_test\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=00:20:00\n\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\nexport OMP_NUM_THREADS=1\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Launch the parallel program\nsrun --hint=nomultithread --distribution=block:block mpi_test.x\n</code></pre> </li> <li> <p>Analyse the data.</p> <p>After the job finishes executing, CrayPat-lite output should be printed to stdout (i.e. at the end of the job's output file). A new directory will also be created containing <code>.rpt</code> and <code>.ap2</code> files. The <code>.rpt</code> files are text files that contain the same information printed in the job's output file and the <code>.ap2</code> files can be used to obtain more detailed information, which can be visualized using the Cray Apprentice2 tool.</p> </li> </ol>"},{"location":"user-guide/profile/#further-help","title":"Further help","text":"<ul> <li>CrayPat-lite User Guide</li> </ul>"},{"location":"user-guide/profile/#craypat","title":"CrayPat","text":"<p>The Cray Performance Analysis Tool (CrayPat) is a powerful framework for analysing a parallel application\u2019s performance on Cray supercomputers. It can provide very detailed information about the timing and performance of individual application procedures.</p> <p>CrayPat can perform two types of performance analysis, sampling experiments and tracing experiments. A sampling experiment probes the code at a predefined interval and produces a report based on the data collected. A tracing experiment explicitly monitors the code performance within named routines. Typically, the overhead associated with a tracing experiment is higher than that associated with a sampling experiment but provides much more detailed information. The key to getting useful data out of a sampling experiment is to run your profiling for a representative length of time.</p>"},{"location":"user-guide/profile/#sampling-analysis","title":"Sampling analysis","text":"<ol> <li> <p>Ensure the <code>perftools-base</code> module is loaded.</p> <p><code>module list</code></p> </li> <li> <p>Load <code>perftools</code> module.</p> <p><code>module load perftools</code></p> </li> <li> <p>Compile your code in the standard way always using the Cray compiler     wrappers (ftn, cc and CC). Object files need to be made available to     CrayPat to correctly build an instrumented executable for profiling     or tracing, this means that the compile and link stage should be     separated by using the <code>-c</code> compile flag.</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; cc -h std=c99 -c jacobi.c\nauser@ln01:/work/t01/t01/auser&gt; cc jacobi.o -o jacobi\n</code></pre> </li> <li> <p>To instrument the binary, run the <code>pat_build</code> command. This will      generate a new binary with <code>+pat</code> appended to the end (e.g. <code>jacobi+pat</code>).</p> <p><code>auser@ln:/work/t01/t01/auser&gt; pat_build jacobi</code></p> </li> <li> <p>Run the new executable with <code>+pat</code> appended as you would with the     regular executable. Each run will produce its own 'experiment     directory' containing the performance data as <code>.xf</code> files     inside a subdirectory called <code>xf-files</code> (e.g. running the      <code>jacobi+pat</code> instrumented executable might produce     <code>jacobi+pat+12265-1573s/xf-files</code>).</p> </li> <li>Generate report data with <code>pat_report</code>.</li> </ol> <p>The <code>.xf</code> files contain the raw sampling data from the run and need to be post-processed to produce useful results. This is done using the <code>pat_report</code> tool which converts all the raw data into a summarised and readable form. You should provide the name of the experiment directory as the argument to <code>pat_report</code>.</p> <pre><code>auser@ln:/work/t01/t01/auser&gt; pat_report jacobi+pat+12265-1573s\n\nTable 1:  Profile by Function (limited entries shown)\n\nSamp% |  Samp |  Imb. |  Imb. | Group\n        |       |  Samp | Samp% |  Function\n        |       |       |       |   PE=HIDE\n100.0% | 849.5 |    -- |    -- | Total\n|--------------------------------------------------\n|  56.7% | 481.4 |    -- |    -- | MPI\n||-------------------------------------------------\n||  48.7% | 414.1 |  50.9 | 11.0% | MPI_Allreduce\n||   4.4% |  37.5 | 118.5 | 76.6% | MPI_Waitall\n||   3.0% |  25.2 |  44.8 | 64.5% | MPI_Isend\n||=================================================\n|  29.9% | 253.9 |  55.1 | 18.0% | USER\n||-------------------------------------------------\n||  29.9% | 253.9 |  55.1 | 18.0% | main\n||=================================================\n|  13.4% | 114.1 |    -- |    -- | ETC\n||-------------------------------------------------\n||  13.4% | 113.9 |  26.1 | 18.8% | __cray_memcpy_SNB\n|==================================================\n</code></pre> <p>This report will generate more files with the extension <code>.ap2</code> in the experiment directory. These hold the same data as the <code>.xf</code> files but in the post-processed form. Another file produced has an <code>.apa</code> extension and is a text file with a suggested configuration for generating a traced experiment. </p> <p>The <code>.ap2</code> files generated are used to view performance data graphically with the Cray Apprentice2 tool.</p> <p>The <code>pat_report</code> command is able to produce many different profile reports from the profiling data. You can select a predefined report with the <code>-O</code> flag to <code>pat_report</code>. A selection of the most generally useful predefined report types are:= listed below.</p> <ul> <li>ca+src - Show the callers (bottom-up view) leading to the     routines that have a high use in the report and include source code     line numbers for the calls and time-consuming statements.</li> <li>load_balance - Show load-balance statistics for the high-use     routines in the program. Parallel processes with minimum, maximum     and median times for routines will be displayed. Only available with     tracing experiments.</li> <li>mpi_callers - Show MPI message statistics. Only available with     tracing experiments.</li> </ul> <p>Example output:</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; pat_report -O ca+src,load_balance  jacobi+pat+12265-1573s\n\nTable 1:  Profile by Function and Callers, with Line Numbers (limited entries shown)\n\nSamp% |  Samp |  Imb. |  Imb. | Group\n        |       |  Samp | Samp% |  Function\n        |       |       |       |   PE=HIDE\n100.0% | 849.5 |    -- |    -- | Total\n|--------------------------------------------------\n|--------------------------------------\n|  56.7% | 481.4 | MPI\n||-------------------------------------\n||  48.7% | 414.1 | MPI_Allreduce\n3|        |       |  main:jacobi.c:line.80\n||   4.4% |  37.5 | MPI_Waitall\n3|        |       |  main:jacobi.c:line.73\n||   3.0% |  25.2 | MPI_Isend\n|||------------------------------------\n3||   1.6% |  13.2 | main:jacobi.c:line.65\n3||   1.4% |  12.0 | main:jacobi.c:line.69\n||=====================================\n|  29.9% | 253.9 | USER\n||-------------------------------------\n||  29.9% | 253.9 | main\n|||------------------------------------\n3||  18.7% | 159.0 | main:jacobi.c:line.76\n3||   9.1% |  76.9 | main:jacobi.c:line.84\n|||====================================\n||=====================================\n|  13.4% | 114.1 | ETC\n||-------------------------------------\n||  13.4% | 113.9 | __cray_memcpy_SNB\n3|        |       |  __cray_memcpy_SNB\n|======================================\n</code></pre>"},{"location":"user-guide/profile/#tracing-analysis","title":"Tracing analysis","text":""},{"location":"user-guide/profile/#automatic-program-analysis-apa","title":"Automatic Program Analysis (APA)","text":"<p>We can produce a focused tracing experiment based on the results from the sampling experiment using <code>pat_build</code> with the <code>.apa</code> file produced during the sampling.</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; pat_build -O jacobi+pat+12265-1573s/build-options.apa\n</code></pre> <p>This will produce a third binary with extension <code>+apa</code>. This binary should once again be run on the compute nodes and the name of the executable changed to <code>jacobi+apa</code>. As with the sampling analysis, a report can be produced using <code>pat_report</code>. For example:</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; pat_report jacobi+apa+13955-1573t\n\nTable 1:  Profile by Function Group and Function (limited entries shown)\n\nTime% |      Time |     Imb. |  Imb. |       Calls | Group\n        |           |     Time | Time% |             |  Function\n        |           |          |       |             |   PE=HIDE\n\n100.0% | 12.987762 |       -- |    -- | 1,387,544.9 | Total\n|-------------------------------------------------------------------------\n|  44.9% |  5.831320 |       -- |    -- |         2.0 | USER\n||------------------------------------------------------------------------\n||  44.9% |  5.831229 | 0.398671 |  6.4% |         1.0 | main\n||========================================================================\n|  29.2% |  3.789904 |       -- |    -- |   199,111.0 | MPI_SYNC\n||------------------------------------------------------------------------\n||  29.2% |  3.789115 | 1.792050 | 47.3% |   199,109.0 | MPI_Allreduce(sync)\n||========================================================================\n|  25.9% |  3.366537 |       -- |    -- | 1,188,431.9 | MPI\n||------------------------------------------------------------------------\n||  18.0% |  2.334765 | 0.164646 |  6.6% |   199,109.0 | MPI_Allreduce\n||   3.7% |  0.486714 | 0.882654 | 65.0% |   199,108.0 | MPI_Waitall\n||   3.3% |  0.428731 | 0.557342 | 57.0% |   395,104.9 | MPI_Isend\n|=========================================================================\n</code></pre>"},{"location":"user-guide/profile/#manual-program-analysis","title":"Manual Program Analysis","text":"<p>CrayPat allows you to manually choose your profiling preference. This is particularly useful if the APA mode does not meet your tracing analysis requirements.</p> <p>The entire program can be traced as a whole using <code>-w</code>:</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; pat_build -w jacobi\n</code></pre> <p>Using <code>-g</code>, a program can be instrumented to trace all function entry point references belonging to the trace function group (mpi, libsci, lapack, scalapack, heap, etc):</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; pat_build -w -g mpi jacobi\n</code></pre>"},{"location":"user-guide/profile/#dynamically-linked-binaries","title":"Dynamically-linked binaries","text":"<p>CrayPat allows you to profile un-instrumented, dynamically linked binaries with the <code>pat_run</code> utility. <code>pat_run</code> delivers profiling information for codes that cannot easily be rebuilt. To use <code>pat_run</code>:</p> <ol> <li> <p>Load the <code>perftools-base</code> module if it is not already loaded.</p> <p><code>module load perftools-base</code></p> </li> <li> <p>Run your application normally including the <code>pat_run</code> command right     after your <code>srun</code> options.</p> <p><code>srun [srun-options] pat_run [pat_run-options] program [program-options]</code></p> </li> <li> <p>Use <code>pat_report</code> to examine any data collected during the execution     of your application.</p> <p><code>auser@ln01:/work/t01/t01/auser&gt; pat_report jacobi+pat+12265-1573s</code></p> </li> </ol> <p>Some useful <code>pat_run</code> options are as follows.</p> <ul> <li><code>-w</code>  Collect data by tracing.</li> <li><code>-g</code>  Trace functions belonging to group names. See the -g option in     pat_build(1) for a list of valid tracegroup values.</li> <li><code>-r</code>  Generate a text report upon successful execution.</li> </ul>"},{"location":"user-guide/profile/#further-help_1","title":"Further help","text":"<ul> <li>CrayPat User Guide</li> </ul>"},{"location":"user-guide/profile/#cray-apprentice2","title":"Cray Apprentice2","text":"<p>Cray Apprentice2 is an optional GUI tool that is used to visualize and manipulate the performance analysis data captured during program execution. Cray Apprentice2 can display a wide variety of reports and graphs, depending on the type of program being analyzed, the way in which the program was instrumented for data capture, and the data that was collected during program execution.</p> <p>You will need to use CrayPat to first instrument your program and capture performance analysis data, and then <code>pat_report</code> to generate the <code>.ap2</code> files from the results. You may then use Cray Apprentice2 to visualize and explore those files.</p> <p>The number and appearance of the reports that can be generated using Cray Apprentice2 is determined by the kind and quantity of data captured during program execution, which in turn is determined by the way in which the program was instrumented and the environment variables in effect at the time of program execution. For example, changing the PAT_RT_SUMMARY environment variable to 0 before executing the instrumented program nearly doubles the number of reports available when analyzing the resulting data in Cray Apprentice2.</p> <pre><code>export PAT_RT_SUMMARY=0\n</code></pre> <p>To use Cray Apprentice2 (<code>app2</code>), load <code>perftools-base</code> module if it is not already loaded.</p> <pre><code>module load perftools-base\n</code></pre> <p>Next, open the experiment directory generated during the instrumentation phase with Apprentice2.</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; app2 jacobi+pat+12265-1573s\n</code></pre>"},{"location":"user-guide/profile/#hardware-performance-counters","title":"Hardware Performance Counters","text":"<p>Hardware performance counters can be used to monitor CPU and power events on ARCHER2 compute nodes. The monitoring and reporting of hardware counter events is  integrated with CrayPat - users should use CrayPat as described earlier in this section to run profiling experiments to gather data from hardware counter events and to analyse the data.</p>"},{"location":"user-guide/profile/#counters-and-counter-groups-available","title":"Counters and counter groups available","text":"<p>You can explore which event counters are available on compute nodes by running the following commands (replace <code>t01</code> with a valid budget code for your account):</p> <pre><code>module load perftools\nsrun --ntasks=1 --partition=standard --qos=short --account=t01 papi_avail\n</code></pre> <p>For convenience, the CrayPat tool provides predetermined groups of hardware event counters. You can get more information on the hardware event counters available through CrayPat with the following commands (on a login or compute node):</p> <pre><code>module load perftools\npat_help counters rome groups\n</code></pre> <p>If you want information on which hardware event counters are included in a group you can type the group name at the prompt you get after running the command above. Once you have finished browsing the help, type <code>.</code> to quit back to the command line.</p>"},{"location":"user-guide/profile/#powerenergy-counters-available","title":"Power/energy counters available","text":"<p>You can also access counters on power/energy consumption. To list the counters available to monitor power/energy use you can use the command (replace <code>t01</code> with a valid budget code for your account):</p> <pre><code>module load perftools\nsrun --ntasks=1 --partition=standard --qos=short --account=t01 papi_native_avail -i cray_pm\n</code></pre>"},{"location":"user-guide/profile/#enabling-hardware-counter-data-collection","title":"Enabling hardware counter data collection","text":"<p>You enable the collection of hardware event counter data as part of a CrayPat  experiment by setting the environment variable <code>PAT_RT_PERFCTR</code> to a comma separated list of the groups/counters that you wish to measure.</p> <p>For example, you could set (usually in your job submission script):</p> <pre><code>export PAT_RT_PERFCTR=1\n</code></pre> <p>to use the <code>1</code> counter group (summary with branch activity).</p>"},{"location":"user-guide/profile/#analysing-hardware-counter-data","title":"Analysing hardware counter data","text":"<p>If you enabled collection of hardware event counters when running your profiling experiment, you will automatically get a report on the data when you use the  <code>pat_report</code> command to analyse the profile experiment data file.</p> <p>You will see information similar to the following in the output from CrayPat for different sections of your code (this example if for the case where  <code>export PAT_RT_PERFCTR=1</code>, counter group: summary with branch activity, was  set in the job submission script):</p> <pre><code>==============================================================================\n  USER / main\n------------------------------------------------------------------------------\n  Time%                                                   88.3% \n  Time                                               446.113787 secs\n  Imb. Time                                           33.094417 secs\n  Imb. Time%                                               6.9% \n  Calls                       0.002 /sec                    1.0 calls\n  PAPI_BR_TKN                 0.240G/sec    106,855,535,005.863 branch\n  PAPI_TOT_INS                5.679G/sec  2,533,386,435,314.367 instr\n  PAPI_BR_INS                 0.509G/sec    227,125,246,394.008 branch\n  PAPI_TOT_CYC                            1,243,344,265,012.828 cycles\n  Instr per cycle                                          2.04 inst/cycle\n  MIPS                 1,453,770.20M/sec                        \n  Average Time per Call                              446.113787 secs\n  CrayPat Overhead : Time      0.2%           \n</code></pre>"},{"location":"user-guide/profile/#using-the-craypat-api-to-gather-hardware-counter-data","title":"Using the CrayPAT API to gather hardware counter data","text":"<p>The CrayPAT API features a particular function, <code>PAT_counters</code>, that allows you to obtain the values of specific hardware counters at specific points within your code.</p> <p>For convenience, we have developed an MPI-based wrapper for this aspect of the CrayPAT API, called <code>pat_mpi_lib</code>, which can be found via the link below.</p> <p>https://github.com/cresta-eu/pat_mpi_lib</p> <p>The PAT MPI Library makes it possible to monitor a user-defined set of hardware performance counters during the execution of an MPI code running across multiple compute nodes. The library is lightweight, containing just four functions, and is intended to be straightforward to use. Once you've defined the hooks in your code for recording counter values, you can control which counters are read at runtime by setting the <code>PAT_RT_PERFCTR</code> environment variable in the job submission script. As your code executes, the defined set of counters will be read at various points. After each reading, the counter values are summed by rank 0 (via an MPI reduction) before being output to a log file.</p> <p>Further information along with test harnesses and example scripts can be found by reading the PAT MPI Library readme file.</p>"},{"location":"user-guide/profile/#more-information-on-hardware-counters","title":"More information on hardware counters","text":"<p>More information on using hardware counters can be found in the appropriate section of the HPE documentation:</p> <ul> <li>HPE Performance Analysis Tools User Guide</li> </ul> <p>Also available are two MPI-based wrapper libraries, one for Power Management (PM) counters that cover such properties as point-in-time power, cumulative energy use and temperature; and one that provides access to PAPI counters. See the links below for further details.</p> <ul> <li>Power Management MPI Library</li> <li>PAPI MPI Library</li> </ul>"},{"location":"user-guide/profile/#performance-and-profiling-data-in-slurm","title":"Performance and profiling data in Slurm","text":"<p>Slurm commands on the login nodes can be used to quickly and simply retrieve information about memory usage for currently running and completed jobs.</p> <p>There are three commands you can use on ARCHER2 to query job data from  Slurm, two are standard Slurm commands and one is a script that provides information on running jobs:</p> <ul> <li>The <code>sstat</code> command is used to display status information of a running   job or job step</li> <li>The <code>sacct</code> command is used to display accounting data for all finished   jobs and job steps within the Slurm job database.</li> <li>The <code>archer2jobload</code> command is used to show CPU and memory usage information   for running jobs. (This script is based on one originally written for the   COSMA HPC facility at the University of   Durham.)</li> </ul> <p>We provide examples of the use of these three commands below.</p> <p>For the <code>sacct</code> and <code>sstat</code> command, the memory properties we print out below are:</p> <ul> <li><code>AveRSS</code> - The mean memory use per node over the length of the job</li> <li><code>MaxRSS</code> - The maximum memory use per node measured during the job</li> <li><code>MaxRSSTask</code> - The maximum memory use from any process in the job</li> </ul>"},{"location":"user-guide/profile/#example-1-sstat-for-running-jobs","title":"Example 1: <code>sstat</code> for running jobs","text":"<p>To display the current memory use of a running job with the ID 123456:</p> <pre><code>sstat --format=JobID,AveCPU,AveRSS,MaxRSS,MaxRSSTask -j 123456\n</code></pre>"},{"location":"user-guide/profile/#example-2-sacct-for-finished-jobs","title":"Example 2: <code>sacct</code> for finished jobs","text":"<p>To display the memory use of a completed job with the ID 123456:</p> <pre><code>sacct --format=JobID,JobName,AveRSS,MaxRSS,MaxRSSTask -j 123456\n</code></pre> <p>Another usage of <code>sacct</code> is to display when a job was submitted, started running and ended for a particular user:</p> <pre><code>sacct --format=JobID,Submit,Start,End -u auser\n</code></pre>"},{"location":"user-guide/profile/#example-3-archer2jobload-for-running-jobs","title":"Example 3: <code>archer2jobload</code> for running jobs","text":"<p>Using the <code>archer2jobload</code> command on its own with no options will show the current CPU and memory use across compute nodes for all running jobs.</p> <p>More usefully, you can provide a job ID to <code>archer2jobload</code> and it will show a summary of the CPU and memory use for a specific job. For example, to get the usage data for job 123456, you would use:</p> <pre><code>auser@ln01:~&gt; archer2jobload 123456\n# JOB: 123456\nCPU_LOAD            MEMORY              ALLOCMEM            FREE_MEM            TMP_DISK            NODELIST            \n127.35-127.86       256000              239872              169686-208172       0                   nid[001481,001638-00\n</code></pre> <p>This shows the minimum CPU load on a compute node is 126.04 (close to the limit of 128 cores) with the maximum load 127.41 (indicating all the nodes are being used evenly). The minimum free memory is 171893 MB and the maximum free memory is 177224 MB.</p> <p>If you add the <code>-l</code> option, you will see a breakdown per node:</p> <pre><code>auser@ln01:~&gt; archer2jobload -l 276236\n# JOB: 123456\nNODELIST            CPU_LOAD            MEMORY              ALLOCMEM            FREE_MEM            TMP_DISK            \nnid001481           127.86              256000              239872              169686              0                   \nnid001638           127.60              256000              239872              171060              0                   \nnid001639           127.64              256000              239872              171253              0                   \nnid001677           127.85              256000              239872              173820              0                   \nnid001678           127.75              256000              239872              173170              0                   \nnid001891           127.63              256000              239872              173316              0                   \nnid001921           127.65              256000              239872              207562              0                   \nnid001922           127.35              256000              239872              208172              0 \n</code></pre>"},{"location":"user-guide/profile/#further-help-with-slurm","title":"Further help with Slurm","text":"<p>The definitions of any variables discussed here and more usage information can be found in the man pages of <code>sstat</code> and <code>sacct</code>.</p>"},{"location":"user-guide/profile/#amd-prof","title":"AMD \u03bcProf","text":"<p>The AMD \u03bcProf tool provides capabilities for low-level profiling on AMD processors, see:</p> <ul> <li>AMD \u03bcProf</li> </ul>"},{"location":"user-guide/profile/#arm-forge","title":"Arm Forge","text":"<p>The Arm Forge tool also provides profiling capabilities. See:</p> <ul> <li>ARCHER2 Arm Forge documentation</li> </ul>"},{"location":"user-guide/python/","title":"Using Python","text":"<p>Python is supported on ARCHER2 both for running intensive parallel jobs and also as an analysis tool. This section describes how to use Python in either of these scenarios.</p> <p>The Python installations on ARCHER2 contain some of the most commonly used packages. If you wish to install additional Python packages, we recommend that you use the <code>pip</code> command, see the section entitled Installing your own Python packages (with pip).</p> <p>Important</p> <p>Python 2 is not supported on ARCHER2 as it has been deprecated since the start of 2020. </p> <p>Note</p> <p>When you log onto ARCHER2, no Python module is loaded by default. You will generally need to load the <code>cray-python</code> module to access the functionality described below.</p>"},{"location":"user-guide/python/#hpe-cray-python-distribution","title":"HPE Cray Python distribution","text":"<p>The recommended way to use Python on ARCHER2 is to use the HPE Cray Python distribution.</p> <p>The HPE Cray distribution provides Python 3 along with some of the most common packages used for scientific computation and data analysis. These include:</p> <ul> <li>numpy and scipy - built using GCC against HPE Cray LibSci</li> <li>mpi4py - built using GCC against HPE Cray MPICH</li> <li>dask</li> </ul> <p>The HPE Cray Python distribution can be loaded (either on the front-end or in a submission script) using:</p> <pre><code>module load cray-python\n</code></pre> <p>Tip</p> <p>The HPE Cray Python distribution is built using GCC compilers. If you wish to compile your own Python, C/C++ or Fortran code to use with HPE Cray Python, you should ensure that you compile using <code>PrgEnv-gnu</code> to make sure they are compatible.</p>"},{"location":"user-guide/python/#installing-your-own-python-packages-with-pip","title":"Installing your own Python packages (with pip)","text":"<p>Sometimes, you may need to setup a local custom Python environment such that it extends a centrally-installed <code>cray-python</code> module. By extend, we mean being able to install packages locally that are not provided by <code>cray-python</code>. This is necessary because some Python packages such as <code>mpi4py</code> must be built specifically for the ARCHER2 system and so are best provided centrally.</p> <p>You can do this by creating a lightweight virtual environment where the local packages can be installed. Further, this environment is created on top of an existing Python installation, known as the environment's base Python.</p> <p>Select the base Python by loading the <code>cray-python</code> module that you wish to extend.</p> <pre><code>auser@ln01:~&gt; module load cray-python\n</code></pre> <p>Next, create the virtual environment within a designated folder.</p> <pre><code>python -m venv --system-site-packages /work/t01/t01/auser/myvenv\n</code></pre> <p>In our example, the environment is created within a <code>myvenv</code> folder located on <code>/work</code>, which means the environment will be accessible from the compute nodes. The <code>--system-site-packages</code> option ensures this environment is based on the currently loaded <code>cray-python</code> module. See https://docs.python.org/3/library/venv.html for more details.</p> <p>You're now ready to activate your environment.</p> <pre><code>source /work/t01/t01/auser/myvenv/bin/activate\n</code></pre> <p>Tip</p> <p>The <code>myvenv</code> path uses a fictitious project code, <code>t01</code>, and username, <code>auser</code>. Please remember to replace those values with your actual project code and username. Alternatively, you could enter <code>${HOME/home/work}</code> in place of <code>/work/t01/t01/auser</code>. That command fragment expands <code>${HOME}</code> and then replaces the <code>home</code> part with <code>work</code>.</p> <p>Installing packages to your local environment can now be done as follows.</p> <pre><code>(myvenv) auser@ln01:~&gt; python -m pip install &lt;package name&gt;\n</code></pre> <p>Running <code>pip</code> directly as in <code>pip install &lt;package name&gt;</code> will also work, but we show the <code>python -m</code> approach as this is consistent with the way the virtual environment was created.</p> <p>And when you have finished installing packages, you can deactivate the environment by running the <code>deactivate</code> command.</p> <pre><code>(myvenv) auser@ln01:~&gt; deactivate\nauser@ln01:~&gt;\n</code></pre> <p>The packages you have installed will only be available once the local environment has been activated. So, when running code that requires these packages, you must first activate the environment, by adding the activation command to the submission script, as shown below.</p> <pre><code>#!/bin/bash --login\n\n#SBATCH --job-name=myvenv\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=64\n#SBATCH --cpus-per-task=2\n#SBATCH --time=00:10:00\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\nsource /work/t01/t01/auser/myvenv/bin/activate\n\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\nsrun --distribution=block:block --hint=nomultithread python ${SLURM_SUBMIT_DIR}/myvenv-script.py\n</code></pre> <p>Tip</p> <p>If you find that a module you've installed to a virtual environment on <code>/work</code> isn't found when running a job, it may be that it was previously installed to the default location of <code>$HOME/.local</code> which is not mounted on the compute nodes. This can be an issue as <code>pip</code> will reuse any modules found at this default location rather than reinstall them into a virtual environment. Thus, even if the virtual environment is on <code>/work</code>, a module you've asked for may actually be located on <code>/home</code>.</p> <p>You can check a module's install location and its dependencies with <code>pip show</code>, for example <code>pip show matplotlib</code>. You may then run <code>pip uninstall matplotlib</code> while no virtual environment is active to uninstall it from <code>$HOME/.local</code>, and then re-run <code>pip install matplotlib</code> while your virtual environment on <code>/work</code> is active to reinstall it there. You will need to do this for any modules installed on <code>/home</code> that will use either directly or indirectly. Remember you can check all your installed modules with <code>pip list</code>.</p> <p>Lastly, the environment being extended does not have to come from one of the centrally-installed <code>cray-python</code> modules. You can also create a local virtual environment based on one of the Machine Learning (ML) modules, e.g., <code>tensorflow</code> or <code>pytorch</code>. One extra command is required; it is issued immediately after the <code>python -m venv ...</code> command.</p> <pre><code>extend-venv-activate /work/t01/t01/auser/myvenv\n</code></pre> <p>The <code>extend-venv-activate</code> command merely adds some extra commands to the virtual environment's <code>activate</code> script, ensuring that the python packages will be gathered from the local virtual environment, the ML module and from the <code>cray-python</code> base module. All this means you would avoid having to install ML packages within your local area.</p> <p>Note</p> <p>The ML modules are themselves based on <code>cray-python</code>. For example, <code>tensorflow/2.12.0</code> is based on the <code>cray-python/3.9.13.1</code> module.</p>"},{"location":"user-guide/python/#running-python","title":"Running Python","text":""},{"location":"user-guide/python/#example-serial-python-submission-script","title":"Example serial Python submission script","text":"<pre><code>#!/bin/bash --login\n\n#SBATCH --job-name=python_test\n#SBATCH --ntasks=1\n#SBATCH --time=00:10:00\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=serial\n#SBATCH --qos=serial\n\n# Load the Python module, ...\nmodule load cray-python\n\n# ..., or, if using local virtual environment\nsource &lt;&lt;path to virtual environment&gt;&gt;/bin/activate\n\n# Run your Python program\npython python_test.py\n</code></pre>"},{"location":"user-guide/python/#example-mpi4py-job-submission-script","title":"Example mpi4py job submission script","text":"<p>Programs that have been parallelised with mpi4py can be run on the ARCHER2 compute nodes. Unlike the serial Python submission script however, we must launch the Python interpreter using <code>srun</code>. Failing to do so will result in Python running a single MPI rank only. </p> <pre><code>#!/bin/bash --login\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=mpi4py_test\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --time=0:10:0\n\n# Replace [budget code] below with your budget code (e.g. t01)\n#SBATCH --account=[budget code]\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the Python module, ...\nmodule load cray-python\n\n# ..., or, if using local virtual environment\nsource &lt;&lt;path to virtual environment&gt;&gt;/bin/activate\n\n# Pass cpus-per-task setting to srun\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Run your Python program\n#   Note that srun MUST be used to wrap the call to python,\n#   otherwise your code will run serially\nsrun --distribution=block:block --hint=nomultithread python mpi4py_test.py\n</code></pre> <p>Tip</p> <p>If you have installed your own packages you will need to activate your local Python environment within your job submission script as shown at the end of Installing your own Python packages (with pip).</p>"},{"location":"user-guide/python/#using-jupyterlab-on-archer2","title":"Using JupyterLab on ARCHER2","text":"<p>It is possible to view and run Jupyter notebooks from both login nodes  and compute nodes on ARCHER2.</p> <p>Note</p> <p>You can test such notebooks on the login nodes, but please do not attempt to run any computationally intensive work. Jobs may get killed once they hit a CPU limit on login nodes.</p> <p>Please follow these steps.</p> <ol> <li> <p>Install JupyterLab in your work directory.    <pre><code>module load cray-python\nexport PYTHONUSERBASE=/work/t01/t01/auser/.local\nexport PATH=$PYTHONUSERBASE/bin:$PATH\n# source &lt;&lt;path to virtual environment&gt;&gt;/bin/activate  # If using a virtualenvironment uncomment this line and remove the --user flag from the next\n\npip install --user jupyterlab\n</code></pre></p> </li> <li> <p>If you want to test JupyterLab on the login node please go straight to step 3.    To run your Jupyter notebook on a compute node, you first need to run an interactive session.    <pre><code>srun --nodes=1 --exclusive --time=00:20:00 --account=&lt;your_budget&gt; \\\n     --partition=standard --qos=short --reservation=shortqos \\\n     --pty /bin/bash\n</code></pre>    Your prompt will change to something like below.    <pre><code>auser@nid001015:/tmp&gt;\n</code></pre>    In this case, the node id is <code>nid001015</code>. Now execute the following on the compute node.    <pre><code>cd /work/t01/t01/auser # Update the path to your work directory\nexport PYTHONUSERBASE=$(pwd)/.local\nexport PATH=$PYTHONUSERBASE/bin:$PATH\nexport HOME=$(pwd)\nmodule load cray-python\n# source &lt;&lt;path to virtual environment&gt;&gt;/bin/activate  # If using a virtualenvironment uncomment this line\n</code></pre></p> </li> <li> <p>Run the JupyterLab server.    <pre><code>export JUPYTER_RUNTIME_DIR=$(pwd)\njupyter lab --ip=0.0.0.0 --no-browser\n</code></pre>    Once it's started, you will see a URL printed in the terminal window of     the form <code>http://127.0.0.1:&lt;port_number&gt;/lab?token=&lt;string&gt;</code>; we'll need this URL for    step 6.</p> </li> <li> <p>Please skip this step if you are connecting from a machine running Windows.    Open a new terminal window on your laptop and run the following command.    <pre><code>ssh &lt;username&gt;@login.archer2.ac.uk -L&lt;port_number&gt;:&lt;node_id&gt;:&lt;port_number&gt;\n</code></pre>    where <code>&lt;username&gt;</code> is your username, and <code>&lt;node_id&gt;</code> is the id of the node you're     currently on (for a login node, this will be <code>ln01</code>, or similar; on a compute     node, it will be a mix of numbers and letters). In our example, <code>&lt;node_id&gt;</code>    is <code>nid001015</code>. Note, please use the same port number as that shown in the URL of    step 3. This number may vary, likely values are 8888 or 8889.</p> </li> <li> <p>Please skip this step if you are connecting from Linux or macOS. If you are connecting from Windows, you should use MobaXterm to configure an SSH tunnel as follows.</p> <ul> <li>Click on the <code>Tunnelling</code> button above the MobaXterm terminal. Create a new tunnel by clicking on <code>New SSH tunnel</code> in the window that opens.</li> <li>In the new window that opens, make sure the <code>Local port forwarding</code> radio button is selected.</li> <li>In the <code>forwarded port</code> text box on the left under <code>My computer with MobaXterm</code>, enter the port number indicated in the JupyterLab server output (e.g., 8888 or 8890).</li> <li>In the three text boxes on the bottom right under <code>SSH server</code> enter <code>login.archer2.ac.uk</code>, your ARCHER2 username and then <code>22</code>.</li> <li>At the top right, under <code>Remote server</code>, enter the id of the login or compute node running the JupyterLab server and the associated port number.</li> <li>Click on the <code>Save</code> button.</li> <li>In the tunnelling window, you will now see a new row for the settings you just entered. If you like, you can give a name to the tunnel in the leftmost column to identify it.</li> <li>Click on the small key icon close to the right for the new connection to tell MobaXterm which SSH private key to use when connecting to ARCHER2. You should tell it to use the same <code>.ppk</code> private key that you normally use when connecting to ARCHER2.</li> <li>The tunnel should now be configured. Click on the small start button (like a play '&gt;' icon) for the new tunnel to open it. You'll be asked to enter your ARCHER2 account password -- please do so.</li> </ul> </li> <li> <p>Now, if you open a browser window locally, you should be able to navigate to the URL    from step 3, and this should display the JupyterLab server. If JupyterLab is running    on a compute node, the notebook will be available for the length of the interactive    session you have requested.</p> </li> </ol> <p>Warning</p> <p>Please do not use the other http address given by the JupyterLab output, the one formatted <code>http://&lt;node_id&gt;:&lt;port_number&gt;/lab?token=&lt;string&gt;</code>. Your local browser will not recognise the <code>&lt;node_id&gt;</code> part of the address.</p>"},{"location":"user-guide/python/#using-dask-job-queue-on-archer2","title":"Using Dask Job-Queue on ARCHER2","text":"<p>The Dask-jobqueue project makes it easy to deploy Dask on ARCHER2.  You can find more information in  the Dask Job-Queue documentation.</p> <p>Please follow these steps:</p> <ol> <li>Install Dask-Jobqueue</li> </ol> <pre><code>module load cray-python\nexport PYTHONUSERBASE=/work/t01/t01/auser/.local\nexport PATH=$PYTHONUSERBASE/bin:$PATH\n\npip install --user dask-jobqueue --upgrade\n</code></pre> <ol> <li>Using Dask</li> </ol> <p>Dask-jobqueue creates a Dask Scheduler in the Python process where the cluster object is instantiated. A script for running dask jobs on ARCHER2 might look something like this:</p> <pre><code>from dask_jobqueue import SLURMCluster\ncluster = SLURMCluster(cores=128, \n                       processes=16,\n                       memory='256GB',\n                       queue='standard',\n                       header_skip=['--mem'],\n                       job_extra=['--qos=\"standard\"'],\n                       python='srun python',\n                       project='z19',\n                       walltime=\"01:00:00\",\n                       shebang=\"#!/bin/bash --login\",\n                       local_directory='$PWD',\n                       interface='hsn0',\n                       env_extra=['module load cray-python',\n                                  'export PYTHONUSERBASE=/work/t01/t01/auser/.local/',\n                                  'export PATH=$PYTHONUSERBASE/bin:$PATH',\n                                  'export PYTHONPATH=$PYTHONUSERBASE/lib/python3.8/site-packages:$PYTHONPATH'])\n\n\n\ncluster.scale(jobs=2)    # Deploy two single-node jobs\n\nfrom dask.distributed import Client\nclient = Client(cluster)  # Connect this local process to remote workers\n\n# wait for jobs to arrive, depending on the queue, this may take some time\nimport dask.array as da\nx = \u2026              # Dask commands now use these distributed resources\n</code></pre> <p>This script can be run on the login nodes and it submits the Dask jobs to the job queue. Users should ensure that the computationally intensive work is done with the Dask commands which run on the compute nodes.</p> <p>The cluster object parameters specify the characteristics for running on a single compute node. The header_skip option is required as we are running on exclusive nodes where you should not specify the memory requirements, however Dask requires you to supply this option.</p> <p>Jobs are be deployed with the cluster.scale command, where the jobs option sets the number of single node jobs requested. Job scripts are generated (from the cluster object) and these are submitted to the queue to begin  running once the resources are available. You can check the status of the jobs by  running <code>squeue -u $USER</code> in a separate terminal.</p> <p>If you wish to see the generated job script you can use:</p> <pre><code>print(cluster.job_script())\n</code></pre>"},{"location":"user-guide/scheduler/","title":"Running jobs on ARCHER2","text":"<p>As with most HPC services, ARCHER2 uses a scheduler to manage access to resources and ensure that the thousands of different users of system are able to share the system and all get access to the resources they require. ARCHER2 uses the Slurm software to schedule jobs.</p> <p>Writing a submission script is typically the most convenient way to submit your job to the scheduler. Example submission scripts (with explanations) for the most common job types are provided below.</p> <p>Interactive jobs are also available and can be particularly useful for developing and debugging applications. More details are available below.</p> <p>Hint</p> <p>If you have any questions on how to run jobs on ARCHER2 do not hesitate to contact the ARCHER2 Service Desk.</p> <p>You typically interact with Slurm by issuing Slurm commands from the login nodes (to submit, check and cancel jobs), and by specifying Slurm directives that describe the resources required for your jobs in job submission scripts.</p>"},{"location":"user-guide/scheduler/#resources","title":"Resources","text":""},{"location":"user-guide/scheduler/#cus","title":"CUs","text":"<p>Time used on ARCHER2 is measured in CUs. 1 CU = 1 Node Hour for a standard 128 core node.</p> <p>The CU calculator will help you to calculate the CU cost for your jobs.</p>"},{"location":"user-guide/scheduler/#checking-available-budget","title":"Checking available budget","text":"<p>You can check in SAFE by selecting <code>Login accounts</code> from the menu, select the login account you want to query.</p> <p>Under <code>Login account details</code> you will see each of the budget codes you have access to listed e.g. <code>e123 resources</code> and then under Resource Pool to the right of this, a note of the remaining budget in CUs. </p> <p>When logged in to the machine you can also use the command </p> <pre><code>sacctmgr show assoc where user=$LOGNAME format=account,user,maxtresmins\n</code></pre> <p>This will list all the budget codes that you have access to e.g.</p> <pre><code>   Account       User   MaxTRESMins\n---------- ---------- -------------\n      e123      userx         cpu=0\n e123-test      userx\n</code></pre> <p>This shows that <code>userx</code> is a member of budgets <code>e123</code> and <code>e123-test</code>.  However, the <code>cpu=0</code> indicates that the <code>e123</code> budget is empty or disabled.   This user can submit jobs using the <code>e123-test</code> budget.</p> <p>To see the number of CUs remaining you must check in SAFE.</p>"},{"location":"user-guide/scheduler/#charging","title":"Charging","text":"<p>Jobs run on ARCHER2 are charged for the time they use i.e. from the time the job begins to run until the time the job ends (not the full wall time requested).</p> <p>Jobs are charged for the full number of nodes which are requested, even if they are not all used.</p> <p>Charging takes place at the time the job ends, and the job is charged in full to the budget which is live at the end time.</p>"},{"location":"user-guide/scheduler/#basic-slurm-commands","title":"Basic Slurm commands","text":"<p>There are four key commands used to interact with the Slurm on the command line:</p> <ul> <li><code>sinfo</code> - Get information on the partitions and resources available</li> <li><code>sbatch jobscript.slurm</code> - Submit a job submission script (in this     case called: <code>jobscript.slurm</code>) to the scheduler</li> <li><code>squeue</code> - Get the current status of jobs submitted to the scheduler</li> <li><code>scancel 12345</code> - Cancel a job (in this case with the job ID     <code>12345</code>)</li> </ul> <p>We cover each of these commands in more detail below.</p>"},{"location":"user-guide/scheduler/#sinfo-information-on-resources","title":"<code>sinfo</code>: information on resources","text":"<p><code>sinfo</code> is used to query information about available resources and partitions. Without any options, <code>sinfo</code> lists the status of all resources and partitions, e.g.</p> <pre><code>auser@ln01:~&gt; sinfo \n\nPARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST \nstandard     up 1-00:00:00    105  down* nid[001006,...,002014]\nstandard     up 1-00:00:00     12  drain nid[001016,...,001969]\nstandard     up 1-00:00:00      5   resv nid[001000,001002-001004,001114] \nstandard     up 1-00:00:00    683  alloc nid[001001,...,001970-001991] \nstandard     up 1-00:00:00    214   idle nid[001022-001023,...,002015-002023]\nstandard     up 1-00:00:00      2   down nid[001021,001050]\n</code></pre> <p>Here we see the number of nodes in different states. For example, 683 nodes are allocated (running jobs), and 214 are idle (available to run jobs).</p> <p>Note</p> <p>that long lists of node IDs have been abbreviated with <code>...</code>.</p>"},{"location":"user-guide/scheduler/#sbatch-submitting-jobs","title":"<code>sbatch</code>: submitting jobs","text":"<p><code>sbatch</code> is used to submit a job script to the job submission system. The script will typically contain one or more <code>srun</code> commands to launch parallel tasks.</p> <p>When you submit the job, the scheduler provides the job ID, which is used to identify this job in other Slurm commands and when looking at resource usage in SAFE.</p> <pre><code>auser@ln01:~&gt; sbatch test-job.slurm\nSubmitted batch job 12345\n</code></pre>"},{"location":"user-guide/scheduler/#squeue-monitoring-jobs","title":"<code>squeue</code>: monitoring jobs","text":"<p><code>squeue</code> without any options or arguments shows the current status of all jobs known to the scheduler. For example:</p> <pre><code>auser@ln01:~&gt; squeue\n</code></pre> <p>will list all jobs on ARCHER2.</p> <p>The output of this is often overwhelmingly large. You can restrict the output to just your jobs by adding the <code>-u $USER</code> option:</p> <pre><code>auser@ln01:~&gt; squeue -u $USER\n</code></pre>"},{"location":"user-guide/scheduler/#scancel-deleting-jobs","title":"<code>scancel</code>: deleting jobs","text":"<p><code>scancel</code> is used to delete a jobs from the scheduler. If the job is waiting to run it is simply cancelled, if it is a running job then it is stopped immediately.</p> <p>If you only want to cancel a specific job you need to provide the job ID of the job you wish to cancel/stop. For example:</p> <pre><code>auser@ln01:~&gt; scancel 12345\n</code></pre> <p>will cancel (if waiting) or stop (if running) the job with ID <code>12345</code>.</p> <p><code>scancel</code> can take other options. For example, if you want to cancel all your pending (queued) jobs but leave the running jobs running, you could use:</p> <pre><code>auser@ln01:~&gt; scancel --state=PENDING --user=$USER\n</code></pre>"},{"location":"user-guide/scheduler/#resource-limits","title":"Resource Limits","text":"<p>The ARCHER2 resource limits for any given job are covered by three separate attributes.</p> <ul> <li>The amount of primary resource you require, i.e., number of     compute nodes.</li> <li>The partition that you want to use - this specifies the nodes that     are eligible to run your job.</li> <li>The Quality of Service (QoS) that you want to use - this specifies     the job limits that apply.</li> </ul>"},{"location":"user-guide/scheduler/#primary-resource","title":"Primary resource","text":"<p>The primary resource you can request for your job is the compute node.</p> <p>Information</p> <p>The <code>--exclusive</code> option is enforced on ARCHER2 which means you will always have access to all of the memory on the compute node regardless of how many processes are actually running on the node.</p> <p>Note</p> <p>You will not generally have access to the full amount of memory resource on the the node as some is retained for running the operating system and other system processes.</p>"},{"location":"user-guide/scheduler/#partitions","title":"Partitions","text":"<p>On ARCHER2, compute nodes are grouped into partitions. You will have to specify a partition using the <code>--partition</code> option in your Slurm submission script. The following table has a list of active partitions on ARCHER2.</p> Full system Partition Description Max nodes available standard CPU nodes with AMD EPYC 7742 64-core processor \u00d7 2, 256/512 GB memory 5860 highmem CPU nodes with AMD EPYC 7742 64-core processor \u00d7 2, 512 GB memory 584 serial CPU nodes with AMD EPYC 7742 64-core processor \u00d7 2, 512 GB memory 2 <p>Note</p> <p>The <code>standard</code> partition includes both the standard memory and high memory nodes but standard memory nodes are preferentially chosen for jobs where possible. To guarantee access to high memory nodes you should specify the <code>highmem</code> partition.</p>"},{"location":"user-guide/scheduler/#quality-of-service-qos","title":"Quality of Service (QoS)","text":"<p>On ARCHER2, job limits are defined by the requested Quality of Service (QoS), as specified by the <code>--qos</code> Slurm directive. The following table lists the active QoS on ARCHER2.</p> Full system QoS Max Nodes Per Job Max Walltime Jobs Queued Jobs Running Partition(s) Notes standard 1024 24 hrs 64 16 standard Maximum of 1024 nodes in use by any one user at any time highmem 256 24 hrs 16 16 highmem Maximum of 512 nodes in use by any one user at any time taskfarm 16 24 hrs 128 32 standard Maximum of 256 nodes in use by any one user at any time short 32 20 mins 16 4 standard long 64 48 hrs 16 16 standard Minimum walltime of 24 hrs, maximum 512 nodes in use by any one user at any time, maximum of 2048 nodes in use by QoS largescale 5860 12 hrs 8 1 standard Minimum job size of 1025 nodes lowpriority 2048 24 hrs 16 16 standard Jobs not charged but requires at least 1 CU in budget to use. serial 32 cores and/or 128 GB memory 24 hrs 32 4 serial Jobs not charged but requires at least 1 CU in budget to use. Maximum of 32 cores and/or 128 GB in use by any one user at any time. reservation Size of reservation Length of reservation No limit no limit standard <p>You can find out the QoS that you can use by running the following command:</p> Full system <pre><code>auser@ln01:~&gt; sacctmgr show assoc user=$USER cluster=archer2 format=cluster,account,user,qos%50\n</code></pre> <p>Hint</p> <p>If you have needs which do not fit within the current QoS, please contact the Service Desk and we can discuss how to accommodate your requirements.</p>"},{"location":"user-guide/scheduler/#e-mail-notifications","title":"E-mail notifications","text":"<p>E-mail notifications from the scheduler are not currently available on ARCHER2.</p>"},{"location":"user-guide/scheduler/#priority","title":"Priority","text":"<p>Job priority on ARCHER2 depends on a number of different factors:</p> <ul> <li>The QoS your job has specified</li> <li>The amount of time you have been queuing for</li> <li>The number of nodes you have requested (job size)</li> <li>Your current fairshare factor</li> </ul> <p>Each of these factors is normalised to a value between 0 and 1, is multiplied with a weight and the resulting values combined to produce a priority for the job.  The current job priority formula on ARCHER2 is:</p> <pre><code>Priority = [10000 * P(QoS)] + [500 * P(Age)] + [300 * P(Fairshare)] + [100 * P(size)]\n</code></pre> <p>The priority factors are:</p> <ul> <li>P(QoS) - The QoS priority normalised to a value between 0 and 1. The maximum raw   value is 10000 and the minimum is 0. Most QoS on ARCHER2 have a raw prioity of 500; the   <code>lowpriority</code> QoS has a raw priority of 1.</li> <li>P(Age) - The priority based on the job age normalised to a value between 0 and 1.   The maximum raw value is 14 days (where P(Age) = 1).</li> <li>P(Fairshare) - The fairshare priority normalised to a value between 0 and 1. Your   fairshare priority is determined by a combination of your budget code fairshare    value and your user fairshare value within that budget code. The more use that    the budget code you are using has made of the system recently relative to other    budget codes on the system, the lower the budget code fairshare value will be; and the more   use you have made of the system recently relative to other users within your   budget code, the lower your user fairshare value will be. The decay half life    for fairshare on ARCHER2 is set to 2 days. More information on the Slurm fairshare   algorithm.</li> <li>P(Size) - The priority based on the job size normalised to a value between 0 and 1.   The maximum size is the total number of ARCHER2 compute nodes.</li> </ul> <p>You can view the priorities for current queued jobs on the system with the <code>sprio</code> command:</p> <pre><code>auser@ln04:~&gt; sprio -l\n          JOBID PARTITION   PRIORITY       SITE        AGE  FAIRSHARE    JOBSIZE        QOS\n         828764 standard        1049          0         45          0          4       1000\n         828765 standard        1049          0         45          0          4       1000\n         828770 standard        1049          0         45          0          4       1000\n         828771 standard        1012          0          8          0          4       1000\n         828773 standard        1012          0          8          0          4       1000\n         828791 standard        1012          0          8          0          4       1000\n         828797 standard        1118          0        115          0          4       1000\n         828800 standard        1154          0        150          0          4       1000\n         828801 standard        1154          0        150          0          4       1000\n         828805 standard        1118          0        115          0          4       1000\n         828806 standard        1154          0        150          0          4       1000\n</code></pre>"},{"location":"user-guide/scheduler/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/scheduler/#slurm-error-messages","title":"Slurm error messages","text":"<p>An incorrect submission will cause Slurm to return an error. Some common problems are listed below, with a suggestion about the likely cause:</p> <ul> <li> <p><code>sbatch: unrecognized option &lt;text&gt;</code></p> <p>One of your options is invalid or has a typo. <code>man sbatch</code> to help.</p> </li> <li> <p><code>error: Batch job submission failed: No partition specified or system default partition</code></p> <p>A <code>--partition=</code> option is missing. You must specify the partition (see the list above). This is most often <code>--partition=standard</code>.</p> </li> <li> <p><code>error: invalid partition specified: &lt;partition&gt;</code></p> <p><code>error: Batch job submission failed: Invalid partition name specified</code></p> <p>Check the partition exists and check the spelling is correct.</p> </li> <li> <p><code>error: Batch job submission failed: Invalid account or account/partition combination specified</code></p> <p>This probably means an invalid account has been given. Check the <code>--account=</code> options against valid accounts in SAFE.</p> </li> <li> <p><code>error: Batch job submission failed: Invalid qos specification</code></p> <p>A QoS option is either missing or invalid. Check the script has a <code>--qos=</code> option and that the option is a valid one from the table above. (Check the spelling of the QoS is correct.)</p> </li> <li> <p><code>error: Your job has no time specification (--time=)...</code></p> <p>Add an option of the form <code>--time=hours:minutes:seconds</code> to the submission script. E.g., <code>--time=01:30:00</code> gives a time limit of 90 minutes.</p> </li> <li> <p><code>error: QOSMaxWallDurationPerJobLimit</code> <code>error: Batch job submission failed: Job violates accounting/QOS policy</code> <code>(job submit limit, user's size and/or time limits)</code></p> <p>The script has probably specified a time limit which is too long for the corresponding QoS. E.g., the time limit for the short QoS is 20 minutes.</p> </li> </ul>"},{"location":"user-guide/scheduler/#slurm-job-state-codes","title":"Slurm job state codes","text":"<p>The <code>squeue</code> command allows users to view information for jobs managed by Slurm. Jobs typically go through the following states: PENDING, RUNNING, COMPLETING, and COMPLETED. The first table provides a description of some job state codes. The second table provides a description of the reasons that cause a job to be in a state.</p> Status Code Description PENDING PD Job is awaiting resource allocation. RUNNING R Job currently has an allocation. SUSPENDED S Job currently has an allocation. COMPLETING CG Job is in the process of completing. Some processes on some nodes may still be active. COMPLETED CD Job has terminated all processes on all nodes with an exit code of zero. TIMEOUT TO Job terminated upon reaching its time limit. STOPPED ST Job has an allocation, but execution has been stopped with SIGSTOP signal. CPUS have been retained by this job. OUT_OF_MEMORY OOM Job experienced out of memory error. FAILED F Job terminated with non-zero exit code or other failure condition. NODE_FAIL NF Job terminated due to failure of one or more allocated nodes. CANCELLED CA Job was explicitly cancelled by the user or system administrator. The job may or may not have been initiated. <p>For a full list of see Job State Codes.</p>"},{"location":"user-guide/scheduler/#slurm-queued-reasons","title":"Slurm queued reasons","text":"Reason Description Priority One or more higher priority jobs exist for this partition or advanced reservation. Resources The job is waiting for resources to become available. BadConstraints The job's constraints can not be satisfied. BeginTime The job's earliest start time has not yet been reached. Dependency This job is waiting for a dependent job to complete. Licenses The job is waiting for a license. WaitingForScheduling No reason has been set for this job yet. Waiting for the scheduler to determine the appropriate reason. Prolog Its PrologSlurmctld program is still running. JobHeldAdmin The job is held by a system administrator. JobHeldUser The job is held by the user. JobLaunchFailure The job could not be launched. This may be due to a file system problem, invalid program name, etc. NonZeroExitCode The job terminated with a non-zero exit code. InvalidAccount The job's account is invalid. InvalidQOS The job's QOS is invalid. QOSUsageThreshold Required QOS threshold has been breached. QOSJobLimit The job's QOS has reached its maximum job count. QOSResourceLimit The job's QOS has reached some resource limit. QOSTimeLimit The job's QOS has reached its time limit. NodeDown A node required by the job is down. TimeLimit The job exhausted its time limit. ReqNodeNotAvail Some node specifically required by the job is not currently available. The node may currently be in use, reserved for another job, in an advanced reservation, DOWN, DRAINED, or not responding. Nodes which are DOWN, DRAINED, or not responding will be identified as part of the job's \"reason\" field as \"UnavailableNodes\". Such nodes will typically require the intervention of a system administrator to make available. <p>For a full list of see Job Reasons.</p>"},{"location":"user-guide/scheduler/#output-from-slurm-jobs","title":"Output from Slurm jobs","text":"<p>Slurm places standard output (STDOUT) and standard error (STDERR) for each job in the file <code>slurm_&lt;JobID&gt;.out</code>. This file appears in the job's working directory once your job starts running.</p> <p>Hint</p> <p>Output may be buffered - to enable live output, e.g. for monitoring job status, add <code>--unbuffered</code> to the <code>srun</code> command in your Slurm script.</p>"},{"location":"user-guide/scheduler/#specifying-resources-in-job-scripts","title":"Specifying resources in job scripts","text":"<p>You specify the resources you require for your job using directives at the top of your job submission script using lines that start with the directive <code>#SBATCH</code>.</p> <p>Hint</p> <p>Most options provided using <code>#SBATCH</code> directives can also be specified as command line options to <code>srun</code>.</p> <p>If you do not specify any options, then the default for each option will be applied. As a minimum, all job submissions must specify the budget that they wish to charge the job too with the option:</p> <ul> <li><code>--account=&lt;budgetID&gt;</code> your budget ID is usually something like      <code>t01</code> or <code>t01-test</code>. You can see which budget codes you can charge      to in SAFE.</li> </ul> <p>Other common options that are used are:</p> <ul> <li><code>--time=&lt;hh:mm:ss&gt;</code> the maximum walltime for your job. e.g. For      a 6.5 hour walltime, you would use <code>--time=6:30:0</code>.</li> <li><code>--job-name=&lt;jobname&gt;</code> set a name for the job to help identify it      in Slurm</li> </ul> <p>To prevent the behaviour of batch scripts being dependent on the user environment at the point of submission, the option</p> <ul> <li><code>--export=none</code> prevents the user environment from being exported      to the batch system.</li> </ul> <p>Using the <code>--export=none</code> means that the behaviour of batch submissions should be repeatable. We strongly recommend its use.</p>"},{"location":"user-guide/scheduler/#additional-options-for-parallel-jobs","title":"Additional options for parallel jobs","text":"<p>Note</p> <p>For parallel jobs, ARCHER2 operates in a node exclusive way. This means that you are assigned resources in the units of full compute nodes for your jobs (i.e. 128 cores) and that no other user can share those compute nodes with you. Hence, the minimum amount of resource you can request for a parallel job is 1 node (or 128 cores).</p> <p>In addition, parallel jobs will also need to specify how many nodes, parallel processes and threads they require.</p> <ul> <li><code>--nodes=&lt;nodes&gt;</code> the number of nodes to use for the job.</li> <li><code>--ntasks-per-node=&lt;processes per node&gt;</code> the number of parallel      processes (e.g. MPI ranks) per node.</li> <li><code>--cpus-per-task=1</code> if you are using parallel processes only with      no threading and you want to use all 128 cores on the node then you      should set the number of CPUs (cores) per parallel process to 1.      Important: if you are using threading (e.g. with OpenMP) or      you want to use less than 128 cores per node (e.g. to access more       memory or memory bandwidth per core) then you will need to change      this option as described below.</li> <li><code>--cpu-freq=&lt;freq. in kHz&gt;</code> set the CPU frequency for the compute       nodes. Valid values are <code>2250000</code> (2.25 GHz), <code>2000000</code> (2.0 GHz),      <code>1500000</code> (1.5 GHz). For more information on CPU frequency settings      and energy use see the Energy use section.</li> </ul> <p>For parallel jobs that use threading (e.g. OpenMP) or when you want to use less than 128 cores per node (e.g. to access more memory or memory bandwidth per core), you will also need to change the <code>--cpus-per-task</code> option.</p> <p>For jobs using threading:    - <code>--cpus-per-task=&lt;threads per task&gt;</code> the number of threads per      parallel process (e.g. number of OpenMP threads per MPI task for      hybrid MPI/OpenMP jobs). Important: you must also set the      <code>OMP_NUM_THREADS</code> environment variable if using OpenMP in your      job.</p> <p>For jobs using less than 128 cores per node:    - <code>--cpus-per-task=&lt;stride between placement of processes&gt;</code> the stride      between the parallel processes. For example, if oyu want to double the      memory and memory bandwidth per process on an ARCHER2 compute node you      would want to place 64 processes per node and leave an empty core between      each process you would set <code>--cpus-per-task=2</code> and <code>--ntasks-per-node=64</code>.</p> <p>Important</p> <p>You must also add <code>export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK</code> to your job submission script to pass the <code>--cpus-per-task</code> setting from the job script to the <code>srun</code> command. (Alternatively, you could use the <code>--cpus-per-task</code> option in the srun command itself.) If you do not do this then the placement of processes/threads will be incorrect and you  will likely see poor performance of your application. </p>"},{"location":"user-guide/scheduler/#options-for-jobs-on-the-data-analysis-nodes","title":"Options for jobs on the data analysis nodes","text":"<p>The data analysis nodes are shared between all users and can be used to  run jobs that require small numbers of cores and/or access to an external network to transfer data. These jobs are often serial jobs that only require a single core.</p> <p>To run jobs on the data analysis node you require the following options:</p> <ul> <li><code>--partition=serial</code> to select the data analysis nodes</li> <li><code>--qos=serial</code> to select the data analysis QoS (see above for QoS limits)</li> <li><code>--ntasks=&lt;number of cores&gt;</code> to select the number of cores you want       to use in this job (up to the maximum defined in the QoS)</li> <li><code>--mem=&lt;amount of memory&gt;</code> to select the amount of memory you require       (up to the maximum defined in the QoS).</li> </ul> <p>More information on using the data analysis nodes (including example job submission scripts) can be found in the Data Analysis section of the User and Best Practice Guide.</p>"},{"location":"user-guide/scheduler/#srun-launching-parallel-jobs","title":"<code>srun</code>: Launching parallel jobs","text":"<p>If you are running parallel jobs, your job submission script should contain one or more <code>srun</code> commands to launch the parallel executable across the compute nodes. In most cases you will want to add the options <code>--distribution=block:block</code> and <code>--hint=nomultithread</code> to your  <code>srun</code> command to ensure you get the correct pinning of processes to  cores on a compute node.</p> <p>Warning</p> <p>If you do not add the <code>--distribution=block:block</code> and <code>--hint=nomultithread</code> options to your <code>srun</code> command the default process placement  may lead to a drop in performance for your jobs on ARCHER2.</p> <p>A brief explanation of these options:  - <code>--hint=nomultithread</code> - do not use hyperthreads/SMP  - <code>--distribution=block:block</code> - the first <code>block</code> means use a block distribution    of processes across nodes (i.e. fill nodes before moving onto the next one) and    the second <code>block</code> means use a block distribution of processes across \"sockets\"    within a node (i.e. fill a \"socket\" before moving on to the next one).</p> <p>Important</p> <p>The Slurm definition of a \"socket\" does not correspond to a physical CPU socket. On ARCHER2 it corresponds to a 4-core CCX (Core CompleX).</p>"},{"location":"user-guide/scheduler/#slurm-definition-of-a-socket","title":"Slurm definition of a \"socket\"","text":"<p>On ARCHER2, Slurm is configured with the following setting:</p> <pre><code>SlurmdParameters=l3cache_as_socket\n</code></pre> <p>The effect of this setting is to define a Slurm socket as a unit that has a shared L3 cache. On ARCHER2, this means that each Slurm \"socket\" corresponds to a 4-core  CCX (Core CompleX). For a more detailed discussion on the hardware and the memory/cache layout see the Hardware section.</p> <p>The effect of this setting can be illustrated by using the <code>xthi</code> program to report placement when we select a cyclic distribution of processes across sockets from srun (<code>--distribution=block:cyclic</code>). As you can see from the output from <code>xthi</code> included  below, the <code>cyclic</code> per-socket distribution results in sequential MPI processes being  placed on every 4th core (i.e. cyclic placement across CCX).</p> <pre><code>Node summary for    1 nodes:\nNode    0, hostname nid000006, mpi 128, omp   1, executable xthi_mpi\nMPI summary: 128 ranks \nNode    0, rank    0, thread   0, (affinity =    0) \nNode    0, rank    1, thread   0, (affinity =    4) \nNode    0, rank    2, thread   0, (affinity =    8) \nNode    0, rank    3, thread   0, (affinity =   12) \nNode    0, rank    4, thread   0, (affinity =   16) \nNode    0, rank    5, thread   0, (affinity =   20) \nNode    0, rank    6, thread   0, (affinity =   24) \nNode    0, rank    7, thread   0, (affinity =   28) \nNode    0, rank    8, thread   0, (affinity =   32) \nNode    0, rank    9, thread   0, (affinity =   36) \nNode    0, rank   10, thread   0, (affinity =   40) \nNode    0, rank   11, thread   0, (affinity =   44) \nNode    0, rank   12, thread   0, (affinity =   48) \nNode    0, rank   13, thread   0, (affinity =   52) \nNode    0, rank   14, thread   0, (affinity =   56) \nNode    0, rank   15, thread   0, (affinity =   60) \nNode    0, rank   16, thread   0, (affinity =   64) \nNode    0, rank   17, thread   0, (affinity =   68) \nNode    0, rank   18, thread   0, (affinity =   72) \nNode    0, rank   19, thread   0, (affinity =   76) \nNode    0, rank   20, thread   0, (affinity =   80) \nNode    0, rank   21, thread   0, (affinity =   84) \nNode    0, rank   22, thread   0, (affinity =   88) \nNode    0, rank   23, thread   0, (affinity =   92) \nNode    0, rank   24, thread   0, (affinity =   96) \nNode    0, rank   25, thread   0, (affinity =  100) \nNode    0, rank   26, thread   0, (affinity =  104) \nNode    0, rank   27, thread   0, (affinity =  108) \nNode    0, rank   28, thread   0, (affinity =  112) \nNode    0, rank   29, thread   0, (affinity =  116) \nNode    0, rank   30, thread   0, (affinity =  120) \nNode    0, rank   31, thread   0, (affinity =  124) \nNode    0, rank   32, thread   0, (affinity =    1) \nNode    0, rank   33, thread   0, (affinity =    5) \nNode    0, rank   34, thread   0, (affinity =    9) \nNode    0, rank   35, thread   0, (affinity =   13) \nNode    0, rank   36, thread   0, (affinity =   17) \nNode    0, rank   37, thread   0, (affinity =   21) \nNode    0, rank   38, thread   0, (affinity =   25) \n\n...output trimmed...\n</code></pre>"},{"location":"user-guide/scheduler/#bolt-job-submission-script-creation-tool","title":"bolt: Job submission script creation tool","text":"<p>The bolt job submission script creation tool has been written by EPCC to simplify the process of writing job submission scripts for modern multicore architectures. Based on the options you supply, bolt will generate a job submission script that uses ARCHER2 in a reasonable way.</p> <p>MPI, OpenMP and hybrid MPI/OpenMP jobs are supported.</p> <p>Warning</p> <p>The tool will allow you to generate scripts for jobs that use the <code>long</code> QoS but you will need to manually modify the resulting script to change the QoS to <code>long</code>.</p> <p>If there are problems or errors in your job parameter specifications then bolt will print warnings or errors. However, bolt cannot detect all problems.</p>"},{"location":"user-guide/scheduler/#basic-usage","title":"Basic Usage","text":"<p>The basic syntax for using bolt is:</p> <pre><code>bolt -n [parallel tasks] -N [parallel tasks per node] -d [number of threads per task] \\\n     -t [wallclock time (h:m:s)] -o [script name] -j [job name] -A [project code]  [arguments...]\n</code></pre> <p>Example 1: to generate a job script to run an executable called <code>my_prog.x</code> for 24 hours using 8192 parallel (MPI) processes and 128 (MPI) processes per compute node you would use something like:</p> <pre><code>bolt -n 8192 -N 128 -t 24:0:0 -o my_job.bolt -j my_job -A z01-budget my_prog.x arg1 arg2\n</code></pre> <p>(remember to substitute <code>z01-budget</code> for your actual budget code.)</p> <p>Example 2: to generate a job script to run an executable called <code>my_prog.x</code> for 3 hours using 2048 parallel (MPI) processes and 64 (MPI) processes per compute node (i.e. using half of the cores on a compute node), you would use:</p> <pre><code>bolt -n 2048 -N 64 -t 3:0:0 -o my_job.bolt -j my_job -A z01-budget my_prog.x arg1 arg2\n</code></pre> <p>These examples generate the job script <code>my_job.bolt</code> with the correct options to run <code>my_prog.x</code> with command line arguments <code>arg1</code> and <code>arg2</code>. The project code against which the job will be charged is specified with the ' -A ' option. As usual, the job script is submitted as follows:</p> <pre><code>sbatch my_job.bolt\n</code></pre> <p>Hint</p> <p>If you do not specify the script name with the '-o' option then your script will be a file called <code>a.bolt</code>.</p> <p>Hint</p> <p>If you do not specify the number of parallel tasks then bolt will try to generate a serial job submission script (and throw an error on the ARCHER2 4 cabinet system as serial jobs are not supported).</p> <p>Hint</p> <p>If you do not specify a project code, bolt will use your default project code (set by your login account).</p> <p>Hint</p> <p>If you do not specify a job name, bolt will use either <code>bolt_ser_job</code> (for serial jobs) or <code>bolt_par_job</code> (for parallel jobs).</p>"},{"location":"user-guide/scheduler/#further-help","title":"Further help","text":"<p>You can access further help on using bolt on ARCHER2 with the ' -h ' option:</p> <pre><code>bolt -h\n</code></pre> <p>A selection of other useful options are:</p> <ul> <li><code>-s</code> Write and submit the job script rather than just writing the      job script.</li> <li><code>-p</code> Force the job to be parallel even if it only uses a single      parallel task.</li> </ul>"},{"location":"user-guide/scheduler/#checkscript-job-submission-script-validation-tool","title":"checkScript job submission script validation tool","text":"<p>The checkScript tool has been written to allow users to validate their job submission scripts before submitting their jobs. The tool will read your job submission script and try to identify errors, problems or inconsistencies.</p> <p>An example of the sort of output the tool can give would be:</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; checkScript submit.slurm\n\n===========================================================================\ncheckScript\n---------------------------------------------------------------------------\nCopyright 2011-2020  EPCC, The University of Edinburgh\nThis program comes with ABSOLUTELY NO WARRANTY.\nThis is free software, and you are welcome to redistribute it\nunder certain conditions.\n===========================================================================\n\nScript details\n---------------\n       User: auser\nScript file: submit.slurm\n  Directory: /work/t01/t01/auser (ok)\n   Job name: test (ok)\n  Partition: standard (ok)\n        QoS: standard (ok)\nCombination:          (ok)\n\nRequested resources\n-------------------\n         nodes =              3                     (ok)\ntasks per node =             16\n cpus per task =              8\ncores per node =            128                     (ok)\nOpenMP defined =           True                     (ok)\n      walltime =          1:0:0                     (ok)\n\nCU Usage Estimate (if full job time used)\n------------------------------------------\n                      CU =          3.000\n\n\n\ncheckScript finished: 0 warning(s) and 0 error(s).\n</code></pre>"},{"location":"user-guide/scheduler/#checking-scripts-and-estimating-start-time-with-test-only","title":"Checking scripts and estimating start time with <code>--test-only</code>","text":"<p><code>sbatch --test-only</code> validates the batch script and returns an estimate of when the job would be scheduled to run given the current scheduler state. Please note that it is just an estimate, the actual start time may differ as the scheduler status when the start time was estimated may be different once the job is actually submitted and due to subsequent changes to the scheduler state. The job is not actually submitted.</p> <pre><code>auser@ln01:~&gt; sbatch --test-only submit.slurm\nsbatch: Job 1039497 to start at 2022-02-01T23:20:51 using 256 processors on nodes nid002836\nin partition standard\n</code></pre>"},{"location":"user-guide/scheduler/#example-job-submission-scripts","title":"Example job submission scripts","text":"<p>A subset of example job submission scripts are included in full below. Examples are provided for both the full system and the 4-cabinet system.</p>"},{"location":"user-guide/scheduler/#example-job-submission-script-for-mpi-parallel-job","title":"Example: job submission script for MPI parallel job","text":"<p>A simple MPI job submission script to submit a job using 4 compute nodes and 128 MPI ranks per node for 20 minutes would look like:</p> <pre><code>#!/bin/bash\n\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=Example_MPI_Job\n#SBATCH --time=0:20:0\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n\n# Replace [budget code] below with your budget code (e.g. t01)\n#SBATCH --account=[budget code]             \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Set the number of threads to 1\n#   This prevents any threaded system libraries from automatically \n#   using threading.\nexport OMP_NUM_THREADS=1\n\n# Propagate the cpus-per-task setting from script to srun commands\n#    By default, Slurm does not propagate this setting from the sbatch\n#    options to srun commands in the job script. If this is not done,\n#    process/thread pinning may be incorrect leading to poor performance\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Launch the parallel job\n#   Using 512 MPI processes and 128 MPI processes per node\n#   srun picks up the distribution from the sbatch options\n\nsrun --distribution=block:block --hint=nomultithread ./my_mpi_executable.x\n</code></pre> <p>This will run your executable \"my_mpi_executable.x\" in parallel on 512 MPI processes using 4 nodes (128 cores per node, i.e. not using hyper-threading). Slurm will allocate 4 nodes to your job and srun will place 128 MPI processes on each node (one per physical core).</p> <p>See above for a more detailed discussion of the different <code>sbatch</code> options</p>"},{"location":"user-guide/scheduler/#example-job-submission-script-for-mpiopenmp-mixed-mode-parallel-job","title":"Example: job submission script for MPI+OpenMP (mixed mode) parallel job","text":"<p>Mixed mode codes that use both MPI (or another distributed memory parallel model) and OpenMP should take care to ensure that the shared memory portion of the process/thread placement does not span more than one NUMA region. Nodes on ARCHER2 are made up of two sockets each containing 4 NUMA regions of 16 cores, i.e. there are 8 NUMA regions in total. Therefore the total number of threads should ideally not be greater than 16, and also needs to be a factor of 16. Sensible choices for the number of threads are therefore 1 (single-threaded), 2, 4, 8, and 16. More information about using OpenMP and MPI+OpenMP can be found in the Tuning chapter.</p> <p>To ensure correct placement of MPI processes the number of cpus-per-task needs to match the number of OpenMP threads, and the number of tasks-per-node should be set to ensure the entire node is filled with MPI tasks.</p> <p>In the example below, we are using 4 nodes for 6 hours. There are 32 MPI processes in total (8 MPI processes per node) and 16 OpenMP threads per MPI process. This results in all 128 physical cores per node being used.</p> <p>Hint</p> <p>Note the use of the <code>export OMP_PLACES=cores</code> environment option to generate the correct thread pinning.</p> <pre><code>#!/bin/bash\n\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=Example_MPI_Job\n#SBATCH --time=0:20:0\n#SBATCH --nodes=4\n#SBATCH --ntasks-per-node=8\n#SBATCH --cpus-per-task=16\n\n# Replace [budget code] below with your project code (e.g. t01)\n#SBATCH --account=[budget code] \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Propagate the cpus-per-task setting from script to srun commands\n#    By default, Slurm does not propagate this setting from the sbatch\n#    options to srun commands in the job script. If this is not done,\n#    process/thread pinning may be incorrect leading to poor performance\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Set the number of threads to 16 and specify placement\n#   There are 16 OpenMP threads per MPI process\n#   We want one thread per physical core\nexport OMP_NUM_THREADS=16\nexport OMP_PLACES=cores\n\n# Launch the parallel job\n#   Using 32 MPI processes\n#   8 MPI processes per node\n#   16 OpenMP threads per MPI process\n#   Additional srun options to pin one thread per physical core\nsrun --hint=nomultithread --distribution=block:block ./my_mixed_executable.x arg1 arg2\n</code></pre>"},{"location":"user-guide/scheduler/#job-arrays","title":"Job arrays","text":"<p>The Slurm job scheduling system offers the job array concept, for running collections of almost-identical jobs. For example, running the same program several times with different arguments or input data.</p> <p>Each job in a job array is called a subjob. The subjobs of a job array can be submitted and queried as a unit, making it easier and cleaner to handle the full set, compared to individual jobs.</p> <p>All subjobs in a job array are started by running the same job script. The job script also contains information on the number of jobs to be started, and Slurm provides a subjob index which can be passed to the individual subjobs or used to select the input data per subjob.</p>"},{"location":"user-guide/scheduler/#job-script-for-a-job-array","title":"Job script for a job array","text":"<p>As an example, the following script runs 56 subjobs, with the subjob index as the only argument to the executable. Each subjob requests a single node and uses all 128 cores on the node by placing 1 MPI process per core and specifies 4 hours maximum runtime per subjob:</p> <pre><code>#!/bin/bash\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=Example_Array_Job\n#SBATCH --time=04:00:00\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --array=0-55\n\n# Replace [budget code] below with your budget code (e.g. t01)\n#SBATCH --account=[budget code]  \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Propagate the cpus-per-task setting from script to srun commands\n#    By default, Slurm does not propagate this setting from the sbatch\n#    options to srun commands in the job script. If this is not done,\n#    process/thread pinning may be incorrect leading to poor performance\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Set the number of threads to 1\n#   This prevents any threaded system libraries from automatically \n#   using threading.\nexport OMP_NUM_THREADS=1\n\nsrun --distribution=block:block --hint=nomultithread /path/to/exe $SLURM_ARRAY_TASK_ID\n</code></pre>"},{"location":"user-guide/scheduler/#submitting-a-job-array","title":"Submitting a job array","text":"<p>Job arrays are submitted using <code>sbatch</code> in the same way as for standard jobs:</p> <pre><code>sbatch job_script.pbs \n</code></pre>"},{"location":"user-guide/scheduler/#job-chaining","title":"Job chaining","text":"<p>Job dependencies can be used to construct complex pipelines or chain together long simulations requiring multiple steps.</p> <p>Hint</p> <p>The <code>--parsable</code> option to <code>sbatch</code> can simplify working with job dependencies. It returns the job ID in a format that can be used as the input to other commands.</p> <p>For example:</p> <pre><code>jobid=$(sbatch --parsable first_job.sh)\nsbatch --dependency=afterok:$jobid second_job.sh\n</code></pre> <p>or for a longer chain:</p> <pre><code>jobid1=$(sbatch --parsable first_job.sh)\njobid2=$(sbatch --parsable --dependency=afterok:$jobid1 second_job.sh)\njobid3=$(sbatch --parsable --dependency=afterok:$jobid1 third_job.sh)\nsbatch --dependency=afterok:$jobid2,afterok:$jobid3 last_job.sh\n</code></pre>"},{"location":"user-guide/scheduler/#using-multiple-srun-commands-in-a-single-job-script","title":"Using multiple <code>srun</code> commands in a single job script","text":"<p>You can use multiple <code>srun</code> commands within in a Slurm job submission script to allow you to use the resource requested more flexibly. For example, you  could run a collection of smaller jobs within the requested resources or you could even subdivide nodes if your individual calculations do not scale up to use all 128 cores on a node.</p> <p>In this guide we will cover two scenarios:</p> <ol> <li>Subdividing the job into multiple full-node or multi-node subjobs, e.g.     requesting 100 nodes and running 100, 1-node subjobs or 50, 2-node      subjobs.</li> <li>Subdividing the job into multiple subjobs that each use a fraction of a     node, e.g. requesting 2 nodes and running 256, 1-core subjobs or 16,     16-core subjobs.</li> </ol>"},{"location":"user-guide/scheduler/#running-multiple-full-node-subjobs-within-a-larger-job","title":"Running multiple, full-node subjobs within a larger job","text":"<p>When subdivding a larger job into smaller subjobs you typically need to  overwrite the <code>--nodes</code> option to <code>srun</code> and add the <code>--ntasks</code> option to ensure that each subjob runs on the correct number of nodes and that subjobs are placed correctly onto separate nodes.</p> <p>For example, we will show how to request 100 nodes and then run 100 separate 1-node jobs, each of which use 128 MPI processes and which run on a different compute node. We start by showing  the job script that would achieve this and then explain how this works and the options used. In our case, we will run 100 copies of the <code>xthi</code>  program that prints the process placement on the node it is running on.</p> <pre><code>#!/bin/bash\n\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=multi_xthi\n#SBATCH --time=0:20:0\n#SBATCH --nodes=100\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n\n# Replace [budget code] below with your budget code (e.g. t01)\n#SBATCH --account=[budget code]             \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Load the xthi module\nmodule load xthi\n\n# Propagate the cpus-per-task setting from script to srun commands\n#    By default, Slurm does not propagate this setting from the sbatch\n#    options to srun commands in the job script. If this is not done,\n#    process/thread pinning may be incorrect leading to poor performance\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Set the number of threads to 1\n#   This prevents any threaded system libraries from automatically \n#   using threading.\nexport OMP_NUM_THREADS=1\n\n# Loop over 100 subjobs starting each of them on a separate node\nfor i in $(seq 1 100)\ndo\n# Launch this subjob on 1 node, note nodes and ntasks options and &amp; to place subjob in the background\nsrun --nodes=1 --ntasks=128 --distribution=block:block --hint=nomultithread xthi &gt; placement${i}.txt &amp;\ndone\n# Wait for all background subjobs to finish\nwait\n</code></pre> <p>Key points from the example job script:</p> <ul> <li>The <code>#SBATCH</code> options select 100 full nodes in the usual way.</li> <li>Each subjob <code>srun</code> command sets the following:<ul> <li><code>--nodes=1</code> We need override this setting from the main job so that each subjob only uses 1 node</li> <li><code>--ntasks=128</code> For normal jobs, the number of parallel tasks (MPI processes) is calculated from   the number of nodes you request and the number of tasks per node. We need to explicitly tell <code>srun</code>   how many we require for this subjob.</li> <li><code>--distribution=block:block --hint=nomultithread</code> These options ensure correct placement of   processes within the compute nodes.</li> <li><code>&amp;</code> Each subjob <code>srun</code> command ends with an ampersand to place the process in the background   and move on to the next loop iteration (and subjob submission). Without this, the script would   wait for this subjob to complete before moving on to submit the next.</li> </ul> </li> <li>Finally, there is the <code>wait</code> command to tell the script to wait for all the background subjobs to complete before exiting. If we did not have this in place, the script would exit as soon as the last subjob was submitted and kill all running subjobs.</li> </ul>"},{"location":"user-guide/scheduler/#running-multiple-subjobs-that-each-use-a-fraction-of-a-node","title":"Running multiple subjobs that each use a fraction of a node","text":"<p>As the ARCHER2 nodes contain a large number of cores (128 per node) it may sometimes be useful to be able to run multiple executables on a single node. For example, you may want to run 128 copies of a serial executable or Python script; or, you may want to run multiple copies of parallel executables that use fewer than 128 cores each. This use model is possible using  multiple <code>srun</code> commands in a job script on ARCHER2</p> <p>Note</p> <p>You can never share a compute node with another user. Although you can use <code>srun</code> to place multiple copies of an executable or script on a  compute node, you still have exclusive use of that node. The minimum amount of resources you can reserve for your use on ARCHER2 is a single node.</p> <p>When using <code>srun</code> to place multiple executables or scripts on a compute  node you must be aware of a few things:</p> <ul> <li>The <code>srun</code> command must specify any Slurm options that differ in value    from those specified to <code>sbatch</code>. This typically means that you need     to specify the <code>--nodes</code>, <code>--ntasks</code> and <code>--ntasks-per-node</code> options to <code>srun</code>.</li> <li>You will need to include the <code>--exact</code> flag to your <code>srun</code> command. With     this flag on, Slurm will ensure that the resources you request are assigned     to your subjob. Furthermore, if the resources are not currently available,     Slurm will output a message letting you know that this is the case and     stall the launch of this subjob until enough of your previous subjobs have     completed to free up the resources for this subjob.</li> <li>You will need to define the memory required by each subjob with the     <code>--mem=&lt;amount of memory&gt;</code> flag. The amount of memory is given in MiB     by default but other units can be specified. If you do not know how     much memory to specify, we recommend that you specify 1500M (1,500 MiB)     per core being used.</li> <li>You will need to place each <code>srun</code> command into the background and     then use the <code>wait</code> command at the end of the submission script to    make sure it does not exit before the commands are complete.</li> <li>If you want to use more than one node in the job and use multiple <code>srun</code>    per node (e.g. 256 single core processes across 2 nodes) then you need    to pass the node ID to the <code>srun</code> commands otherwise Slurm will oversubscribe    cores on the first node.</li> </ul> <p>Below, we provide four examples or running multiple subjobs in a node:  one that runs 128 serial processes across a single node; one that runs 8  subjobs each of which use 8 MPI processes with 2 OpenMP threads per MPI  process; one that runs four inhomogeneous jobs, each of which requires a  different number of MPI processes and OpenMP threads per process; and one  that runs 256 serial processes across two nodes.</p>"},{"location":"user-guide/scheduler/#example-1-128-serial-tasks-running-on-a-single-node","title":"Example 1: 128 serial tasks running on a single node","text":"<p>For our first example, we will run 128 single-core copies of the <code>xthi</code> program (which prints process/thread placement) on a single ARCHER2 compute node with each copy of <code>xthi</code> pinned to a different core. The job submission script for this example would look like:</p> <pre><code>#!/bin/bash\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=MultiSerialOnCompute\n#SBATCH --time=0:10:0\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n#SBATCH --hint=nomultithread\n#SBATCH --distribution=block:block\n\n# Replace [budget code] below with your budget code (e.g. t01)\n#SBATCH --account=[budget code]  \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Make xthi available\nmodule load xthi\n\n# Set the number of threads to 1\n#   This prevents any threaded system libraries from automatically \n#   using threading.\nexport OMP_NUM_THREADS=1\n\n# Propagate the cpus-per-task setting from script to srun commands\n#    By default, Slurm does not propagate this setting from the sbatch\n#    options to srun commands in the job script. If this is not done,\n#    process/thread pinning may be incorrect leading to poor performance\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Loop over 128 subjobs pinning each to a different core\nfor i in $(seq 1 128)\ndo\n# Launch subjob overriding job settings as required and in the background\n# Make sure to change the amount specified by the `--mem=` flag to the amount \n# of memory required. The amount of memory is given in MiB by default but other\n# units can be specified. If you do not know how much memory to specify, we \n# recommend that you specify `--mem=1500M` (1,500 MiB).\nsrun --nodes=1 --ntasks=1 --ntasks-per-node=1 \\\n--exact --mem=1500M xthi &gt; placement${i}.txt &amp;\ndone\n\n# Wait for all subjobs to finish\nwait\n</code></pre>"},{"location":"user-guide/scheduler/#example-2-8-subjobs-on-1-node-each-with-8-mpi-processes-and-2-openmp-threads-per-process","title":"Example 2: 8 subjobs on 1 node each with 8 MPI processes and 2 OpenMP threads per process","text":"<p>For our second example, we will run 8 subjobs, each running the <code>xthi</code> program (which prints process/thread placement) across 1 node. Each subjob will use 8 MPI processes and 2 OpenMP threads per process. The job submission script for this example would look like:</p> <pre><code>#!/bin/bash\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=MultiParallelOnCompute\n#SBATCH --time=0:10:0\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=64\n#SBATCH --cpus-per-task=2\n#SBATCH --hint=nomultithread\n#SBATCH --distribution=block:block\n\n# Replace [budget code] below with your budget code (e.g. t01)\n#SBATCH --account=[budget code]  \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Make xthi available\nmodule load xthi\n\n# Set the number of threads to 2 as required by all subjobs\nexport OMP_NUM_THREADS=2\n\n# Loop over 8 subjobs\nfor i in $(seq 1 8)\ndo\necho $j $i\n# Launch subjob overriding job settings as required and in the background\n# Make sure to change the amount specified by the `--mem=` flag to the amount \n# of memory required. The amount of memory is given in MiB by default but other\n# units can be specified. If you do not know how much memory to specify, we \n# recommend that you specify `--mem=12500M` (12,500 MiB).\nsrun --nodes=1 --ntasks=8 --ntasks-per-node=8 --cpus-per-task=2 \\\n--exact --mem=12500M xthi &gt; placement${i}.txt &amp;\ndone\n\n# Wait for all subjobs to finish\nwait\n</code></pre>"},{"location":"user-guide/scheduler/#example-3-running-inhomogeneous-subjobs-on-one-node","title":"Example 3: Running inhomogeneous subjobs on one node","text":"<p>For our third example, we will run 4 subjobs, each running the <code>xthi</code> program  (which prints process/thread placement) across 1 node. Our subjobs will each  run with a different number of MPI processes and OpenMP threads. We will run: one job with 64 MPI processes and 1 OpenMP process per thread; one job with  16 MPI processes and 2 threads per process; one job with 4 MPI processes and  4 OpenMP threads per job; and, one job with 1 MPI process and 16 OpenMP  threads  per job.</p> <p>To be able to change the number of MPI processes and OpenMP threads per  process, we will need to forgo using the <code>#SBATCH --ntasks-per-node</code> and the  <code>#SBATCH cpus-per-task</code> commands -- if you set these Slurm will not let you  alter the <code>OMP_NUM_THREADS</code> variable and you will not be able to change the  number of OpenMP threads per process between each job.</p> <p>Before each <code>srun</code> command, you will need to define the number of OpenMP  threads per process you want by changing the <code>OMP_NUM_THREADS</code> variable.  Furthermore, for each <code>srun</code> command, you will need to set the <code>--ntasks</code> flag  to equal the number of MPI processes you want to use. You will also need to  set the <code>--cpus-per-task</code> flag to equal the number of OpenMP threads per  process you want to use.</p> <pre><code>#!/bin/bash\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=MultiParallelOnCompute\n#SBATCH --time=0:10:0\n#SBATCH --nodes=1\n#SBATCH --hint=nomultithread\n#SBATCH --distribution=block:block\n\n# Replace [budget code] below with your budget code (e.g. t01)\n#SBATCH --account=[budget code]  \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Make xthi available\nmodule load xthi\n\n# Set the number of threads to value required by the first job\nexport OMP_NUM_THREADS=1\nsrun --ntasks=64 --cpus-per-task=${OMP_NUM_THREADS} \\\n--exact --mem=12500M xthi &gt; placement${OMP_NUM_THREADS}.txt &amp;\n\n# Set the number of threads to the value required by the second job\nexport OMP_NUM_THREADS=2\nsrun --ntasks=16 --cpus-per-task=${OMP_NUM_THREADS} \\\n--exact --mem=12500M xthi &gt; placement${OMP_NUM_THREADS}.txt &amp;\n\n# Set the number of threads to the value required by the second job\nexport OMP_NUM_THREADS=4\nsrun --ntasks=4 --cpus-per-task=${OMP_NUM_THREADS} \\\n--exact --mem=12500M xthi &gt; placement${OMP_NUM_THREADS}.txt &amp;\n\n# Set the number of threads to the value required by the second job\nexport OMP_NUM_THREADS=16\nsrun --ntasks=1 --cpus-per-task=${OMP_NUM_THREADS} \\\n--exact --mem=12500M xthi &gt; placement${OMP_NUM_THREADS}.txt &amp;\n\n# Wait for all subjobs to finish\nwait\n</code></pre>"},{"location":"user-guide/scheduler/#example-4-256-serial-tasks-running-across-two-nodes","title":"Example 4: 256 serial tasks running across two nodes","text":"<p>For our fourth example, we will run 256 single-core copies of the <code>xthi</code> program (which prints process/thread placement) across two ARCHER2 compute nodes with each copy of <code>xthi</code> pinned to a different core. We will illustrate a mechanism for getting the node IDs to pass to <code>srun</code> as this is required to ensure that the individual subjobs are assigned to the correct node. This mechanism uses the <code>scontrol</code> command to turn the  nodelist from <code>sbatch</code> into a format we can use as input to <code>srun</code>. The job submission script for this example would look like:</p> <pre><code>#!/bin/bash\n# Slurm job options (job-name, compute nodes, job time)\n#SBATCH --job-name=MultiSerialOnComputes\n#SBATCH --time=0:10:0\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=128\n#SBATCH --cpus-per-task=1\n\n# Replace [budget code] below with your budget code (e.g. t01)\n#SBATCH --account=[budget code]  \n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# Make xthi available\nmodule load xthi\n\n# Set the number of threads to 1\n#   This prevents any threaded system libraries from automatically \n#   using threading.\nexport OMP_NUM_THREADS=1\n\n# Propagate the cpus-per-task setting from script to srun commands\n#    By default, Slurm does not propagate this setting from the sbatch\n#    options to srun commands in the job script. If this is not done,\n#    process/thread pinning may be incorrect leading to poor performance\nexport SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\n\n# Get a list of the nodes assigned to this job in a format we can use.\n#   scontrol converts the condensed node IDs in the sbatch environment\n#   variable into a list of full node IDs that we can use with srun to\n#   ensure the subjobs are placed on the correct node. e.g. this converts\n#   \"nid[001234,002345]\" to \"nid001234 nid002345\"\nnodelist=$(scontrol show hostnames $SLURM_JOB_NODELIST)\n\n# Loop over the nodes assigned to the job\nfor nodeid in $nodelist\ndo\n# Loop over 128 subjobs on each node pinning each to a different core\nfor i in $(seq 1 128)\ndo\n# Launch subjob overriding job settings as required and in the background\n# Make sure to change the amount specified by the `--mem=` flag to the amount \n# of memory required. The amount of memory is given in MiB by default but other\n# units can be specified. If you do not know how much memory to specify, we \n# recommend that you specify `--mem=1500M` (1,500 MiB).\nsrun --nodelist=${nodeid} --nodes=1 --ntasks=1 --ntasks-per-node=1 \\\n--exact --mem=1500M xthi &gt; placement_${nodeid}_${i}.txt &amp;\ndone\ndone\n\n# Wait for all subjobs to finish\nwait\n</code></pre>"},{"location":"user-guide/scheduler/#process-placement","title":"Process placement","text":"<p>There are many occasions where you may want to control (usually, MPI) process placement and change it from the default, for example:</p> <ul> <li>You may want to place processes to different NUMA regions in a round-robin way rather than    the default sequential placement</li> <li>You may be using fewer than 128 processes per node and want to ensure that processes    are placed evenly across NUMA regions (16-core blocks) or core complexes (4-core blocks that    share an L3 cache)</li> </ul> <p>There are a number of different methods for defining process placement, below we cover two different options: using Slurm options and using the <code>MPICH_RANK_REORDER_METHOD</code> environment variable. Most users will likely use the Slurm options approach.</p>"},{"location":"user-guide/scheduler/#standard-process-placement","title":"Standard process placement","text":"<p>The standard approach recommended on ARCHER2 is to place processes sequentially on nodes until the maximum number of tasks is reached. You can use the <code>xthi</code> program to verify this for MPI process placement:</p> <pre><code>auser@ln04:/work/t01/t01/auser&gt; salloc --nodes=2 --ntasks-per-node=128 \\\n     --cpus-per-task=1 --time=0:10:0 --partition=standard --qos=short \\\n     --account=[your account]\n\nsalloc: Pending job allocation 1170365\nsalloc: job 1170365 queued and waiting for resources\nsalloc: job 1170365 has been allocated resources\nsalloc: Granted job allocation 1170365\nsalloc: Waiting for resource configuration\nsalloc: Nodes nid[002526-002527] are ready for job\n\nauser@ln04:/work/t01/t01/auser&gt; module load xthi\nauser@ln04:/work/t01/t01/auser&gt; export OMP_NUM_THREADS=1\nauser@ln04:/work/t01/t01/auser&gt; export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\nauser@ln04:/work/t01/t01/auser&gt; srun --distribution=block:block --hint=nomultithread xthi\n\nNode summary for    2 nodes:\nNode    0, hostname nid002526, mpi 128, omp   1, executable xthi\nNode    1, hostname nid002527, mpi 128, omp   1, executable xthi\nMPI summary: 256 ranks \nNode    0, rank    0, thread   0, (affinity =    0) \nNode    0, rank    1, thread   0, (affinity =    1) \nNode    0, rank    2, thread   0, (affinity =    2) \nNode    0, rank    3, thread   0, (affinity =    3) \n\n...output trimmed...\n\nNode    0, rank  124, thread   0, (affinity =  124) \nNode    0, rank  125, thread   0, (affinity =  125) \nNode    0, rank  126, thread   0, (affinity =  126) \nNode    0, rank  127, thread   0, (affinity =  127) \nNode    1, rank  128, thread   0, (affinity =    0) \nNode    1, rank  129, thread   0, (affinity =    1) \nNode    1, rank  130, thread   0, (affinity =    2) \nNode    1, rank  131, thread   0, (affinity =    3) \n\n...output trimmed...\n</code></pre> <p>Note</p> <p>For MPI programs on ARCHER2, each rank corresponds to a process.</p> <p>Important</p> <p>To get good performance out of MPI collective operations, MPI processes should be placed sequentially on cores as in the standard placement described above.</p>"},{"location":"user-guide/scheduler/#setting-process-placement-using-slurm-options","title":"Setting process placement using Slurm options","text":""},{"location":"user-guide/scheduler/#for-underpopulation-of-nodes-with-processes","title":"For underpopulation of nodes with processes","text":"<p>When you are using fewer processes than cores on compute nodes (i.e. &lt; 128 processes per node) the basic Slurm options (usually supplied in your script as options to <code>sbatch</code>) for  process placement are:</p> <ul> <li><code>--ntasks-per-node=X</code> Place X processes on each node</li> <li><code>--cpus-per-task=Y</code> Set a stride of Y cores between each placed process. If you specify this    option in a job submission script (queued using <code>sbatch</code>) or via <code>salloc</code> they you will also need   to set <code>export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK</code> to ensure the setting is passed to <code>srun</code>   commands in the script or allocation.</li> </ul> <p>In addition, the following options are added to your <code>srun</code> commands in your job submission script:</p> <ul> <li><code>--hint=nomultithread</code> Only use physical cores (avoids use of SMT/hyperthreads)</li> <li><code>--distribution=block:block</code> Allocate processes to cores in a sequential fashion</li> </ul> <p>For example, to place 32 processes per node and have 1 process per 4-core block (corresponding to a CCX, Core CompleX, that shares an L3 cache), you would set:</p> <ul> <li><code>--ntasks-per-node=32</code> Place 32 processes on each node</li> <li><code>--cpus-per-task=4</code> Set a stride of 4 cores between each placed process</li> </ul> <p>Here is the output from <code>xthi</code>:</p> <pre><code>auser@ln04:/work/t01/t01/auser&gt; salloc --nodes=2 --ntasks-per-node=32 \\\n     --cpus-per-task=4 --time=0:10:0 --partition=standard --qos=short \\\n     --account=[your account]\n\nsalloc: Pending job allocation 1170383\nsalloc: job 1170383 queued and waiting for resources\nsalloc: job 1170383 has been allocated resources\nsalloc: Granted job allocation 1170383\nsalloc: Waiting for resource configuration\nsalloc: Nodes nid[002526-002527] are ready for job\n\nauser@ln04:/work/t01/t01/auser&gt; module load xthi\nauser@ln04:/work/t01/t01/auser&gt; export OMP_NUM_THREADS=1\nauser@ln04:/work/t01/t01/auser&gt; export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\nauser@ln04:/work/t01/t01/auser&gt; srun --distribution=block:block --hint=nomultithread xthi\n\nNode summary for    2 nodes:\nNode    0, hostname nid002526, mpi  32, omp   1, executable xthi\nNode    1, hostname nid002527, mpi  32, omp   1, executable xthi\nMPI summary: 64 ranks \nNode    0, rank    0, thread   0, (affinity =  0-3) \nNode    0, rank    1, thread   0, (affinity =  4-7) \nNode    0, rank    2, thread   0, (affinity = 8-11) \nNode    0, rank    3, thread   0, (affinity = 12-15) \nNode    0, rank    4, thread   0, (affinity = 16-19) \nNode    0, rank    5, thread   0, (affinity = 20-23) \nNode    0, rank    6, thread   0, (affinity = 24-27) \nNode    0, rank    7, thread   0, (affinity = 28-31) \nNode    0, rank    8, thread   0, (affinity = 32-35) \nNode    0, rank    9, thread   0, (affinity = 36-39) \nNode    0, rank   10, thread   0, (affinity = 40-43) \nNode    0, rank   11, thread   0, (affinity = 44-47) \nNode    0, rank   12, thread   0, (affinity = 48-51) \nNode    0, rank   13, thread   0, (affinity = 52-55) \nNode    0, rank   14, thread   0, (affinity = 56-59) \nNode    0, rank   15, thread   0, (affinity = 60-63) \nNode    0, rank   16, thread   0, (affinity = 64-67) \nNode    0, rank   17, thread   0, (affinity = 68-71) \nNode    0, rank   18, thread   0, (affinity = 72-75) \nNode    0, rank   19, thread   0, (affinity = 76-79) \nNode    0, rank   20, thread   0, (affinity = 80-83) \nNode    0, rank   21, thread   0, (affinity = 84-87) \nNode    0, rank   22, thread   0, (affinity = 88-91) \nNode    0, rank   23, thread   0, (affinity = 92-95) \nNode    0, rank   24, thread   0, (affinity = 96-99) \nNode    0, rank   25, thread   0, (affinity = 100-103) \nNode    0, rank   26, thread   0, (affinity = 104-107) \nNode    0, rank   27, thread   0, (affinity = 108-111) \nNode    0, rank   28, thread   0, (affinity = 112-115) \nNode    0, rank   29, thread   0, (affinity = 116-119) \nNode    0, rank   30, thread   0, (affinity = 120-123) \nNode    0, rank   31, thread   0, (affinity = 124-127) \nNode    1, rank   32, thread   0, (affinity =  0-3) \nNode    1, rank   33, thread   0, (affinity =  4-7) \nNode    1, rank   34, thread   0, (affinity = 8-11) \nNode    1, rank   35, thread   0, (affinity = 12-15) \nNode    1, rank   36, thread   0, (affinity = 16-19) \nNode    1, rank   37, thread   0, (affinity = 20-23) \nNode    1, rank   38, thread   0, (affinity = 24-27) \nNode    1, rank   39, thread   0, (affinity = 28-31) \nNode    1, rank   40, thread   0, (affinity = 32-35) \nNode    1, rank   41, thread   0, (affinity = 36-39) \nNode    1, rank   42, thread   0, (affinity = 40-43) \nNode    1, rank   43, thread   0, (affinity = 44-47) \nNode    1, rank   44, thread   0, (affinity = 48-51) \nNode    1, rank   45, thread   0, (affinity = 52-55) \nNode    1, rank   46, thread   0, (affinity = 56-59) \nNode    1, rank   47, thread   0, (affinity = 60-63) \nNode    1, rank   48, thread   0, (affinity = 64-67) \nNode    1, rank   49, thread   0, (affinity = 68-71) \nNode    1, rank   50, thread   0, (affinity = 72-75) \nNode    1, rank   51, thread   0, (affinity = 76-79) \nNode    1, rank   52, thread   0, (affinity = 80-83) \nNode    1, rank   53, thread   0, (affinity = 84-87) \nNode    1, rank   54, thread   0, (affinity = 88-91) \nNode    1, rank   55, thread   0, (affinity = 92-95) \nNode    1, rank   56, thread   0, (affinity = 96-99) \nNode    1, rank   57, thread   0, (affinity = 100-103) \nNode    1, rank   58, thread   0, (affinity = 104-107) \nNode    1, rank   59, thread   0, (affinity = 108-111) \nNode    1, rank   60, thread   0, (affinity = 112-115) \nNode    1, rank   61, thread   0, (affinity = 116-119) \nNode    1, rank   62, thread   0, (affinity = 120-123) \nNode    1, rank   63, thread   0, (affinity = 124-127) \n</code></pre> <p>Tip</p> <p>You usually only want to use physical cores on ARCHER2, so (<code>ntasks-per-node</code>) \u00d7 (<code>cpus-per-task</code>) should generally be equal to 128.</p>"},{"location":"user-guide/scheduler/#full-node-population-with-non-sequential-process-placement","title":"Full node population with non-sequential process placement","text":"<p>If you want to change the order processes are placed on nodes and cores using Slurm options then you should use the <code>--distribution</code> option to <code>srun</code> to change this.</p> <p>For example, to place processes sequentially on nodes but round-robin on the 16-core NUMA regions in a single node, you would use the <code>--distribution=block:cyclic</code> option to <code>srun</code>. This type of process placement can be beneficial when a code is memory bound.</p> <pre><code>auser@ln04:/work/t01/t01/auser&gt; salloc --nodes=2 --ntasks-per-node=128 \\\n     --cpus-per-task=1 --time=0:10:0 --partition=standard --qos=short \\\n     --account=[your account]\n\nsalloc: Pending job allocation 1170594\nsalloc: job 1170594 queued and waiting for resources\nsalloc: job 1170594 has been allocated resources\nsalloc: Granted job allocation 1170594\nsalloc: Waiting for resource configuration\nsalloc: Nodes nid[002616,002621] are ready for job\n\nauser@ln04:/work/t01/t01/auser&gt; module load xthi\nauser@ln04:/work/t01/t01/auser&gt; export OMP_NUM_THREADS=1\nauser@ln04:/work/t01/t01/auser&gt; srun --distribution=block:cyclic --hint=nomultithread xthi\n\nNode summary for    2 nodes:\nNode    0, hostname nid002616, mpi 128, omp   1, executable xthi\nNode    1, hostname nid002621, mpi 128, omp   1, executable xthi\nMPI summary: 256 ranks \nNode    0, rank    0, thread   0, (affinity =    0) \nNode    0, rank    1, thread   0, (affinity =   16) \nNode    0, rank    2, thread   0, (affinity =   32) \nNode    0, rank    3, thread   0, (affinity =   48) \nNode    0, rank    4, thread   0, (affinity =   64) \nNode    0, rank    5, thread   0, (affinity =   80) \nNode    0, rank    6, thread   0, (affinity =   96) \nNode    0, rank    7, thread   0, (affinity =  112) \nNode    0, rank    8, thread   0, (affinity =    1) \nNode    0, rank    9, thread   0, (affinity =   17) \nNode    0, rank   10, thread   0, (affinity =   33) \nNode    0, rank   11, thread   0, (affinity =   49) \nNode    0, rank   12, thread   0, (affinity =   65) \nNode    0, rank   13, thread   0, (affinity =   81) \nNode    0, rank   14, thread   0, (affinity =   97) \nNode    0, rank   15, thread   0, (affinity =  113\n\n...output trimmed...\n\nNode    0, rank  120, thread   0, (affinity =   15) \nNode    0, rank  121, thread   0, (affinity =   31) \nNode    0, rank  122, thread   0, (affinity =   47) \nNode    0, rank  123, thread   0, (affinity =   63) \nNode    0, rank  124, thread   0, (affinity =   79) \nNode    0, rank  125, thread   0, (affinity =   95) \nNode    0, rank  126, thread   0, (affinity =  111) \nNode    0, rank  127, thread   0, (affinity =  127) \nNode    1, rank  128, thread   0, (affinity =    0) \nNode    1, rank  129, thread   0, (affinity =   16) \nNode    1, rank  130, thread   0, (affinity =   32) \nNode    1, rank  131, thread   0, (affinity =   48) \nNode    1, rank  132, thread   0, (affinity =   64) \nNode    1, rank  133, thread   0, (affinity =   80) \nNode    1, rank  134, thread   0, (affinity =   96) \nNode    1, rank  135, thread   0, (affinity =  112) \n\n...output trimmed...\n</code></pre> <p>If you wish to place processes round robin on both nodes and 16-core regions (cores that share access to a DRAM single memory controller) within in a node you would use <code>--distribution=cyclic:cyclic</code>:</p> <pre><code>auser@ln04:/work/t01/t01/auser&gt; salloc --nodes=2 --ntasks-per-node=128 \\\n     --cpus-per-task=1 --time=0:10:0 --partition=standard --qos=short \\\n     --account=[your account]\n\nsalloc: Pending job allocation 1170594\nsalloc: job 1170594 queued and waiting for resources\nsalloc: job 1170594 has been allocated resources\nsalloc: Granted job allocation 1170594\nsalloc: Waiting for resource configuration\nsalloc: Nodes nid[002616,002621] are ready for job\n\nauser@ln04:/work/t01/t01/auser&gt; module load xthi\nauser@ln04:/work/t01/t01/auser&gt; export OMP_NUM_THREADS=1\nauser@ln04:/work/t01/t01/auser&gt; export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK\nauser@ln04:/work/t01/t01/auser&gt; srun --distribution=cyclic:cyclic --hint=nomultithread xthi\n\nNode summary for    2 nodes:\nNode    0, hostname nid002616, mpi 128, omp   1, executable xthi\nNode    1, hostname nid002621, mpi 128, omp   1, executable xthi\nMPI summary: 256 ranks \nNode    0, rank    0, thread   0, (affinity =    0) \nNode    0, rank    2, thread   0, (affinity =   16) \nNode    0, rank    4, thread   0, (affinity =   32) \nNode    0, rank    6, thread   0, (affinity =   48) \nNode    0, rank    8, thread   0, (affinity =   64) \nNode    0, rank   10, thread   0, (affinity =   80) \nNode    0, rank   12, thread   0, (affinity =   96) \nNode    0, rank   14, thread   0, (affinity =  112) \nNode    0, rank   16, thread   0, (affinity =    1) \nNode    0, rank   18, thread   0, (affinity =   17) \nNode    0, rank   20, thread   0, (affinity =   33) \nNode    0, rank   22, thread   0, (affinity =   49) \nNode    0, rank   24, thread   0, (affinity =   65) \nNode    0, rank   26, thread   0, (affinity =   81) \nNode    0, rank   28, thread   0, (affinity =   97) \nNode    0, rank   30, thread   0, (affinity =  113) \n\n...output trimmed...\n\nNode    1, rank    1, thread   0, (affinity =    0) \nNode    1, rank    3, thread   0, (affinity =   16) \nNode    1, rank    5, thread   0, (affinity =   32) \nNode    1, rank    7, thread   0, (affinity =   48) \nNode    1, rank    9, thread   0, (affinity =   64) \nNode    1, rank   11, thread   0, (affinity =   80) \nNode    1, rank   13, thread   0, (affinity =   96) \nNode    1, rank   15, thread   0, (affinity =  112) \nNode    1, rank   17, thread   0, (affinity =    1) \nNode    1, rank   19, thread   0, (affinity =   17) \nNode    1, rank   21, thread   0, (affinity =   33) \nNode    1, rank   23, thread   0, (affinity =   49) \nNode    1, rank   25, thread   0, (affinity =   65) \nNode    1, rank   27, thread   0, (affinity =   81) \nNode    1, rank   29, thread   0, (affinity =   97) \nNode    1, rank   31, thread   0, (affinity =  113) \n\n...output trimmed...\n</code></pre> <p>Remember, MPI collective performance is generally much worse if processes are not placed sequentially on a node (so adjacent MPI ranks are as close to each other as possible). This is the reason that the default recommended placement on ARCHER2 is sequential rather than  round-robin.</p>"},{"location":"user-guide/scheduler/#mpich_rank_reorder_method-for-mpi-process-placement","title":"<code>MPICH_RANK_REORDER_METHOD</code> for MPI process placement","text":"<p>The <code>MPICH_RANK_REORDER_METHOD</code> environment variable can also be used to specify other types of MPI task placement. For example, setting it to \"0\" results in a round-robin placement on both nodes and NUMA regions in a node (equivalent to the <code>--distribution=cyclic:cyclic</code> option to <code>srun</code>). Note, we do not specify the <code>--distribution</code> option to <code>srun</code> in this case as the environment variable is controlling placement:</p> <pre><code>salloc --nodes=8 --ntasks-per-node=2 --cpus-per-task=1 --time=0:10:0 --account=t01\n\nsalloc: Granted job allocation 24236\nsalloc: Waiting for resource configuration\nsalloc: Nodes cn13 are ready for job\n\nmodule load xthi\nexport OMP_NUM_THREADS=1\nexport MPICH_RANK_REORDER_METHOD=0\nsrun --hint=nomultithread xthi\n\nNode summary for    2 nodes:\nNode    0, hostname nid002616, mpi 128, omp   1, executable xthi\nNode    1, hostname nid002621, mpi 128, omp   1, executable xthi\nMPI summary: 256 ranks \nNode    0, rank    0, thread   0, (affinity =    0) \nNode    0, rank    2, thread   0, (affinity =   16) \nNode    0, rank    4, thread   0, (affinity =   32) \nNode    0, rank    6, thread   0, (affinity =   48) \nNode    0, rank    8, thread   0, (affinity =   64) \nNode    0, rank   10, thread   0, (affinity =   80) \nNode    0, rank   12, thread   0, (affinity =   96) \nNode    0, rank   14, thread   0, (affinity =  112) \nNode    0, rank   16, thread   0, (affinity =    1) \nNode    0, rank   18, thread   0, (affinity =   17) \nNode    0, rank   20, thread   0, (affinity =   33) \nNode    0, rank   22, thread   0, (affinity =   49) \nNode    0, rank   24, thread   0, (affinity =   65) \nNode    0, rank   26, thread   0, (affinity =   81) \nNode    0, rank   28, thread   0, (affinity =   97) \nNode    0, rank   30, thread   0, (affinity =  113) \n\n...output trimmed...\n</code></pre> <p>There are other modes available with the <code>MPICH_RANK_REORDER_METHOD</code> environment variable, including one which lets the user provide a file called <code>MPICH_RANK_ORDER</code> which contains a list of each task's placement on each node. These options are described in detail in the <code>intro_mpi</code> man page.</p>"},{"location":"user-guide/scheduler/#grid_order","title":"grid_order","text":"<p>For MPI applications which perform a large amount of nearest-neighbor communication, e.g., stencil-based applications on structured grids, HPE provide a tool in the <code>perftools-base</code> module (Loaded by default for all users) called <code>grid_order</code> which can generate a <code>MPICH_RANK_ORDER</code> file automatically by taking as parameters the dimensions of the grid, core count, etc. For example, to place 256 MPI parameters in row-major order on a Cartesian grid of size $(8, 8, 4)$, using 128 cores per node:</p> <pre><code>grid_order -R -c 128 -g 8,8,4\n\n# grid_order -R -Z -c 128 -g 8,8,4\n# Region 3: 0,0,1 (0..255)\n0,1,2,3,32,33,34,35,64,65,66,67,96,97,98,99,128,129,130,131,160,161,162,163,192,193,194,195,224,225,226,227,4,5,6,7,36,37,38,39,68,69,70,71,100,101,102,103,132,133,134,135,164,165,166,167,196,197,198,199,228,229,230,231,8,9,10,11,40,41,42,43,72,73,74,75,104,105,106,107,136,137,138,139,168,169,170,171,200,201,202,203,232,233,234,235,12,13,14,15,44,45,46,47,76,77,78,79,108,109,110,111,140,141,142,143,172,173,174,175,204,205,206,207,236,237,238,239\n16,17,18,19,48,49,50,51,80,81,82,83,112,113,114,115,144,145,146,147,176,177,178,179,208,209,210,211,240,241,242,243,20,21,22,23,52,53,54,55,84,85,86,87,116,117,118,119,148,149,150,151,180,181,182,183,212,213,214,215,244,245,246,247,24,25,26,27,56,57,58,59,88,89,90,91,120,121,122,123,152,153,154,155,184,185,186,187,216,217,218,219,248,249,250,251,28,29,30,31,60,61,62,63,92,93,94,95,124,125,126,127,156,157,158,159,188,189,190,191,220,221,222,223,252,253,254,255\n</code></pre> <p>One can then save this output to a file called <code>MPICH_RANK_ORDER</code> and then set <code>MPICH_RANK_REORDER_METHOD=3</code> before running the job, which tells Cray MPI to read the <code>MPICH_RANK_ORDER</code> file to set the MPI task placement. For more information, please see the man page <code>man grid_order</code>.</p>"},{"location":"user-guide/scheduler/#interactive-jobs","title":"Interactive Jobs","text":""},{"location":"user-guide/scheduler/#using-salloc-to-reserve-resources","title":"Using <code>salloc</code> to reserve resources","text":"<p>When you are developing or debugging code you often want to run many short jobs with a small amount of editing the code between runs. This can be achieved by using the login nodes to run MPI but you may want to test on the compute nodes (e.g. you may want to test running on multiple nodes across the high performance interconnect). One of the best ways to achieve this on ARCHER2 is to use interactive jobs.</p> <p>An interactive job allows you to issue <code>srun</code> commands directly from the command line without using a job submission script, and to see the output from your program directly in the terminal.</p> <p>You use the <code>salloc</code> command to reserve compute nodes for interactive jobs.</p> <p>To submit a request for an interactive job reserving 8 nodes (1024 physical cores) for 20 minutes on the short QoS you would issue the following command from the command line:</p> <pre><code>auser@ln01:&gt; salloc --nodes=8 --ntasks-per-node=128 --cpus-per-task=1 \\\n--time=00:20:00 --partition=standard --qos=short \\\n--account=[budget code]\n</code></pre> <p>When you submit this job your terminal will display something like:</p> <pre><code>salloc: Granted job allocation 24236\nsalloc: Waiting for resource configuration\nsalloc: Nodes nid000002 are ready for job\nauser@ln01:&gt;\n</code></pre> <p>It may take some time for your interactive job to start. Once it runs you will enter a standard interactive terminal session (a new shell). Note that this shell is still on the front end (the prompt has not change). Whilst the interactive session lasts you will be able to run parallel jobs on the compute nodes by issuing the <code>srun --distribution=block:block --hint=nomultithread</code> command directly at  your command prompt using the same syntax as you would inside a job script. The maximum number of nodes you can use is limited by resources requested in the <code>salloc</code> command.</p> <p>Important</p> <p>If you wish the <code>cpus-per-task</code> option to <code>salloc</code> to propagate to <code>srun</code> commands in the allocation, you will need to use the command  <code>export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK</code> before you issue any <code>srun</code> commands.</p> <p>If you know you will be doing a lot of intensive debugging you may find it useful to request an interactive session lasting the expected length of your working session, say a full day.</p> <p>Your session will end when you hit the requested walltime. If you wish to finish before this you should use the <code>exit</code> command - this will return you to your prompt before you issued the <code>salloc</code> command.</p>"},{"location":"user-guide/scheduler/#using-srun-directly","title":"Using <code>srun</code> directly","text":"<p>A second way to run an interactive job is to use <code>srun</code> directly in the following way (here using the <code>short</code> QoS):</p> <pre><code>auser@ln01:/work/t01/t01/auser&gt; srun --nodes=1 --exclusive --time=00:20:00 \\\n                --partition=standard --qos=short --account=[budget code] \\\n    --pty /bin/bash\nauser@nid001261:/work/t01/t01/auser&gt; hostname\nnid001261\n</code></pre> <p>The <code>--pty /bin/bash</code> will cause a new shell to be started on the first node of a new allocation . This is perhaps closer to what many people consider an 'interactive' job than the method using <code>salloc</code> appears.</p> <p>One can now issue shell commands in the usual way. A further invocation of <code>srun</code> is required to launch a parallel job in the allocation.</p> <p>Note</p> <p>When using <code>srun</code> within an interactive <code>srun</code> session, you will need to  include both the <code>--overlap</code> and <code>--oversubscribe</code> flags, and specify the number of cores you want  to use: <pre><code>auser@nid001261:/work/t01/t01/auser&gt; srun --overlap --oversubscribe --distribution=block:block \\\n                --hint=nomultithread --ntasks=128 ./my_mpi_executable.x\n</code></pre></p> <p>Without <code>--overlap</code> the second <code>srun</code> will block until the first one has completed. Since your interactive session was launched with <code>srun</code> this means it will never actually start -- you will get repeated warnings that \"Requested nodes are busy\".</p> <p>When finished, type <code>exit</code> to relinquish the allocation and control will be returned to the front end.</p> <p>By default, the interactive shell will retain the environment of the parent. If you want a clean shell, remember to specify <code>--export=none</code>.</p>"},{"location":"user-guide/scheduler/#heterogeneous-jobs","title":"Heterogeneous jobs","text":"<p>Most of the Slurm submissions discussed above involve running a single executable. However, there are situations where two or more distinct executables are coupled and need to be run at the same time, potentially using the same MPI communicator. This is most easily handled via the Slurm heterogeneous job mechanism.</p> <p>Two common cases are discussed below: first, a client server model in which client and server each have a different <code>MPI_COMM_WORLD</code>, and second the case were two or more executables share <code>MPI_COMM_WORLD</code>.</p>"},{"location":"user-guide/scheduler/#heterogeneous-jobs-for-a-clientserver-model-distinct-mpi_comm_worlds","title":"Heterogeneous jobs for a client/server model: distinct <code>MPI_COMM_WORLDs</code>","text":"<p>The essential feature of a heterogeneous job here is to create a single batch submission which specifies the resource requirements for the individual components. Schematically, we would use</p> <p><pre><code>#!/bin/bash\n\n# Slurm specifications for the first component\n\n#SBATCH --partition=standard\n\n...\n\n#SBATCH hetjob\n\n# Slurm specifications for the second component\n\n#SBATCH --partition=standard\n\n...\n</code></pre> where new each component beyond the first is introduced by the special token <code>#SBATCH hetjob</code> (note this is not a normal option and is not <code>--hetjob</code>). Each component must specify a partition.</p> <p>Such a job will appear in the scheduler as, e.g., <pre><code>           50098+0  standard qscript-    user  PD       0:00      1 (None) \n           50098+1  standard qscript-    user  PD       0:00      2 (None) \n</code></pre> and counts as (in this case) two separate jobs from the point of QoS limits.</p> <p>Consider a case where we have two executables which may both be parallel (in that they use MPI), both run at the same time, and communicate with each other using MPI or by some other means. In the following example, we run two different executables, <code>xthi-a</code> and <code>xthi-b</code>, both of which must finish before the jobs completes.</p> <p><pre><code>#!/bin/bash\n\n#SBATCH --time=00:20:00\n#SBATCH --exclusive\n#SBATCH --export=none\n\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=8\n\n#SBATCH hetjob\n\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=4\n\n# Run two executables with separate MPI_COMM_WORLD\n\nsrun --distribution=block:block --hint=nomultithread --het-group=0 ./xthi-a &amp;\nsrun --distribution=block:block --hint=nomultithread --het-group=1 ./xthi-b &amp;\nwait\n</code></pre> In this case, each executable is launched with a separate call to <code>srun</code> but specifies a different heterogeneous group via the <code>--het-group</code> option. The first group is <code>--het-group=0</code>. Both are run in the background with <code>&amp;</code> and the <code>wait</code> is required to ensure both executables have completed before the job submission exits.</p> <p>The above is a rather artificial example using two executables which are in fact just symbolic links in the job directory to <code>xthi</code>, used without loading the module. You can test this script yourself by creating symbolic links to the original executable before submitting the job:</p> <pre><code>auser@ln04:/work/t01/t01/auser/job-dir&gt; module load xthi\nauser@ln04:/work/t01/t01/auser/job-dir&gt; which xthi\n/work/y07/shared/utils/core/xthi/1.2/CRAYCLANG/11.0/bin/xthi\nauser@ln04:/work/t01/t01/auser/job-dir&gt; ln -s /work/y07/shared/utils/core/xthi/1.2/CRAYCLANG/11.0/bin/xthi xthi-a\nauser@ln04:/work/t01/t01/auser/job-dir&gt; ln -s /work/y07/shared/utils/core/xthi/1.2/CRAYCLANG/11.0/bin/xthi xthi-b\n</code></pre> <p>The example job will produce two reports showing the placement of the MPI tasks from the two instances of <code>xthi</code> running in each of the heterogeneous groups. For example, the output might be</p> <p><pre><code>Node summary for    1 nodes:\nNode    0, hostname nid002400, mpi   8, omp   1, executable xthi-a\nMPI summary: 8 ranks\nNode    0, rank    0, thread   0, (affinity =    0)\nNode    0, rank    1, thread   0, (affinity =    1)\nNode    0, rank    2, thread   0, (affinity =    2)\nNode    0, rank    3, thread   0, (affinity =    3)\nNode    0, rank    4, thread   0, (affinity =    4)\nNode    0, rank    5, thread   0, (affinity =    5)\nNode    0, rank    6, thread   0, (affinity =    6)\nNode    0, rank    7, thread   0, (affinity =    7)\nNode summary for    2 nodes:\nNode    0, hostname nid002146, mpi   4, omp   1, executable xthi-b\nNode    1, hostname nid002149, mpi   4, omp   1, executable xthi-b\nMPI summary: 8 ranks\nNode    0, rank    0, thread   0, (affinity =    0)\nNode    0, rank    1, thread   0, (affinity =    1)\nNode    0, rank    2, thread   0, (affinity =    2)\nNode    0, rank    3, thread   0, (affinity =    3)\nNode    1, rank    4, thread   0, (affinity =    0)\nNode    1, rank    5, thread   0, (affinity =    1)\nNode    1, rank    6, thread   0, (affinity =    2)\nNode    1, rank    7, thread   0, (affinity =    3)\n</code></pre> Here we have the first executable running on one node with a communicator size 8 (ranks 0-7). The second executable runs on two nodes also with communicator size 8 (ranks 0-7, 4 ranks per node). Further examples of placement for heterogenenous jobs are given below.</p> <p>Finally, if your workflow requires the different heterogeneous jobs to communicate via MPI, but without sharing their <code>MPI_COM_WORLD</code>, you will need to export two new variables before your <code>srun</code> commands as defined below:</p> <pre><code>export PMI_UNIVERSE_SIZE=3\nexport MPICH_SINGLE_HOST_ENABLED=0\n</code></pre>"},{"location":"user-guide/scheduler/#heterogeneous-jobs-for-a-shared-mpi_com_world","title":"Heterogeneous jobs for a shared <code>MPI_COM_WORLD</code>","text":"<p>Note</p> <p>The directive <code>SBATCH hetjob</code> can no longer be used for jobs requiring a shared <code>MPI_COMM_WORLD</code></p> <p>Note</p> <p>In this approach, each <code>hetjob</code> component must be on its own set of nodes. You cannot use this approach to place different <code>hetjob</code> components on  the same node.</p> <p>If two or more heterogeneous components need to share a unique <code>MPI_COMM_WORLD</code>, a single <code>srun</code> invocation with the differrent components separated by a colon <code>:</code> should be used. Arguements to the individual components of the <code>srun</code> control the placement of the tasks and threads for each component. For example, running the same <code>xthi-a</code> and <code>xthi-b</code> executables as above but now in a shared communicator, we might run:</p> <pre><code>#!/bin/bash\n\n#SBATCH --time=00:20:00\n#SBATCH --export=none\n#SBATCH --account=[...]\n\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n# We must specify correctly the total number of nodes required.\n#SBATCH --nodes=3\n\nSHARED_ARGS=\"--distribution=block:block --hint=nomultithread\"\n\nsrun --het-group=0 --nodes=1 --ntasks-per-node=8 ${SHARED_ARGS} ./xthi-a : \\\n--het-group=1 --nodes=2 --ntasks-per-node=4 ${SHARED_ARGS} ./xthi-b\n</code></pre> <p>The output should confirm we have a single <code>MPI_COMM_WORLD</code> with a total of three nodes, <code>xthi-a</code> running on one and <code>xthi-b</code> on two, with ranks 0-15 extending across both executables.</p> <pre><code>Node summary for    3 nodes:\nNode    0, hostname nid002668, mpi   8, omp   1, executable xthi-a\nNode    1, hostname nid002669, mpi   4, omp   1, executable xthi-b\nNode    2, hostname nid002670, mpi   4, omp   1, executable xthi-b\nMPI summary: 16 ranks \nNode    0, rank    0, thread   0, (affinity =    0) \nNode    0, rank    1, thread   0, (affinity =    1) \nNode    0, rank    2, thread   0, (affinity =    2) \nNode    0, rank    3, thread   0, (affinity =    3) \nNode    0, rank    4, thread   0, (affinity =    4) \nNode    0, rank    5, thread   0, (affinity =    5) \nNode    0, rank    6, thread   0, (affinity =    6) \nNode    0, rank    7, thread   0, (affinity =    7) \nNode    1, rank    8, thread   0, (affinity =    0) \nNode    1, rank    9, thread   0, (affinity =    1) \nNode    1, rank   10, thread   0, (affinity =    2) \nNode    1, rank   11, thread   0, (affinity =    3) \nNode    2, rank   12, thread   0, (affinity =    0) \nNode    2, rank   13, thread   0, (affinity =    1) \nNode    2, rank   14, thread   0, (affinity =    2) \nNode    2, rank   15, thread   0, (affinity =    3) \n</code></pre>"},{"location":"user-guide/scheduler/#heterogeneous-placement-for-mixed-mpiopenmp-work","title":"Heterogeneous placement for mixed MPI/OpenMP work","text":"<p>Some care may be required for placement of tasks/threads in heterogeneous jobs in which the number of threads needs to be specified differently for different components.</p> <p>In the following we have two components, again using <code>xthi-a</code> and <code>xthi-b</code> as our two separate executables. The first component runs 8 MPI tasks each with 16 OpenMP threads on one node. The second component runs 8 MPI tasks with one task per NUMA region on a second node; each task has one thread. An appropriate Slurm submission might be:</p> <pre><code>#!/bin/bash\n\n#SBATCH --time=00:20:00\n#SBATCH --export=none\n#SBATCH --account=[...]\n\n#SBATCH --partition=standard\n#SBATCH --qos=standard\n\n#SBATCH --nodes=2\n\nSHARED_ARGS=\"--distribution=block:block --hint=nomultithread \\\n              --nodes=1 --ntasks-per-node=8 --cpus-per-task=16\"\n\n# Do not set OMP_NUM_THREADS in the calling environment\n\nunset OMP_NUM_THREADS\nexport OMP_PROC_BIND=spread\n\nsrun --het-group=0 ${SHARED_ARGS} --export=all,OMP_NUM_THREADS=16 ./xthi-a : \\\n--het-group=1 ${SHARED_ARGS} --export=all,OMP_NUM_THREADS=1  ./xthi-b\n</code></pre> <p>The important point here is that <code>OMP_NUM_THREADS</code> must not be set in the environment that calls <code>srun</code> in order that the different specifications for the separate groups via <code>--export</code> on the <code>srun</code> command line take effect. If <code>OMP_NUM_THREADS</code> is set in the calling environment, then that value takes precedence, and each component will see the same value of <code>OMP_NUM_THREADS</code>.</p> <p>The output might then be:</p> <pre><code>Node    0, hostname nid001111, mpi   8, omp  16, executable xthi-a\nNode    1, hostname nid001126, mpi   8, omp   1, executable xthi-b\nNode    0, rank    0, thread   0, (affinity =    0)\nNode    0, rank    0, thread   1, (affinity =    1)\nNode    0, rank    0, thread   2, (affinity =    2)\nNode    0, rank    0, thread   3, (affinity =    3)\nNode    0, rank    0, thread   4, (affinity =    4)\nNode    0, rank    0, thread   5, (affinity =    5)\nNode    0, rank    0, thread   6, (affinity =    6)\nNode    0, rank    0, thread   7, (affinity =    7)\nNode    0, rank    0, thread   8, (affinity =    8)\nNode    0, rank    0, thread   9, (affinity =    9)\nNode    0, rank    0, thread  10, (affinity =   10)\nNode    0, rank    0, thread  11, (affinity =   11)\nNode    0, rank    0, thread  12, (affinity =   12)\nNode    0, rank    0, thread  13, (affinity =   13)\nNode    0, rank    0, thread  14, (affinity =   14)\nNode    0, rank    0, thread  15, (affinity =   15)\nNode    0, rank    1, thread   0, (affinity =   16)\nNode    0, rank    1, thread   1, (affinity =   17)\n...\nNode    0, rank    7, thread  14, (affinity =  126)\nNode    0, rank    7, thread  15, (affinity =  127)\nNode    1, rank    8, thread   0, (affinity =    0)\nNode    1, rank    9, thread   0, (affinity =   16)\nNode    1, rank   10, thread   0, (affinity =   32)\nNode    1, rank   11, thread   0, (affinity =   48)\nNode    1, rank   12, thread   0, (affinity =   64)\nNode    1, rank   13, thread   0, (affinity =   80)\nNode    1, rank   14, thread   0, (affinity =   96)\nNode    1, rank   15, thread   0, (affinity =  112)\n</code></pre> <p>Here we can see the eight MPI tasks from <code>xthi-a</code> each running with sixteen OpenMP threads. Then the 8 MPI tasks with no threading from <code>xthi-b</code> are spaced across the cores on the second node, one per NUMA region.</p>"},{"location":"user-guide/scheduler/#low-priority-access","title":"Low priority access","text":"<p>Low priority jobs are not charged against your allocation but will only run when other, higher-priority, jobs cannot be run. Although low priority jobs are not charged, you do need a valid, positive budget to be able to submit and run low priority jobs, i.e. you need at least 1 CU in your budget.</p> <p>Low priority access is always available and has the following limits:</p> <ul> <li>1024 node maximum job size</li> <li>Maximum 16 low priority jobs submitted (including running) per user</li> <li>Maximum 16 low priority job running per user</li> <li>Maximum runtime of 24 hours</li> </ul> <p>You submit a low priority job on ARCHER2 by using the <code>lowpriority</code> QoS. For example, you would usually have the following line in your job submission script sbatch  options:</p> <pre><code>#SBATCH --qos=lowpriority\n</code></pre>"},{"location":"user-guide/scheduler/#reservations","title":"Reservations","text":"<p>Reservations are available on ARCHER2. These allow users to reserve a number of nodes for a specified length of time starting at a particular time on the system.</p> <p>Reservations require justification. They will only be approved if the request could not be fulfilled with the normal QoS's. For instance, you require a job/jobs to run at a particular time e.g. for a demonstration or course.</p> <p>Note</p> <p>Reservation requests must be submitted at least 60 hours in advance of the reservation start time. If requesting a reservation for a Monday at 18:00, please ensure this is received by the Friday at 12:00 the latest. The same applies over Service Holidays.</p> <p>Note</p> <p>Reservations are only valid for standard compute nodes, high memory compute nodes and/or PP nodes cannot be included in reservations.</p> <p>Reservations will be charged at 1.5 times the usual CU rate and our policy is that they will be charged the full rate for the entire reservation at the time of booking, whether or not you use the nodes for the full time. In addition, you will not be refunded the CUs if you fail to use them due to a job issue unless this issue is due to a system failure.</p> <p>To request a reservation you complete a form on SAFE:</p> <ol> <li>Log into SAFE</li> <li>Under the \"Login accounts\" menu, choose the \"Request reservation\" option</li> </ol> <p>On the first page, you need to provide the following:</p> <ul> <li>The start time and date of the reservation.</li> <li>The end time and date of the reservation.</li> <li>Your justification for the reservation -- this must be provided or the request will be rejected.</li> <li>The number of nodes required.</li> </ul> <p>On the second page, you will need to specify which username you wish the reservation to be charged against and, once the username has been selected, the budget you want to charge the reservation to. (The selected username will be charged for the reservation but the reservation can be used by all members of the selected budget.)</p> <p>Your request will be checked by the ARCHER2 User Administration team and, if approved, you will be provided a reservation ID which can be used on the system. To submit jobs to a reservation, you need to add <code>--reservation=&lt;reservation ID&gt;</code> and <code>--qos=reservation</code> options to your job submission script or command.</p> <p>Important</p> <p>You must have at least 1 CU in the budget to submit a job on ARCHER2, even to a pre-paid reservation.</p> <p>Tip</p> <p>You can submit jobs to a reservation as soon as the reservation has been set up; jobs will remain queued until the reservation starts.</p>"},{"location":"user-guide/scheduler/#serial-jobs","title":"Serial jobs","text":"<p>You can run serial jobs on the shared data analysis nodes. More information on using the data analysis nodes (including example job submission scripts) can be found in the Data Analysis section of the User and Best Practice Guide.</p>"},{"location":"user-guide/scheduler/#best-practices-for-job-submission","title":"Best practices for job submission","text":"<p>This guidance is adapted from the advice provided by NERSC</p>"},{"location":"user-guide/scheduler/#time-limits","title":"Time Limits","text":"<p>Due to backfill scheduling, short and variable-length jobs generally start quickly resulting in much better job throughput. You can specify a minimum time for your job with the <code>--time-min</code> option to SBATCH:</p> <pre><code>#SBATCH --time-min=&lt;lower_bound&gt;\n#SBATCH --time=&lt;upper_bound&gt;\n</code></pre> <p>Within your job script, you can get the time remaining in the job with <code>squeue -h -j ${Slurm_JOBID} -o %L</code> to allow you to deal with potentially varying runtimes when using this option.</p>"},{"location":"user-guide/scheduler/#long-running-jobs","title":"Long Running Jobs","text":"<p>Simulations which must run for a long period of time achieve the best throughput when composed of many small jobs using a checkpoint and restart method chained together (see above for how to chain jobs together). However, this method does occur a startup and shutdown overhead for each job as the state is saved and loaded so you should experiment to find the best balance between runtime (long runtimes minimise the checkpoint/restart overheads) and throughput (short runtimes maximise throughput).</p>"},{"location":"user-guide/scheduler/#interconnect-locality","title":"Interconnect locality","text":"<p>For jobs which are sensitive to interconnect (MPI) performance and utilise 128 nodes or less it is possible to request that all nodes are in a single Slingshot dragonfly group. The maximum number of nodes in a group on ARCHER2 is 128.</p> <p>Slurm has a concept of \"switches\" which on ARCHER2 are configured to map to Slingshot electrical groups; where all compute nodes have all-to-all electrical connections which minimises latency. Since this places an additional constraint on the scheduler a maximum time to wait for the requested topology can be specified - after this time, the job will be placed without the constraint.</p> <p>For example, to specify that all requested nodes should come from one electrical group and to wait for up to 6 hours (360 minutes) for that placement, you would use the following option in your job:</p> <pre><code>#SBATCH --switches=1@360\n</code></pre> <p>You can request multiple groups using this option if you are using  more nodes than are in a single group to maximise the number of nodes that share electrical connetions in the job. For example, to request 4 groups (maximum of 512 nodes) and have this as an absolute constraint with no timeout, you would use:</p> <pre><code>#SBATCH --switches=4\n</code></pre> <p>Danger</p> <p>When specifying the number of groups take care to request enough groups to satisfy the requested number of nodes. If the number is too low then an unneccesary delay will be added due to the unsatisfiable request.</p> <p>A useful heuristic to ensure this is the case is to ensure that the total nodes requested is less than or equal to the number of groups multiplied by 128.</p>"},{"location":"user-guide/scheduler/#large-jobs","title":"Large Jobs","text":"<p>Large jobs may take longer to start up. The <code>sbcast</code> command is recommended for large jobs requesting over 1500 MPI tasks. By default, Slurm reads the executable on the allocated compute nodes from the location where it is installed; this may take long time when the file system (where the executable resides) is slow or busy. The <code>sbcast</code> command, the executable can be copied to the <code>/tmp</code> directory on each of the compute nodes. Since <code>/tmp</code> is part of the memory on the compute nodes, it can speed up the job startup time.</p> <pre><code>sbcast --compress=none /path/to/exe /tmp/exe\nsrun /tmp/exe\n</code></pre>"},{"location":"user-guide/scheduler/#huge-pages","title":"Huge pages","text":"<p>Huge pages are virtual memory pages which are bigger than the default page size of 4K bytes. Huge pages can improve memory performance for common access patterns on large data sets since it helps to reduce the number of virtual to physical address translations when compared to using the default 4KB.</p> <p>To use huge pages for an application (with the 2 MB huge pages as an example):</p> <pre><code>module load craype-hugepages2M\ncc -o mycode.exe mycode.c\n</code></pre> <p>And also load the same huge pages module at runtime.</p> <p>Warning</p> <p>Due to the huge pages memory fragmentation issue, applications may get Cannot allocate memory warnings or errors when there are not enough hugepages on the compute node, such as:</p> <p>libhugetlbfs [nid0000xx:xxxxx]: WARNING: New heap segment map at 0x10000000 failed: Cannot allocate memory``</p> <p>By default, The verbosity level of libhugetlbfs <code>HUGETLB_VERBOSE</code> is set to <code>0</code> on ARCHER2 to surpress debugging messages. Users can adjust this value to obtain more information on huge pages use.</p>"},{"location":"user-guide/scheduler/#when-to-use-huge-pages","title":"When to Use Huge Pages","text":"<ul> <li>For MPI applications, map the static data and/or heap onto huge     pages.</li> <li>For an application which uses shared memory, which needs to be     concurrently registered with the high speed network drivers for     remote communication.</li> <li>For SHMEM applications, map the static data and/or private heap onto     huge pages.</li> <li>For applications written in Unified Parallel C, Coarray Fortran, and     other languages based on the PGAS programming model, map the static     data and/or private heap onto huge pages.</li> <li>For an application doing heavy I/O.</li> <li>To improve memory performance for common access patterns on large     data sets.</li> </ul>"},{"location":"user-guide/scheduler/#when-to-avoid-huge-pages","title":"When to Avoid Huge Pages","text":"<ul> <li>Applications sometimes consist of many steering programs in addition     to the core application. Applying huge page behavior to all     processes would not provide any benefit and would consume huge pages     that would otherwise benefit the core application. The runtime     environment variable <code>HUGETLB_RESTRICT_EXE</code> can be used to specify     the susbset of the programs to use hugepages.</li> <li>For certain applications if using hugepages either causes issues or     slows down performance. One such example is that when an application     forks more subprocesses (such as pthreads) and these threads     allocate memory, the newly allocated memory are the default 4 KB     pages.</li> </ul>"},{"location":"user-guide/sw-environment-4cab/","title":"Software environment: 4-cabinet system","text":"<p>Important</p> <p>This section covers the software environment on the initial, 4-cabinet ARCHER2 system. For docmentation on the software environment on the full ARCHER2 system, please see Software environment: full system.</p> <p>The software environment on ARCHER2 is primarily controlled through the <code>module</code> command. By loading and switching software modules you control which software and versions are available to you.</p> <p>Information</p> <p>A module is a self-contained description of a software package -- it contains the settings required to run a software package and, usually, encodes required dependencies on other software packages.</p> <p>By default, all users on ARCHER2 start with the default software environment loaded.</p> <p>Software modules on ARCHER2 are provided by both HPE Cray (usually known as the Cray Development Environment, CDE) and by EPCC, who provide the Service Provision, and Computational Science and Engineering services.</p> <p>In this section, we provide:</p> <ul> <li>A brief overview of the <code>module</code> command</li> <li>A brief description of how the <code>module</code> command manipulates your      environment</li> </ul>"},{"location":"user-guide/sw-environment-4cab/#using-the-module-command","title":"Using the <code>module</code> command","text":"<p>We only cover basic usage of the <code>module</code> command here. For full documentation please see the Linux manual page on modules</p> <p>The <code>module</code> command takes a subcommand to indicate what operation you wish to perform. Common subcommands are:</p> <ul> <li><code>module list [name]</code> - List modules currently loaded in your      environment, optionally filtered by <code>[name]</code></li> <li><code>module avail [name]</code> - List modules available, optionally      filtered by <code>[name]</code></li> <li><code>module savelist</code> - List module collections available (usually      used for accessing different programming environments)</li> <li><code>module restore name</code> - Restore the module collection called      <code>name</code> (usually used for setting up a programming environment)</li> <li><code>module load name</code> - Load the module called <code>name</code> into your      environment</li> <li><code>module remove name</code> - Remove the module called <code>name</code> from your      environment</li> <li><code>module swap old new</code> - Swap module <code>new</code> for module <code>old</code> in your      environment</li> <li><code>module help name</code> - Show help information on module <code>name</code></li> <li><code>module show name</code> - List what module <code>name</code> actually does to your      environment</li> </ul> <p>These are described in more detail below.</p>"},{"location":"user-guide/sw-environment-4cab/#information-on-the-available-modules","title":"Information on the available modules","text":"<p>The <code>module list</code> command will give the names of the modules and their versions you have presently loaded in your environment:</p> <pre><code>auser@uan01:~&gt; module list\nCurrently Loaded Modulefiles:\n1) cpe-aocc                          7) cray-dsmml/0.1.2(default)\n2) aocc/2.1.0.3(default)             8) perftools-base/20.09.0(default)\n3) craype/2.7.0(default)             9) xpmem/2.2.35-7.0.1.0_1.3__gd50fabf.shasta(default)\n4) craype-x86-rome                  10) cray-mpich/8.0.15(default)\n5) libfabric/1.11.0.0.233(default)  11) cray-libsci/20.08.1.2(default)\n6) craype-network-ofi\n</code></pre> <p>Finding out which software modules are available on the system is performed using the <code>module avail</code> command. To list all software modules available, use:</p> <pre><code>auser@uan01:~&gt; module avail\n------------------------------- /opt/cray/pe/perftools/20.09.0/modulefiles --------------------------------\nperftools       perftools-lite-events  perftools-lite-hbm    perftools-nwpc     \nperftools-lite  perftools-lite-gpu     perftools-lite-loops  perftools-preload  \n\n---------------------------------- /opt/cray/pe/craype/2.7.0/modulefiles ----------------------------------\ncraype-hugepages1G  craype-hugepages8M   craype-hugepages128M  craype-network-ofi          \ncraype-hugepages2G  craype-hugepages16M  craype-hugepages256M  craype-network-slingshot10  \ncraype-hugepages2M  craype-hugepages32M  craype-hugepages512M  craype-x86-rome             \ncraype-hugepages4M  craype-hugepages64M  craype-network-none   \n\n------------------------------------- /usr/local/Modules/modulefiles --------------------------------------\ndot  module-git  module-info  modules  null  use.own  \n\n-------------------------------------- /opt/cray/pe/cpe-prgenv/7.0.0 --------------------------------------\ncpe-aocc  cpe-cray  cpe-gnu  \n\n-------------------------------------------- /opt/modulefiles ---------------------------------------------\naocc/2.1.0.3(default)  cray-R/4.0.2.0(default)  gcc/8.1.0  gcc/9.3.0  gcc/10.1.0(default)  \n\n\n---------------------------------------- /opt/cray/pe/modulefiles -----------------------------------------\natp/3.7.4(default)              cray-mpich-abi/8.0.15             craype-dl-plugin-py3/20.06.1(default)  \ncce/10.0.3(default)             cray-mpich-ucx/8.0.15             craype/2.7.0(default)                  \ncray-ccdb/4.7.1(default)        cray-mpich/8.0.15(default)        craypkg-gen/1.3.10(default)            \ncray-cti/2.7.3(default)         cray-netcdf-hdf5parallel/4.7.4.0  gdb4hpc/4.7.3(default)                 \ncray-dsmml/0.1.2(default)       cray-netcdf/4.7.4.0               iobuf/2.0.10(default)                  \ncray-fftw/3.3.8.7(default)      cray-openshmemx/11.1.1(default)   papi/6.0.0.2(default)                  \ncray-ga/5.7.0.3                 cray-parallel-netcdf/1.12.1.0     perftools-base/20.09.0(default)        \ncray-hdf5-parallel/1.12.0.0     cray-pmi-lib/6.0.6(default)       valgrind4hpc/2.7.2(default)            \ncray-hdf5/1.12.0.0              cray-pmi/6.0.6(default)           \ncray-libsci/20.08.1.2(default)  cray-python/3.8.5.0(default)    \n</code></pre> <p>This will list all the names and versions of the modules available on the service. Not all of them may work in your account though due to, for example, licencing restrictions. You will notice that for many modules we have more than one version, each of which is identified by a version number. One of these versions is the default. As the service develops the default version will change and old versions of software may be deleted.</p> <p>You can list all the modules of a particular type by providing an argument to the <code>module avail</code> command. For example, to list all available versions of the HPE Cray FFTW library, use:</p> <pre><code>auser@uan01:~&gt; module avail cray-fftw\n\n---------------------------------------- /opt/cray/pe/modulefiles -----------------------------------------\ncray-fftw/3.3.8.7(default) \n</code></pre> <p>If you want more info on any of the modules, you can use the <code>module help</code> command:</p> <pre><code>auser@uan01:~&gt; module help cray-fftw\n\n-------------------------------------------------------------------\nModule Specific Help for /opt/cray/pe/modulefiles/cray-fftw/3.3.8.7:\n\n\n===================================================================\nFFTW 3.3.8.7\n============\n  Release Date:\n  -------------\n    June 2020\n\n\n  Purpose:\n  --------\n    This Cray FFTW 3.3.8.7 release is supported on Cray Shasta Systems. \n    FFTW is supported on the host CPU but not on the accelerator of Cray systems.\n\n    The Cray FFTW 3.3.8.7 release provides the following:\n      - Optimizations for AMD Rome CPUs.\n    See the Product and OS Dependencies section for details\n\n[...]\n</code></pre> <p>The <code>module show</code> command reveals what operations the module actually performs to change your environment when it is loaded. We provide a brief overview of what the significance of these different settings mean below. For example, for the default FFTW module:</p> <pre><code>auser@uan01:~&gt; module show cray-fftw\n-------------------------------------------------------------------\n/opt/cray/pe/modulefiles/cray-fftw/3.3.8.7:\n\nconflict        cray-fftw\nconflict        fftw\nsetenv          FFTW_VERSION 3.3.8.7\nsetenv          CRAY_FFTW_VERSION 3.3.8.7\nsetenv          CRAY_FFTW_PREFIX /opt/cray/pe/fftw/3.3.8.7/x86_rome\nsetenv          FFTW_ROOT /opt/cray/pe/fftw/3.3.8.7/x86_rome\nsetenv          FFTW_DIR /opt/cray/pe/fftw/3.3.8.7/x86_rome/lib\nsetenv          FFTW_INC /opt/cray/pe/fftw/3.3.8.7/x86_rome/include\nprepend-path    PATH /opt/cray/pe/fftw/3.3.8.7/x86_rome/bin\nprepend-path    MANPATH /opt/cray/pe/fftw/3.3.8.7/share/man\nprepend-path    CRAY_LD_LIBRARY_PATH /opt/cray/pe/fftw/3.3.8.7/x86_rome/lib\nprepend-path    PE_PKGCONFIG_PRODUCTS PE_FFTW\nsetenv          PE_FFTW_TARGET_x86_skylake x86_skylake\nsetenv          PE_FFTW_TARGET_x86_rome x86_rome\nsetenv          PE_FFTW_TARGET_x86_cascadelake x86_cascadelake\nsetenv          PE_FFTW_TARGET_x86_64 x86_64\nsetenv          PE_FFTW_TARGET_share share\nsetenv          PE_FFTW_TARGET_sandybridge sandybridge\nsetenv          PE_FFTW_TARGET_mic_knl mic_knl\nsetenv          PE_FFTW_TARGET_ivybridge ivybridge\nsetenv          PE_FFTW_TARGET_haswell haswell\nsetenv          PE_FFTW_TARGET_broadwell broadwell\nsetenv          PE_FFTW_VOLATILE_PKGCONFIG_PATH /opt/cray/pe/fftw/3.3.8.7/@PE_FFTW_TARGET@/lib/pkgconfig\nsetenv          PE_FFTW_PKGCONFIG_VARIABLES PE_FFTW_OMP_REQUIRES_@openmp@\nsetenv          PE_FFTW_OMP_REQUIRES { }\nsetenv          PE_FFTW_OMP_REQUIRES_openmp _mp\nsetenv          PE_FFTW_PKGCONFIG_LIBS fftw3_mpi:libfftw3_threads:fftw3:fftw3f_mpi:libfftw3f_threads:fftw3f\nmodule-whatis   {FFTW 3.3.8.7 - Fastest Fourier Transform in the West}\n  [...]\n</code></pre>"},{"location":"user-guide/sw-environment-4cab/#loading-removing-and-swapping-modules","title":"Loading, removing and swapping modules","text":"<p>To load a module to use the <code>module load</code> command. For example, to load the default version of HPE Cray FFTW into your environment, use:</p> <pre><code>auser@uan01:~&gt; module load cray-fftw\n</code></pre> <p>Once you have done this, your environment will be setup to use the HPE Cray FFTW library. The above command will load the default version of HPE Cray FFTW. If you need a specific version of the software, you can add more information:</p> <pre><code>auser@uan01:~&gt; module load cray-fftw/3.3.8.7\n</code></pre> <p>will load HPE Cray FFTW version 3.3.8.7 into your environment, regardless of the default.</p> <p>If you want to remove software from your environment, <code>module remove</code> will remove a loaded module:</p> <pre><code>auser@uan01:~&gt; module remove cray-fftw\n</code></pre> <p>will unload what ever version of <code>cray-fftw</code> (even if it is not the default) you might have loaded.</p> <p>There are many situations in which you might want to change the presently loaded version to a different one, such as trying the latest version which is not yet the default or using a legacy version to keep compatibility with old data. This can be achieved most easily by using <code>module swap oldmodule newmodule</code>.</p> <p>Suppose you have loaded version 3.3.8.7 of <code>cray-fftw</code>, the following command will change to version 3.3.8.5:</p> <pre><code>auser@uan01:~&gt; module swap cray-fftw cray-fftw/3.3.8.5\n</code></pre> <p>You did not need to specify the version of the loaded module in your current environment as this can be inferred as it will be the only one you have loaded.</p>"},{"location":"user-guide/sw-environment-4cab/#changing-programming-environment","title":"Changing Programming Environment","text":"<p>The three programming environments <code>PrgEnv-aocc</code>, <code>PrgEnv-cray</code>, <code>PrgEnv-gnu</code> are implemented as module collections. The correct way to change programming environment, that is, change the collection of modules, is therefore via <code>module restore</code>. For example:</p> <pre><code>auser@uan01:~&gt; module restore PrgEnv-gnu\n</code></pre> <p>!!! note there is only one argument, which is the collection to be restored. The command <code>module restore</code> will output a list of modules in the outgoing collection as they are unloaded, and the modules in the incoming collection as they are loaded. If you prefer not to have messages</p> <pre><code>auser@uan1:~&gt; module -s restore PrgEnv-gnu\n</code></pre> <p>will suppress the messages. An attempt to restore a collection which is already loaded will result in no operation.</p> <p>Module collections are stored in a user's home directory <code>${HOME}/.module</code>. However, as the home directory is not available to the back end, <code>module restore</code> may fail for batch jobs. In this case, it is possible to restore one of the three standard programming environments via, e.g.,</p> <pre><code>module restore /etc/cray-pe.d/PrgEnv-gnu\n</code></pre>"},{"location":"user-guide/sw-environment-4cab/#capturing-your-environment-for-reuse","title":"Capturing your environment for reuse","text":"<p>Sometimes it is useful to save the module environment that you are using to compile a piece of code or execute a piece of software. This is saved as a module collection. You can save a collection from your current environment by executing:</p> <pre><code>auser@uan01:~&gt; module save [collection_name]\n</code></pre> <p>Note</p> <p>If you do not specify the environment name, it is called <code>default</code>.</p> <p>You can find the list of saved module environments by executing:</p> <pre><code>auser@uan01:~&gt; module savelist\nNamed collection list:\n 1) default   2) PrgEnv-aocc   3) PrgEnv-cray   4) PrgEnv-gnu \n</code></pre> <p>To list the modules in a collection, you can execute, e.g.,:</p> <pre><code>auser@uan01:~&gt; module saveshow PrgEnv-gnu\n-------------------------------------------------------------------\n/home/t01/t01/auser/.module/default:\nmodule use --append /opt/cray/pe/perftools/20.09.0/modulefiles\nmodule use --append /opt/cray/pe/craype/2.7.0/modulefiles\nmodule use --append /usr/local/Modules/modulefiles\nmodule use --append /opt/cray/pe/cpe-prgenv/7.0.0\nmodule use --append /opt/modulefiles\nmodule use --append /opt/cray/modulefiles\nmodule use --append /opt/cray/pe/modulefiles\nmodule use --append /opt/cray/pe/craype-targets/default/modulefiles\nmodule load cpe-gnu\nmodule load gcc\nmodule load craype\nmodule load craype-x86-rome\nmodule load --notuasked libfabric\nmodule load craype-network-ofi\nmodule load cray-dsmml\nmodule load perftools-base\nmodule load xpmem\nmodule load cray-mpich\nmodule load cray-libsci\nmodule load /work/y07/shared/archer2-modules/modulefiles-cse/epcc-setup-env\n</code></pre> <p>Note again that the details of the collection have been saved to the home directory (the first line of output above). It is possible to save a module collection with a fully qualified path, e.g.,</p> <pre><code>auser@uan1:~&gt; module save /work/t01/z01/auser/.module/PrgEnv-gnu\n</code></pre> <p>which would make it available from the batch system.</p> <p>To delete a module environment, you can execute:</p> <pre><code>auser@uan01:~&gt; module saverm &lt;environment_name&gt;\n</code></pre>"},{"location":"user-guide/sw-environment-4cab/#shell-environment-overview","title":"Shell environment overview","text":"<p>When you log in to ARCHER2, you are using the bash shell by default. As any other software, the bash shell has loaded a set of environment variables that can be listed by executing <code>printenv</code> or <code>export</code>.</p> <p>The environment variables listed before are useful to define the behaviour of the software you run. For instance, <code>OMP_NUM_THREADS</code> define the number of threads.</p> <p>To define an environment variable, you need to execute:</p> <pre><code>export OMP_NUM_THREADS=4\n</code></pre> <p>Please note there are no blanks between the variable name, the assignation symbol, and the value. If the value is a string, enclose the string in double quotation marks.</p> <p>You can show the value of a specific environment variable if you print it:</p> <pre><code>echo $OMP_NUM_THREADS\n</code></pre> <p>Do not forget the dollar symbol. To remove an environment variable, just execute:</p> <pre><code>unset OMP_NUM_THREADS\n</code></pre>"},{"location":"user-guide/sw-environment/","title":"Software environment","text":"<p>The software environment on ARCHER2 is managed using the  Lmod software. Selecting which software is available in your environment is primarily controlled through the <code>module</code> command. By loading and switching software modules you control which software and versions are available to you.</p> <p>Information</p> <p>A module is a self-contained description of a software package -- it contains the settings required to run a software package and, usually, encodes required dependencies on other software packages.</p> <p>By default, all users on ARCHER2 start with the default software environment loaded.</p> <p>Software modules on ARCHER2 are provided by both HPE (usually known as the HPE Cray Programming Environment, CPE) and by EPCC, who provide the Service Provision, and Computational Science and Engineering services.</p> <p>In this section, we provide:</p> <ul> <li>A brief overview of the <code>module</code> command</li> <li>A brief description of how the <code>module</code> command manipulates your      environment</li> </ul>"},{"location":"user-guide/sw-environment/#using-the-module-command","title":"Using the <code>module</code> command","text":"<p>We only cover basic usage of the Lmod <code>module</code> command here. For full documentation please see the Lmod documentation</p> <p>The <code>module</code> command takes a subcommand to indicate what operation you wish to perform. Common subcommands are:</p> <ul> <li><code>module restore</code> - Restore the default module setup (i.e. as if you had logged      out and back in again)</li> <li><code>module list [name]</code> - List modules currently loaded in your      environment, optionally filtered by <code>[name]</code></li> <li><code>module avail [name]</code> - List modules available, optionally      filtered by <code>[name]</code></li> <li><code>module spider [name][/version]</code> - Search available modules (including hidden       modules) and provide information on modules</li> <li><code>module load name</code> - Load the module called <code>name</code> into your      environment</li> <li><code>module remove name</code> - Remove the module called <code>name</code> from your      environment</li> <li><code>module help name</code> - Show help information on module <code>name</code></li> <li><code>module show name</code> - List what module <code>name</code> actually does to your      environment</li> </ul> <p>These are described in more detail below.</p> <p>Tip</p> <p>Lmod allows you to use the <code>ml</code> shortcut command. Without any arguments, <code>ml</code> behaves like <code>module list</code>; when a module name is specified to <code>ml</code>, <code>ml</code> behaves like <code>module load</code>.</p> <p>Note</p> <p>You will often have to include <code>module</code> commands in any job submission scripts to setup the software to use in your jobs. Generally, if you load modules in interactive sessions, these loaded modules do not carry over into any job submission scripts.</p> <p>Important</p> <p>You should not use the <code>module purge</code> command on ARCHER2 as this will cause issues for the HPE Cray programming environment. If you wish to  reset your modules, you should use the <code>module restore</code> command instead.</p>"},{"location":"user-guide/sw-environment/#information-on-the-available-modules","title":"Information on the available modules","text":"<p>The key commands for getting information on modules are covered in more detail below. They are:</p> <ul> <li><code>module list</code></li> <li><code>module avail</code></li> <li><code>module spider</code></li> <li><code>module help</code></li> <li><code>module show</code></li> </ul>"},{"location":"user-guide/sw-environment/#module-list","title":"<code>module list</code>","text":"<p>The <code>module list</code> command will give the names of the modules and their versions you have presently loaded in your environment:</p> <pre><code>auser@ln03:~&gt; module list\n\nCurrently Loaded Modules:\n  1) craype-x86-rome                         6) cce/15.0.0             11) PrgEnv-cray/8.3.3\n  2) libfabric/1.12.1.2.2.0.0                7) craype/2.7.19          12) bolt/0.8\n  3) craype-network-ofi                      8) cray-dsmml/0.2.2       13) epcc-setup-env\n  4) perftools-base/22.12.0                  9) cray-mpich/8.1.23      14) load-epcc-module\n  5) xpmem/2.5.2-2.4_3.30__gd0f7936.shasta  10) cray-libsci/22.12.1.1\n</code></pre> <p>All users start with a default set of modules loaded corresponding to:</p> <ul> <li>The HPE Cray Compiling Environment (CCE): includes the HPE Cray clang and Fortran compilers</li> <li>HPE Cray MPICH: The HPE Cray MPI library</li> <li>HPE Cray LibSci: The HPE Cray numerical libraries (including BLAS/LAPACK and ScaLAPACK)</li> </ul>"},{"location":"user-guide/sw-environment/#module-avail","title":"<code>module avail</code>","text":"<p>Finding out which software modules are currently available to load on the system is performed using the <code>module avail</code> command. To list all software modules currently available to load, use:</p> <pre><code>auser@uan01:~&gt; module avail\n\n--------------------------- /work/y07/shared/archer2-lmod/utils/compiler/crayclang/10.0 ---------------------------\n   darshan/3.3.1\n\n------------------------------------ /work/y07/shared/archer2-lmod/python/core ------------------------------------\n   matplotlib/3.4.3    netcdf4/1.5.7    pytorch/1.10.0    scons/4.3.0    seaborn/0.11.2    tensorflow/2.7.0\n\n------------------------------------- /work/y07/shared/archer2-lmod/libs/core -------------------------------------\n   aocl/3.1     (D)    gmp/6.2.1            matio/1.5.23        parmetis/4.0.3        slepc/3.14.1\n   aocl/4.0            gsl/2.7              metis/5.1.0         petsc/3.14.2          slepc/3.18.3       (D)\n   boost/1.72.0        hypre/2.18.0         mkl/2023.0.0        petsc/3.18.5   (D)    superlu-dist/6.4.0\n   boost/1.81.0 (D)    hypre/2.25.0  (D)    mumps/5.3.5         scotch/6.1.0          superlu-dist/8.1.2 (D)\n   eigen/3.4.0         libxml2/2.9.7        mumps/5.5.1  (D)    scotch/7.0.3   (D)    superlu/5.2.2\n\n------------------------------------- /work/y07/shared/archer2-lmod/apps/core -------------------------------------\n   castep/22.11                    namd/2.14                 (D)    py-chemshell/21.0.3\n   code_saturne/7.0.1-cce15        nektar/5.2.0                     quantum_espresso/6.8  (D)\n   code_saturne/7.0.1-gcc11 (D)    nwchem/7.0.2                     quantum_espresso/7.1\n   cp2k/cp2k-2023.1                onetep/6.1.9.0-CCE-LibSci (D)    tcl-chemshell/3.7.1\n   elk/elk-7.2.42                  onetep/6.1.9.0-GCC-LibSci        vasp/5/5.4.4.pl2-vtst\n   fhiaims/210716.3                onetep/6.1.9.0-GCC-MKL           vasp/5/5.4.4.pl2\n   gromacs/2022.4+plumed           openfoam/com/v2106               vasp/6/6.3.2-vtst\n   gromacs/2022.4           (D)    openfoam/com/v2212        (D)    vasp/6/6.3.2          (D)\n   lammps/17Feb2023                openfoam/org/v9.20210903\n   namd/2.14-nosmp                 openfoam/org/v10.20230119 (D)\n\n------------------------------------ /work/y07/shared/archer2-lmod/utils/core -------------------------------------\n   amd-uprof/3.6.449          darshan-util/3.3.1        imagemagick/7.1.0         reframe/4.1.0\n   arm/forge/22.1.3           epcc-reframe/0.2          ncl/6.6.2                 tcl/8.6.13\n   bolt/0.7                   epcc-setup-env     (L)    nco/5.0.3          (D)    tk/8.6.13\n   bolt/0.8          (L,D)    gct/v6.2.20201212         nco/5.0.5                 usage-analysis/1.2\n   cdo/1.9.9rc1               genmaskcpu/1.0            ncview/2.1.7              visidata/2.1\n   cdo/2.1.1         (D)      gnuplot/5.4.2-simg        other-software/1.0        vmd/1.9.3-gcc10\n   cmake/3.18.4               gnuplot/5.4.2      (D)    paraview/5.9.1     (D)    xthi/1.3\n   cmake/3.21.3      (D)      gnuplot/5.4.3             paraview/5.10.1\n\n--------------------- /opt/cray/pe/lmod/modulefiles/mpi/crayclang/14.0/ofi/1.0/cray-mpich/8.0 ---------------------\n   cray-hdf5-parallel/1.12.2.1    cray-mpixlate/1.0.0.6    cray-parallel-netcdf/1.12.3.1\n\n--------------------------- /opt/cray/pe/lmod/modulefiles/comnet/crayclang/14.0/ofi/1.0 ---------------------------\n   cray-mpich-abi/8.1.23    cray-mpich/8.1.23 (L)\n\n...output trimmed...\n</code></pre> <p>This will list all the names and versions of the modules that you can currently load. Note that other modules may be defined but not available to you as they depend on modules you do not have loaded. Lmod only shows modules that you can currently load, not all those that are defined. You can search for modules that are not currently visble to you using the <code>module spider</code> command - we  cover this in more detail below.</p> <p>Note also, that not all modules may work in your account though due to, for example, licencing restrictions. You will notice that for many modules we have more than one version, each of which is identified by a version number. One of these versions is the default. As the service develops the default version will change and old versions of software may be deleted.</p> <p>You can list all the modules of a particular type by providing an argument to the <code>module avail</code> command. For example, to list all available versions of the HPE Cray FFTW library, use:</p> <pre><code>auser@ln03:~&gt;  module avail cray-fftw\n\n--------------------------------- /opt/cray/pe/lmod/modulefiles/cpu/x86-rome/1.0 ----------------------------------\n   cray-fftw/3.3.10.3\n\nModule defaults are chosen based on Find First Rules due to Name/Version/Version modules found in the module tree.\nSee https://lmod.readthedocs.io/en/latest/060_locating.html for details.\n\nUse \"module spider\" to find all possible modules and extensions.\nUse \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\".\n</code></pre>"},{"location":"user-guide/sw-environment/#module-spider","title":"<code>module spider</code>","text":"<p>The <code>module spider</code> command is used to find out which modules are defined on the system. Unlike <code>module avail</code>, this includes modules that are not currently able to be loaded due to the fact you have not yet loaded dependencies to make them directly available.</p> <p><code>module spider</code> takes 3 forms:</p> <ul> <li><code>module spider</code> without any arguments lists all modules defined on the system</li> <li><code>module spider &lt;module&gt;</code> shows information on which versions of <code>&lt;module&gt;</code> are    defined on the system</li> <li><code>module spider &lt;module&gt;/&lt;version&gt;</code> shows information on the specific version of     the module defined on the system, including dependencies that must be loaded     before this module can be loaded (if any)</li> </ul> <p>If you cannot find a module that you expect to be on the system using <code>module avail</code> then you can use <code>module spider</code> to find out which dependencies you need to load to make the module available.</p> <p>For example, the module <code>cray-netcdf-hdf5parallel</code> is installed on ARCHER2 but it will not be found by <code>module avail</code>:</p> <pre><code>auser@ln03:~&gt; module avail cray-netcdf-hdf5parallel\nNo module(s) or extension(s) found!\nUse \"module spider\" to find all possible modules and extensions.\nUse \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\".\n</code></pre> <p>We can use <code>module spider</code> without any arguments to verify it exists and list the versions available:</p> <pre><code>auser@ln03:~&gt; module spider\n\n-----------------------------------------------------------------------------------------------\nThe following is a list of the modules and extensions currently available:\n-----------------------------------------------------------------------------------------------\n\n...output trimmed...\n\n  cray-mpich-abi: cray-mpich-abi/8.1.23\n\n  cray-mpixlate: cray-mpixlate/1.0.0.6\n\n  cray-mrnet: cray-mrnet/5.0.4\n\n  cray-netcdf: cray-netcdf/4.9.0.1\n\n  cray-netcdf-hdf5parallel: cray-netcdf-hdf5parallel/4.9.0.1\n\n  cray-openshmemx: cray-openshmemx/11.5.7\n\n...output trimmed...\n</code></pre> <p>Now we know which versions are available, we can use <code>module spider cray-netcdf-hdf5parallel/4.9.0.1</code> to find out how we can make it available:</p> <pre><code>auser@ln03:~&gt; module spider module spider cray-netcdf-hdf5parallel/4.9.0.1\n\n---------------------------------------------------------------------------------------------------------------\n  cray-netcdf-hdf5parallel: cray-netcdf-hdf5parallel/4.9.0.1\n---------------------------------------------------------------------------------------------------------------\n\n    You will need to load all module(s) on any one of the lines below before the \"cray-netcdf-hdf5parallel/4.9.0.1\" module is available to load.\n\n      aocc/3.2.0  cray-mpich/8.1.23  cray-hdf5-parallel/1.12.2.1\n      cce/15.0.0  cray-mpich/8.1.23  cray-hdf5-parallel/1.12.2.1\n      craype-network-none  cray-mpich/8.1.23  cray-hdf5-parallel/1.12.2.1\n      craype-network-ofi  cray-mpich/8.1.23  cray-hdf5-parallel/1.12.2.1\n      craype-network-ucx  cray-mpich/8.1.23  cray-hdf5-parallel/1.12.2.1\n      gcc/10.3.0  cray-mpich/8.1.23  cray-hdf5-parallel/1.12.2.1\n      gcc/11.2.0  cray-mpich/8.1.23  cray-hdf5-parallel/1.12.2.1\n\n    Help:\n      Release info:  /opt/cray/pe/netcdf-hdf5parallel/4.9.0.1/release_info\n</code></pre> <p>There is a lot of information here, but what the output is essentailly telling us is that in order to have <code>cray-netcdf-hdf5parallel/4.9.0.1</code> available to  load we need to have loaded a compiler (any version of CCE, GCC or AOCC),  an MPI library (any version of cray-mpich) and <code>cray-hdf5-parallel</code> loaded. As we always have a compiler and MPI library loaded, we can satisfy all of the dependencies by loading <code>cray-hdf5-parallel</code>, and then we can use <code>module avail cray-netcdf-hdf5parallel</code> again to show that the module is now available to load:</p> <pre><code>auser@ln03:~&gt; module load cray-hdf5-parallel\nauser@ln03:~&gt; module avail cray-netcdf-hdf5parallel\n\n--- /opt/cray/pe/lmod/modulefiles/hdf5-parallel/crayclang/14.0/ofi/1.0/cray-mpich/8.0/cray-hdf5-parallel/1.12.2 ---\n   cray-netcdf-hdf5parallel/4.9.0.1\n\nModule defaults are chosen based on Find First Rules due to Name/Version/Version modules found in the module tree.\nSee https://lmod.readthedocs.io/en/latest/060_locating.html for details.\n\nUse \"module spider\" to find all possible modules and extensions.\nUse \"module keyword key1 key2 ...\" to search for all possible modules matching any of the \"keys\".\n</code></pre>"},{"location":"user-guide/sw-environment/#module-help","title":"<code>module help</code>","text":"<p>If you want more info on any of the modules, you can use the <code>module help</code> command:</p> <pre><code>auser@ln03:~&gt; module help gromacs\n</code></pre>"},{"location":"user-guide/sw-environment/#module-show","title":"<code>module show</code>","text":"<p>The <code>module show</code> command reveals what operations the module actually performs to change your environment when it is loaded. For example, for the default FFTW module:</p> <pre><code>auser@ln03:~&gt; module show gromacs\n\n  [...]\n</code></pre>"},{"location":"user-guide/sw-environment/#loading-removing-and-swapping-modules","title":"Loading, removing and swapping modules","text":"<p>To change your environment and make different software available you use the following commands which we cover in more detail below.</p> <ul> <li><code>module load</code></li> <li><code>module remove</code></li> <li><code>module swap</code></li> </ul>"},{"location":"user-guide/sw-environment/#module-load","title":"<code>module load</code>","text":"<p>To load a module to use the <code>module load</code> command. For example, to load the default version of GROMACS into your environment, use:</p> <pre><code>auser@ln03:~&gt; module load gromacs\n</code></pre> <p>Once you have done this, your environment will be setup to use GROMACS. The above command will load the default version of GROMACS. If you need a specific version of the software, you can add more information:</p> <pre><code>auser@uan01:~&gt; module load gromacs/2022.4 \n</code></pre> <p>will load GROMACS version 2022.4 into your environment, regardless of the default.</p>"},{"location":"user-guide/sw-environment/#module-remove","title":"<code>module remove</code>","text":"<p>If you want to remove software from your environment, <code>module remove</code> will remove a loaded module:</p> <pre><code>auser@uan01:~&gt; module remove gromacs\n</code></pre> <p>will unload what ever version of <code>gromacs</code> you might have loaded (even if it is not the default).</p>"},{"location":"user-guide/sw-environment/#module-swap","title":"<code>module swap</code>","text":"<p>There are many situations in which you might want to change the presently loaded version to a different one, such as trying the latest version which is not yet the default or using a legacy version to keep compatibility with old data. This can be achieved most easily by using <code>module swap oldmodule newmodule</code>.</p> <p>For example, to swap from the default CCE (cray) compiler environment to the GCC (gnu) compiler environment, you would use:</p> <pre><code>auser@ln03:~&gt; module swap PrgEnv-cray PrgEnv-gnu\n</code></pre> <p>You did not need to specify the version of the loaded module in your current environment as this can be inferred as it will be the only one you have loaded.</p>"},{"location":"user-guide/sw-environment/#shell-environment-overview","title":"Shell environment overview","text":"<p>When you log in to ARCHER2, you are using the bash shell by default. As with any software, the bash shell has loaded a set of environment variables that can be listed by executing <code>printenv</code> or <code>export</code>.</p> <p>The environment variables listed before are useful to define the behaviour of the software you run. For instance, <code>OMP_NUM_THREADS</code> define the number of threads.</p> <p>To define an environment variable, you need to execute:</p> <pre><code>export OMP_NUM_THREADS=4\n</code></pre> <p>Please note there are no blanks between the variable name, the assignation symbol, and the value. If the value is a string, enclose the string in double quotation marks.</p> <p>You can show the value of a specific environment variable if you print it:</p> <pre><code>echo $OMP_NUM_THREADS\n</code></pre> <p>Do not forget the dollar symbol. To remove an environment variable, just execute:</p> <pre><code>unset OMP_NUM_THREADS\n</code></pre> <p>Note that the dollar symbol is not included when you use the <code>unset</code> command.</p>"},{"location":"user-guide/sw-environment/#cgroup-control-of-login-resources","title":"cgroup control of login resources","text":"<p>Note that it not possible for a single user to  monopolise the resources on a login node as this is controlled by cgroups. This means that a user cannot slow  down the response time for other users.</p>"},{"location":"user-guide/tds/","title":"ARCHER2 Test and Development System (TDS) user notes","text":"<p>The ARCHER2 Test and Development System (TDS) is a small system used for testing changes before they are rolled out onto the full ARCHER2 system. This page  contains useful information for people using the TDS on its configuration and what they can expect from the system.</p> <p>Important</p> <p>The TDS is used for testing on a day to day basis. This means that nodes and the entire system may be made unavailable or rebooted with little or no warning.</p>"},{"location":"user-guide/tds/#tds-system-details","title":"TDS system details","text":"<ul> <li>Login node: 2x 64-core AMD EPYC 7742, 512 GB RAM</li> <li> <p>Compute nodes: 8 compute nodes in total</p> <ul> <li>4 standard memory compute nodes: 2x 64-core AMD EPYC 7742, 256 GB RAM</li> <li>4 high memory compute nodes: 2x 64-core AMD EPYC 7742, 512 GB RAM</li> </ul> </li> <li> <p>Slingshot interconnect</p> </li> <li> <p>Storage:</p> <ul> <li>/home file system: shared with ARCHER2 main system</li> <li>/work file system: 224 TiB Lustre (2x MDT, 2x OST) - not shared with main system</li> </ul> </li> </ul>"},{"location":"user-guide/tds/#connecting-to-the-tds","title":"Connecting to the TDS","text":"<p>You can only log into the TDS from an ARCHER2 login node. You should create an  SSH key pair on an ARCHER2 login node and add the public part to your ARCHER2 account in SAFE in the usual way.</p> <p>Once your new key pair is setup, you can then login to the TDS (from an ARCHER2 login node) with</p> <pre><code>ssh login-tds.archer2.ac.uk\n</code></pre> <p>You will require your SSH key passphrase (for the new key pair you generated) and your usual ARCHER2 account password to login to the TDS.</p>"},{"location":"user-guide/tds/#slurm-scheduler-configuration","title":"Slurm scheduler configuration","text":"<ul> <li>Paritions available:<ul> <li><code>standard</code>: includes all compute nodes</li> <li><code>highmem</code>: includes high memory compute nodes</li> </ul> </li> <li>QoS available:<ul> <li><code>standard</code>: same limits as on ARCHER2 main system</li> <li><code>highmem</code>: same limits as on ARCHER2 main system</li> </ul> </li> </ul>"},{"location":"user-guide/tds/#known-issuesnotes","title":"Known issues/notes","text":"<ul> <li> <p>Software modules</p> <ul> <li>HPE Cray Programming Environment 22.12</li> <li>ARCHER2 CSE service modules available but not all software installed on TDS <code>/work</code> file system - i.e. you may be able to load a module but the software it points to may not be available. Check if the software is actually installed before trying to use it.</li> </ul> </li> <li> <p>GCC 12.2.0 (gcc/g++/gfortran) compiler has been shown to give incorrect numerical results for a number of software packages (VASP, CASTEP. CP2K). If you want to use this compiler version we recommend checking output carefully. We may remove this version from the PE software stack installed on the full system as part of the software upgrade.</p> </li> <li> <p>Singularity + MPI does not currently work - MPI executable in the Singularity container segfaults.</p> </li> <li> <p>Energy use data is not available from TDS compute nodes.</p> </li> <li> <p>Change of behaviour of the <code>--cpus-per-task</code> Slurm option. If you set <code>--cpus-per-task</code> greater than <code>1</code> in your job submission script (e.g. using <code>#SBATCH</code> directives) then this option is not inhereted by <code>srun</code> commands in the job script. You need to eithe set something like <code>export SRUN_CPUS_PER_TASK=$SLURM_CPUS_PER_TASK</code> or repeat the option explicitly in the <code>srun</code> command (e.g. <code>srun --cpus-per-task=$SLURM_CPUS_PER_TASK --hint=nomultithread --distribution=block:block</code>).</p> </li> <li> <p>Change in definition of a Slurm NUMA region. On the TDS, a Slurm NUMA region is 4 cores (corresponding to an Core CompleX CCX in the AMD EPYC Zen2 architecture). This means cyclic process placements on NUMA regions (e.g. <code>--distribution=block:cyclic</code>) will cycle over 4-core CCX. (On the main system, a Slurm NUMA region is 16 cores).</p> </li> </ul>"},{"location":"user-guide/tuning/","title":"Performance tuning","text":""},{"location":"user-guide/tuning/#mpi","title":"MPI","text":"<p>The vast majority of parallel scientific applications use the MPI library as the main way to implement parallelism; it is used so universally that the Cray compiler wrappers on ARCHER2 link to the Cray MPI library by default. Unlike other clusters you may have used, there is no choice of MPI library on ARCHER2: regardless of what compiler you are using, your program will use Cray MPI. This is because the Slingshot network on ARCHER2 is Cray-specific and significant effort has been put in by Cray software engineers to optimise the MPI performance on their Shasta systems.</p> <p>Here we list a number of suggestions for improving the performance of your MPI programs on ARCHER2. Although MPI programs are capable of scaling very well due to the bespoke communications hardware and software, the details of how a program calls MPI can have significant effects on achieved performance.</p> <p>Note</p> <p>Many of these tips are actually quite generic and should be beneficial to any MPI program; however, they all become much more important when running on very large numbers of processes on a machine the size of ARCHER2.</p>"},{"location":"user-guide/tuning/#mpi-environment-variables","title":"MPI environment variables","text":"<p>There are a number of environment variables available to control aspects of MPI behavour on ARCHER2, the set of options can be displayed by running,</p> <p><pre><code>man intro_mpi\n</code></pre> o n the ARCHER2 login nodes. </p> <p>A couple of specific variables to highlight are MPICH_OFI_STARTUP_CONNECT and MPICH_OFI_RMA_STARTUP_CONNECT.</p> <p>When using the default OFI transport layer the connections between ranks are set-up as they are required. This allows for good performance while reducing memory requirements. However for jobs using all-to-all communication it might be better to generate these connections in a coordinated way at the start of the application. To enable this set the following environment variable:</p> <pre><code>  export MPICH_OFI_STARTUP_CONNECT=1  \n</code></pre> <p>Additionally, RMA jobs requiring an all-to-all communication pattern on node it may be beneficial to set up the connections between processes on a node in a coordinated fashion:</p> <pre><code>  export MPICH_OFI_RMA_STARTUP_CONNECT=1\n</code></pre> <p>This option automatically enables MPICH_OFI_STARTUP_CONNECT.</p>"},{"location":"user-guide/tuning/#synchronous-vs-asynchronous-communications","title":"Synchronous vs asynchronous communications","text":""},{"location":"user-guide/tuning/#mpi_send","title":"MPI_Send","text":"<p>A standard way to send data in MPI is using <code>MPI_Send</code> (aptly called standard send). Somewhat confusingly, MPI is allowed to choose how to implement this in two different ways:</p> <ul> <li> <p>Synchronously     The sending process waits until a matching receive has been posted,     i.e. it operates like <code>MPI_Ssend</code>. This clearly has the risk of     deadlock if no receive is ever issued.</p> </li> <li> <p>Asynchronously     MPI makes a copy of the message into an internal buffer and returns     straight away without waiting for a matching receive; the message     may actually be delivered later on. This is like the behaviour of     the the buffered send routine <code>MPI_Bsend</code>.</p> </li> </ul> <p>The rationale is that MPI, rather than the user, should decide how best to send a message.</p> <p>In practice, what typically happens is that MPI tries to use an asynchronous approach via the eager protocol: the message is sent directly to a preallocated buffer on the receiver and the routine returns immediately afterwards. Clearly there is a limit on how much space can be reserved for this, so:</p> <ul> <li>small messages will be sent asynchronously;</li> <li>large messages will be sent synchronously.</li> </ul> <p>The threshold is often termed the eager limit which is fixed for the entire run of your program. It will have some default setting which varies from system to system, but might be around 8K bytes.</p>"},{"location":"user-guide/tuning/#implications","title":"Implications","text":"<ul> <li>An MPI program will typically run faster if <code>MPI_Send</code> is     implemented asynchronously using the eager protocol since     synchronisation between sender and receive is much reduced.</li> <li>However, you should never assume that <code>MPI_Send</code> buffers your     message, so if you have concerns about deadlock you will need to use     the non-blocking variant <code>MPI_Isend</code> to guarantee that the send     routine returns control to you immediately even if there is no     matching receive.</li> <li>It is not enough to say deadlock is an issue in principle, but     it runs OK on my laptop so there is no problem in practice. The     eager limit is system-dependent so the fact that a message happens     to be buffered on your laptop is no guarantee it will be buffered on     ARCHER2.</li> <li>To check that you have a correct code, replace all instances of     <code>MPI_Send</code> / <code>MPI_Isend</code> with <code>MPI_Ssend</code> / <code>MPI_Issend</code>. A correct     MPI program should still run correctly when all references to     standard send are replaced by synchronous send (since MPI is allowed     to implement standard send as synchronous send).</li> </ul>"},{"location":"user-guide/tuning/#tuning-performance","title":"Tuning performance","text":"<p>With most MPI libraries you should be able to alter the default value of the eager limit at runtime, perhaps via an environment variable or a command-line argument to <code>mpirun</code>.</p> <p>The advice for tuning the performance of <code>MPI_Send</code> is</p> <ul> <li>find out what the distribution of message sizes for <code>MPI_Send</code> is (a     profiling tool may be useful here);</li> <li>this applies to <code>MPI_Isend</code> as well: even in the non-blocking form,     which can help to weaken synchronisation between sender and     receiver, the amount of hand-shaking required is much reduced if the     eager protocol is used;</li> <li>find out from the system documentation how to alter the value of the     eager limit (there is no standardised way to set it);</li> <li>set the eager limit to a value larger than your typical message size     -- you may need to add a small amount, say a few hundred bytes, to     allow for any additional header information that is added to each     message;</li> <li>measure the performance before and after to check that it has     improved.</li> </ul> <p>Note</p> <p>It cannot be stressed strongly enough that although the performance may be affected by the value of the eager limit, the functionality of your program should be unaffected. If changing the eager limit affects the correctness of your program (e.g. whether or not it deadlocks) then you have an incorrect MPI program.</p>"},{"location":"user-guide/tuning/#setting-the-eager-limit-on-archer2","title":"Setting the eager limit on ARCHER2","text":"<p>On ARCHER2, things are a little more complicated. Although the eager limit defaults to 16KiB, messages up to 256KiB are sent asynchronously because they are actually sent as a number of smaller messages.</p> <p>To send even larger messages asynchronously, alter the value of <code>FI_OFI_RXM_SAR_LIMIT</code> in your job submission script, e.g. to set to 512KiB:</p> <pre><code>export FI_OFI_RXM_SAR_LIMIT=524288\n</code></pre> <p>You can also control the size of the smaller messages by altering the value of <code>FI_OFI_RXM_BUFFER_SIZE</code> in your job submission script, e.g. to set to 128KiB:</p> <pre><code>export FI_OFI_RXM_BUFFER_SIZE=131072\n</code></pre> <p>A different protocol is used for messages between two processes on the same node. The default eager limit for these is 8K. Although the performance of on-node messages is unlikely to be a limiting factor for your program you can change this value, e.g. to set to 16KiB:</p> <pre><code>export MPICH_SMP_SINGLE_COPY_SIZE=16384\n</code></pre>"},{"location":"user-guide/tuning/#collective-operations","title":"Collective operations","text":"<p>Many of the collective operations that are commonly required by parallel scientific programs, i.e. operations that involve a group of processes, are already implemented in MPI. The canonical operation is perhaps adding up a double precision number across all MPI processes, which is best achieved by a reduction operation:</p> <pre><code>MPI_Allreduce(&amp;x, &amp;xsum, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);\n</code></pre> <p>This will be implemented using an efficient algorithm, for example based on a binary tree. Using such divide-and-conquer approaches typically results in an algorithm whose execution time on P processes scales as log_2(P); compare this to a naive approach where every process sends its input to rank 0 where the time will scale as P. This might not be significant on your laptop, but even on as few as 1000 processes the tree-based algorithm will already be around 100 times faster.</p> <p>So, the basic advice is always use a collective routine to implement your communications pattern if at all possible.</p> <p>In real MPI applications, collective operations are often called on a small amount of data, for example a global reduction of a single variable. In these cases, the time taken will be dominated by message latency and the first port of call when looking at performance optimisation is to call them as infrequently as possible!</p> <ul> <li>If you are simply printing diagnostics to the screen in an iterative     loop, consider doing this less frequently, e.g every ten iterations,     or even not at all (although you should easily be able to turn     diagnostics on again for future debugging).</li> <li>If you are computing some termination criterion, it may actually be     faster overall to compute it and check for convergence infrequently,     e.g. every ten iterations, even although this means that your     program could run for up to 9 extra iterations.</li> <li>If possible, group data into a single buffer and call a single     reduction with count &gt; 1; two reductions with count = 1 will take     almost exactly twice as long as a single reduction with count = 2.</li> <li>For example, if you only need to output a sequence of summed data at     the end of the run, store the partial totals in an array and do a     single reduction right at the end.</li> </ul> <p>Sometimes, the collective routines available may not appear to do exactly what you want. However, they can sometimes be used with a small amount of additional programming work:</p> <ul> <li> <p>To operate on a subset of processes, create sub-communicators     containing the relevant subset(s) and use these communicators     instead of <code>MPI_COMM_WORLD</code>. Useful functions for communicator     management include:</p> <ul> <li><code>MPI_Comm_split</code> is the most general routine;</li> <li><code>MPI_Comm_split_type</code> can be used to create a separate     communicator for each shared-memory node with <code>split type =     MPI_COMM_TYPE_SHARED</code>;</li> <li><code>MPI_Cart_sub</code> can divide a Cartesian communicator into regular     slices.</li> </ul> </li> <li> <p>If the communication pattern is what you want, but the data on     each process is not arranged in the required layout, consider using     MPI derived data types for the input and/or output. This can be     useful, for example, if you want to communicate non-contiguous data     such as a subsection of a multidimensional array although care must     be taken in defining these types to ensure they have the correct     extents.</p> <p>Another example would be using <code>MPI_Allreduce</code> to add up an integer and a double-precision variable using a single call by putting them together into a C <code>struct</code> and defining a matching MPI datatype using <code>MPI_Type_create_struct</code>. Here you would also have to provide MPI with a custom reduction operation using <code>MPI_Op_create</code>.</p> </li> </ul> <p>Many MPI programs call <code>MPI_Barrier</code> to explicitly synchronise all the processes. Although this can be useful for getting reliable performance timings, it is rare in practice to find a program where the call is actually needed for correctness. For example, you may see:</p> <pre><code>// Ensure the input x is available on all processes\nMPI_Barrier(MPI_COMM_WORLD);\n// Perform a global reduction operation\nMPI_Allreduce(&amp;x, &amp;xsum, 1, MPI_DOUBLE, MPI_SUM, MPI_COMM_WORLD);\n// Ensure the result xsum is available on all processes\nMPI_Barrier(MPI_COMM_WORLD);\n</code></pre> <p>Neither of these barriers are needed as the reduction operation performs all the required synchronisation.</p> <p>If removing a barrier from your MPI code makes it run incorrectly, then this should ring alarm bells -- it is often a symptom of an underlying bug that is simply being masked by the barrier.</p> <p>For example, if you use non-blocking calls such as <code>MPI_Irecv</code> then it is the programmer's responsibility to ensure that these are completed at some later point, for example by calling <code>MPI_Wait</code> on the returned request object. A common bug is to forget to do this, in which case you might be reading the contents of the receive buffer before the incoming message has arrived (e.g. if the sender is running late).</p> <p>Calling a barrier may mask this bug as it will make all the processes wait for each other, perhaps allowing the late sender to catch up. However, this is not guaranteed so the real solution is to call the non-blocking communications correctly.</p> <p>One of the few times when a barrier may be required is if processes are communicating with each other via some other non-MPI method, e.g. via the file system. If you want processes to sequentially open, append to, then close the same file then barriers are a simple way to achieve this:</p> <pre><code>for (i=0; i &lt; size; i++)\n{\n  if (rank == i) append_data_to_file(data, filename);\n  MPI_Barrier(comm);\n}\n</code></pre> <p>but this is really something of a special case.</p> <p>Global synchronisation may be required if you are using more advanced techniques such as hybrid MPI/OpenMP or single-sided MPI communication with put and get, but typically you should be using specialised routines such as <code>MPI_Win_fence</code> rather than <code>MPI_Barrier</code>.</p> <p>Tip</p> <p>If you run a performance profiler on your code and it shows a lot of time being spent in a collective operation such as <code>MPI_Allreduce</code>, this is not necessarily a sign that the reduction operation itself is the bottleneck. This is often a symptom of load imbalance: even if a reduction operation is efficiently implemented, it may take a long time to complete if the MPI processes do not all call it at the same time. <code>MPI_Allreduce</code> synchronises across processes so will have to wait for all the processes to call it before it can complete. A single slow process will therefore adversely impact the performance of your entire parallel program.</p>"},{"location":"user-guide/tuning/#openmp","title":"OpenMP","text":"<p>There are a variety of possible issues that can result in poor performance of OpenMP programs. These include:</p>"},{"location":"user-guide/tuning/#sequential-code","title":"Sequential code","text":"<p>Code outside of parallel regions is executed sequentially by the master thread.</p>"},{"location":"user-guide/tuning/#idle-threads","title":"Idle threads","text":"<p>If different threads have different amounts of computation to do, then threads may be idle whenever a barrier is encountered, for example at the end of parallel regions or the end of worksharing loops. For worksharing loops, choosing a suitable schedule kind may help. For more irregular computation patterns, using OpenMP tasks might offer a solution: the runtime will try to load balance tasks across the threads in the team.</p> <p>Synchronisation mechanisms that enforce mutual exclusion, such as critical regions, atomic statements and locks can also result in idle threads if there is contention - threads have to wait their turn for access.</p>"},{"location":"user-guide/tuning/#synchronisation","title":"Synchronisation","text":"<p>The act of synchronising threads comes at some cost, even if the threads are never idle. In OpenMP, the most common source of synchronisation overheads is the implicit barriers at the end of parallel regions and worksharing loops. The overhead of these barriers depends on the OpenMP implementation being used as well as on the number of threads, but is typically in the range of a few microseconds. This means that for a simple parallel loop such as</p> <pre><code>#pragma omp parallel for reduction(+:sum)\nfor (i=0;i&lt;n;i++){\n   sum += a[i];\n}\n</code></pre> <p>the number of iterations required to make parallel execution worthwhile may be of the order of 100,000. On ARCHER2, benchmarking has shown that for the AOCC compiler, OpenMP barriers have significantly higher overhead than for either the Cray or GNU compilers.</p> <p>It is possible to suppress the implicit barrier at the end of worksharing loop using a <code>nowait</code> clause, taking care that this does not introduce and race conditions.</p> <p>Atomic statements are designed to be capable of more efficient implementation that the equivalent critical region or lock/unlock pair, so should be used where applicable.</p>"},{"location":"user-guide/tuning/#scheduling","title":"Scheduling","text":"<p>Whenever we rely on the OpenMP runtime to dynamically assign computation to threads (e.g. dynamic or guided loop schedules, tasks), there is some overhead incurred (some of this cost may actually be internal synchronisation in the runtime).  It is often necessary to adjust the granularity of the computation to find a compromise between too many small units (and high scheduling cost) and too few large units (where load imbalance may dominate). For example, we can choose a non-default chunksize for the dynamic schedule, or adjust the amount of computation within each OpenMP task construct.</p>"},{"location":"user-guide/tuning/#communication","title":"Communication","text":"<p>Communication between threads in OpenMP takes place via the cache coherency mechanism. In brief, whenever a thread writes a memory location, all copies of this location which are in a cache belonging to a different core have to be marked as invalid. Subsequent accesses to this location by other threads will result in the up-to-date value being retrieved from the cache where the last write occurred (or possibly from main memory).</p> <p>Due to the fine granularity of memory accesses, these overheads are difficult to analyse or monitor. To minimise communication, we need to write code with good data affinity - i.e. each thread should access the same subset of program data as much as possible.</p>"},{"location":"user-guide/tuning/#numa-effects","title":"NUMA effects","text":"<p>On modern CPU nodes, main memory is often organised in NUMA regions - sections of main memory associated with a subset of the cores on a node. On ARCHER2 nodes, there are 8 NUMA regions per node, each associated with 16 CPU cores. On such systems the location of data in main memory with respect to the cores that are accessing it can be important. The default OS policy is to place data in the NUMA region which first accesses it (first touch policy).  For OpenMP programs this can be the worst possible option: if the data is initialised by the master thread, it is all allocated one NUMA region and having all threads accessing data becomes a bandwidth bottleneck.</p> <p>This default policy can be changed using the <code>numactl</code> command, but it is probably better to make use of the first touch policy by explicitly parallelising the data initialisation in the application code. This may be straightforward for large multidimensional arrays, but more challenging for irregular data structures.</p>"},{"location":"user-guide/tuning/#false-sharing","title":"False sharing","text":"<p>The cache coherency mechanism described above operates on units of data corresponding to the size of cache lines - for ARCHER2 CPUs this is 64 bytes. This means that if different threads are accessing neighbouring words in memory, and at least some of the accesses are writes, then communication may be happening even if no individual word is actually being accessed by more than one thread. This means that patterns such as</p> <pre><code>#pragma omp parallel shared(count) private(myid) \n{\n  myid = omp_get_thread_num();\n  ....\n  count[myid]++;\n  ....\n}\n</code></pre> <p>may give poor performance if the updates to the <code>count</code> array are sufficiently frequent.</p>"},{"location":"user-guide/tuning/#hardware-resource-contention","title":"Hardware resource contention","text":"<p>Whenever there are multiple threads (or processes) executing inside a node, they may contend for some hardware resources. The most important of these for many HPC applications is memory bandwidth. This is effect is very evident on ARCHER2 CPUs - it is possible for just 2 threads to almost saturate the available memory bandwidth in a NUMA region which has 16 cores associated with it. For very bandwidth-intensive applications, running more that 2 threads per NUMA region may gain little additional performance. If an OpenMP code is not using all the cores on a node, by default Slurm will spread the threads out across NUMA regions to maximise the available bandwidth.</p> <p>Another resource that threads may contend for is space in shared caches. On ARCHER2, every set of 4 cores shares 16MB of L3 cache. </p>"},{"location":"user-guide/tuning/#compiler-non-optimisation","title":"Compiler non-optimisation","text":"<p>In rare cases, adding OpenMP directives can adversely affect the compiler's optimisation process. The symptom of this is that the OpenMP code running on 1 thread is slower than the same code compiled without the OpenMP flag. It can be difficult to find a workaround - using the compiler's diagnostic flags to find out which optimisation (e.g. vectorisation, loop unrolling) is being affected and adding compiler-specific directives may help.</p>"},{"location":"user-guide/tuning/#hybrid-mpi-and-openmp","title":"Hybrid MPI and OpenMP","text":"<p>There are two main motivations for using both MPI and OpenMP in the same application code: reducing memory requirements and improving performance. At low core counts, where the pure MPI version of the code is still scaling well, adding OpenMP is unlikely to improve performance. In fact, it can introduce some additional overheads which make performance worse! The benefit is likely to come in the regime where the pure MPI version starts to lose scalability - here adding OpenMP can reduce communication costs, make load balancing easier, or be an effective way of exploiting additional parallelism without excessive code re-writing.</p> <p>An important performance consideration for MPI + OpenMP applications is the choice of the number of OpenMP threads per MPI process. The optimum value will depend on the application, the input data, the number of nodes requested and the choice of compiler, and is hard to predict without experimentation. However, there are some considerations that apply to ARCHER2:</p> <ul> <li> <p>Due to NUMA effects, it is likely that running at least one MPI   process per NUMA region (i.e. at least 8 MPI processes per node) will    be beneficial.</p> </li> <li> <p>The number of MPI processes per node should be a power of 2, so that   all OpenMP threads run in the same NUMA region as their parent   MPI process.</p> </li> <li> <p>For applications where each process has a small memory footprint   (e.g. some molecular dynamics codes), running no more than 4 OpenMP   threads per MPI process may be beneficial, so that all the threads   in a process share a single L3 cache.</p> </li> </ul>"}]}